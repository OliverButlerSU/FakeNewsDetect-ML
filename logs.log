2024-01-03 18:12:51,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 18:12:51,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 18:12:51,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 18:12:51,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 18:26:21,485:INFO:PyCaret ClassificationExperiment
2024-01-03 18:26:21,485:INFO:Logging name: clf-default-name
2024-01-03 18:26:21,486:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:26:21,486:INFO:version 3.2.0
2024-01-03 18:26:21,486:INFO:Initializing setup()
2024-01-03 18:26:21,486:INFO:self.USI: 829a
2024-01-03 18:26:21,486:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:26:21,486:INFO:Checking environment
2024-01-03 18:26:21,486:INFO:python_version: 3.11.5
2024-01-03 18:26:21,486:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:26:21,486:INFO:machine: AMD64
2024-01-03 18:26:21,486:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:26:21,488:INFO:Memory: svmem(total=16893386752, available=3819470848, percent=77.4, used=13073915904, free=3819470848)
2024-01-03 18:26:21,488:INFO:Physical Core: 4
2024-01-03 18:26:21,488:INFO:Logical Core: 8
2024-01-03 18:26:21,488:INFO:Checking libraries
2024-01-03 18:26:21,488:INFO:System:
2024-01-03 18:26:21,488:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:26:21,488:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:26:21,488:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:26:21,488:INFO:PyCaret required dependencies:
2024-01-03 18:26:21,539:INFO:                 pip: 23.3.1
2024-01-03 18:26:21,539:INFO:          setuptools: 68.2.2
2024-01-03 18:26:21,539:INFO:             pycaret: 3.2.0
2024-01-03 18:26:21,539:INFO:             IPython: 8.15.0
2024-01-03 18:26:21,539:INFO:          ipywidgets: 8.0.4
2024-01-03 18:26:21,539:INFO:                tqdm: 4.66.1
2024-01-03 18:26:21,539:INFO:               numpy: 1.25.2
2024-01-03 18:26:21,539:INFO:              pandas: 1.5.3
2024-01-03 18:26:21,539:INFO:              jinja2: 3.1.2
2024-01-03 18:26:21,539:INFO:               scipy: 1.10.1
2024-01-03 18:26:21,539:INFO:              joblib: 1.2.0
2024-01-03 18:26:21,539:INFO:             sklearn: 1.2.2
2024-01-03 18:26:21,539:INFO:                pyod: 1.1.2
2024-01-03 18:26:21,539:INFO:            imblearn: 0.11.0
2024-01-03 18:26:21,539:INFO:   category_encoders: 2.6.3
2024-01-03 18:26:21,539:INFO:            lightgbm: 4.2.0
2024-01-03 18:26:21,539:INFO:               numba: 0.58.1
2024-01-03 18:26:21,539:INFO:            requests: 2.31.0
2024-01-03 18:26:21,539:INFO:          matplotlib: 3.6.0
2024-01-03 18:26:21,539:INFO:          scikitplot: 0.3.7
2024-01-03 18:26:21,539:INFO:         yellowbrick: 1.5
2024-01-03 18:26:21,539:INFO:              plotly: 5.18.0
2024-01-03 18:26:21,539:INFO:    plotly-resampler: Not installed
2024-01-03 18:26:21,539:INFO:             kaleido: 0.2.1
2024-01-03 18:26:21,539:INFO:           schemdraw: 0.15
2024-01-03 18:26:21,539:INFO:         statsmodels: 0.14.1
2024-01-03 18:26:21,539:INFO:              sktime: 0.21.1
2024-01-03 18:26:21,540:INFO:               tbats: 1.1.3
2024-01-03 18:26:21,540:INFO:            pmdarima: 2.0.4
2024-01-03 18:26:21,540:INFO:              psutil: 5.9.0
2024-01-03 18:26:21,540:INFO:          markupsafe: 2.1.1
2024-01-03 18:26:21,540:INFO:             pickle5: Not installed
2024-01-03 18:26:21,540:INFO:         cloudpickle: 3.0.0
2024-01-03 18:26:21,540:INFO:         deprecation: 2.1.0
2024-01-03 18:26:21,540:INFO:              xxhash: 3.4.1
2024-01-03 18:26:21,540:INFO:           wurlitzer: Not installed
2024-01-03 18:26:21,540:INFO:PyCaret optional dependencies:
2024-01-03 18:26:21,548:INFO:                shap: Not installed
2024-01-03 18:26:21,548:INFO:           interpret: Not installed
2024-01-03 18:26:21,548:INFO:                umap: Not installed
2024-01-03 18:26:21,548:INFO:     ydata_profiling: Not installed
2024-01-03 18:26:21,548:INFO:  explainerdashboard: Not installed
2024-01-03 18:26:21,548:INFO:             autoviz: Not installed
2024-01-03 18:26:21,548:INFO:           fairlearn: Not installed
2024-01-03 18:26:21,548:INFO:          deepchecks: Not installed
2024-01-03 18:26:21,548:INFO:             xgboost: Not installed
2024-01-03 18:26:21,548:INFO:            catboost: Not installed
2024-01-03 18:26:21,548:INFO:              kmodes: Not installed
2024-01-03 18:26:21,548:INFO:             mlxtend: 0.23.0
2024-01-03 18:26:21,548:INFO:       statsforecast: Not installed
2024-01-03 18:26:21,548:INFO:        tune_sklearn: Not installed
2024-01-03 18:26:21,548:INFO:                 ray: Not installed
2024-01-03 18:26:21,548:INFO:            hyperopt: Not installed
2024-01-03 18:26:21,548:INFO:              optuna: Not installed
2024-01-03 18:26:21,548:INFO:               skopt: Not installed
2024-01-03 18:26:21,548:INFO:              mlflow: Not installed
2024-01-03 18:26:21,548:INFO:              gradio: Not installed
2024-01-03 18:26:21,548:INFO:             fastapi: Not installed
2024-01-03 18:26:21,548:INFO:             uvicorn: Not installed
2024-01-03 18:26:21,548:INFO:              m2cgen: Not installed
2024-01-03 18:26:21,548:INFO:           evidently: Not installed
2024-01-03 18:26:21,548:INFO:               fugue: Not installed
2024-01-03 18:26:21,549:INFO:           streamlit: Not installed
2024-01-03 18:26:21,549:INFO:             prophet: Not installed
2024-01-03 18:26:21,549:INFO:None
2024-01-03 18:26:21,549:INFO:Set up data.
2024-01-03 18:31:45,312:INFO:PyCaret ClassificationExperiment
2024-01-03 18:31:45,313:INFO:Logging name: clf-default-name
2024-01-03 18:31:45,313:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:31:45,313:INFO:version 3.2.0
2024-01-03 18:31:45,313:INFO:Initializing setup()
2024-01-03 18:31:45,313:INFO:self.USI: 8d0d
2024-01-03 18:31:45,313:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:31:45,313:INFO:Checking environment
2024-01-03 18:31:45,313:INFO:python_version: 3.11.5
2024-01-03 18:31:45,313:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:31:45,313:INFO:machine: AMD64
2024-01-03 18:31:45,313:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:31:45,313:INFO:Memory: svmem(total=16893386752, available=3838423040, percent=77.3, used=13054963712, free=3838423040)
2024-01-03 18:31:45,313:INFO:Physical Core: 4
2024-01-03 18:31:45,313:INFO:Logical Core: 8
2024-01-03 18:31:45,313:INFO:Checking libraries
2024-01-03 18:31:45,313:INFO:System:
2024-01-03 18:31:45,313:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:31:45,313:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:31:45,313:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:31:45,313:INFO:PyCaret required dependencies:
2024-01-03 18:31:45,313:INFO:                 pip: 23.3.1
2024-01-03 18:31:45,313:INFO:          setuptools: 68.2.2
2024-01-03 18:31:45,313:INFO:             pycaret: 3.2.0
2024-01-03 18:31:45,313:INFO:             IPython: 8.15.0
2024-01-03 18:31:45,314:INFO:          ipywidgets: 8.0.4
2024-01-03 18:31:45,314:INFO:                tqdm: 4.66.1
2024-01-03 18:31:45,314:INFO:               numpy: 1.25.2
2024-01-03 18:31:45,314:INFO:              pandas: 1.5.3
2024-01-03 18:31:45,314:INFO:              jinja2: 3.1.2
2024-01-03 18:31:45,314:INFO:               scipy: 1.10.1
2024-01-03 18:31:45,314:INFO:              joblib: 1.2.0
2024-01-03 18:31:45,314:INFO:             sklearn: 1.2.2
2024-01-03 18:31:45,314:INFO:                pyod: 1.1.2
2024-01-03 18:31:45,314:INFO:            imblearn: 0.11.0
2024-01-03 18:31:45,314:INFO:   category_encoders: 2.6.3
2024-01-03 18:31:45,314:INFO:            lightgbm: 4.2.0
2024-01-03 18:31:45,314:INFO:               numba: 0.58.1
2024-01-03 18:31:45,314:INFO:            requests: 2.31.0
2024-01-03 18:31:45,314:INFO:          matplotlib: 3.6.0
2024-01-03 18:31:45,314:INFO:          scikitplot: 0.3.7
2024-01-03 18:31:45,314:INFO:         yellowbrick: 1.5
2024-01-03 18:31:45,314:INFO:              plotly: 5.18.0
2024-01-03 18:31:45,314:INFO:    plotly-resampler: Not installed
2024-01-03 18:31:45,314:INFO:             kaleido: 0.2.1
2024-01-03 18:31:45,314:INFO:           schemdraw: 0.15
2024-01-03 18:31:45,314:INFO:         statsmodels: 0.14.1
2024-01-03 18:31:45,314:INFO:              sktime: 0.21.1
2024-01-03 18:31:45,314:INFO:               tbats: 1.1.3
2024-01-03 18:31:45,314:INFO:            pmdarima: 2.0.4
2024-01-03 18:31:45,314:INFO:              psutil: 5.9.0
2024-01-03 18:31:45,314:INFO:          markupsafe: 2.1.1
2024-01-03 18:31:45,314:INFO:             pickle5: Not installed
2024-01-03 18:31:45,314:INFO:         cloudpickle: 3.0.0
2024-01-03 18:31:45,314:INFO:         deprecation: 2.1.0
2024-01-03 18:31:45,314:INFO:              xxhash: 3.4.1
2024-01-03 18:31:45,314:INFO:           wurlitzer: Not installed
2024-01-03 18:31:45,314:INFO:PyCaret optional dependencies:
2024-01-03 18:31:45,315:INFO:                shap: Not installed
2024-01-03 18:31:45,315:INFO:           interpret: Not installed
2024-01-03 18:31:45,315:INFO:                umap: Not installed
2024-01-03 18:31:45,315:INFO:     ydata_profiling: Not installed
2024-01-03 18:31:45,315:INFO:  explainerdashboard: Not installed
2024-01-03 18:31:45,315:INFO:             autoviz: Not installed
2024-01-03 18:31:45,315:INFO:           fairlearn: Not installed
2024-01-03 18:31:45,315:INFO:          deepchecks: Not installed
2024-01-03 18:31:45,315:INFO:             xgboost: Not installed
2024-01-03 18:31:45,315:INFO:            catboost: Not installed
2024-01-03 18:31:45,315:INFO:              kmodes: Not installed
2024-01-03 18:31:45,315:INFO:             mlxtend: 0.23.0
2024-01-03 18:31:45,315:INFO:       statsforecast: Not installed
2024-01-03 18:31:45,315:INFO:        tune_sklearn: Not installed
2024-01-03 18:31:45,315:INFO:                 ray: Not installed
2024-01-03 18:31:45,315:INFO:            hyperopt: Not installed
2024-01-03 18:31:45,315:INFO:              optuna: Not installed
2024-01-03 18:31:45,315:INFO:               skopt: Not installed
2024-01-03 18:31:45,315:INFO:              mlflow: Not installed
2024-01-03 18:31:45,315:INFO:              gradio: Not installed
2024-01-03 18:31:45,315:INFO:             fastapi: Not installed
2024-01-03 18:31:45,315:INFO:             uvicorn: Not installed
2024-01-03 18:31:45,315:INFO:              m2cgen: Not installed
2024-01-03 18:31:45,315:INFO:           evidently: Not installed
2024-01-03 18:31:45,315:INFO:               fugue: Not installed
2024-01-03 18:31:45,315:INFO:           streamlit: Not installed
2024-01-03 18:31:45,315:INFO:             prophet: Not installed
2024-01-03 18:31:45,315:INFO:None
2024-01-03 18:31:45,315:INFO:Set up data.
2024-01-03 18:33:06,595:INFO:PyCaret ClassificationExperiment
2024-01-03 18:33:06,595:INFO:Logging name: clf-default-name
2024-01-03 18:33:06,595:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:33:06,595:INFO:version 3.2.0
2024-01-03 18:33:06,595:INFO:Initializing setup()
2024-01-03 18:33:06,595:INFO:self.USI: ff63
2024-01-03 18:33:06,595:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:33:06,595:INFO:Checking environment
2024-01-03 18:33:06,595:INFO:python_version: 3.11.5
2024-01-03 18:33:06,595:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:33:06,596:INFO:machine: AMD64
2024-01-03 18:33:06,596:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:33:06,596:INFO:Memory: svmem(total=16893386752, available=3623231488, percent=78.6, used=13270155264, free=3623231488)
2024-01-03 18:33:06,596:INFO:Physical Core: 4
2024-01-03 18:33:06,596:INFO:Logical Core: 8
2024-01-03 18:33:06,596:INFO:Checking libraries
2024-01-03 18:33:06,596:INFO:System:
2024-01-03 18:33:06,596:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:33:06,596:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:33:06,596:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:33:06,596:INFO:PyCaret required dependencies:
2024-01-03 18:33:06,596:INFO:                 pip: 23.3.1
2024-01-03 18:33:06,596:INFO:          setuptools: 68.2.2
2024-01-03 18:33:06,596:INFO:             pycaret: 3.2.0
2024-01-03 18:33:06,596:INFO:             IPython: 8.15.0
2024-01-03 18:33:06,596:INFO:          ipywidgets: 8.0.4
2024-01-03 18:33:06,596:INFO:                tqdm: 4.66.1
2024-01-03 18:33:06,596:INFO:               numpy: 1.25.2
2024-01-03 18:33:06,596:INFO:              pandas: 1.5.3
2024-01-03 18:33:06,596:INFO:              jinja2: 3.1.2
2024-01-03 18:33:06,596:INFO:               scipy: 1.10.1
2024-01-03 18:33:06,596:INFO:              joblib: 1.2.0
2024-01-03 18:33:06,596:INFO:             sklearn: 1.2.2
2024-01-03 18:33:06,596:INFO:                pyod: 1.1.2
2024-01-03 18:33:06,597:INFO:            imblearn: 0.11.0
2024-01-03 18:33:06,597:INFO:   category_encoders: 2.6.3
2024-01-03 18:33:06,597:INFO:            lightgbm: 4.2.0
2024-01-03 18:33:06,597:INFO:               numba: 0.58.1
2024-01-03 18:33:06,597:INFO:            requests: 2.31.0
2024-01-03 18:33:06,597:INFO:          matplotlib: 3.6.0
2024-01-03 18:33:06,597:INFO:          scikitplot: 0.3.7
2024-01-03 18:33:06,597:INFO:         yellowbrick: 1.5
2024-01-03 18:33:06,597:INFO:              plotly: 5.18.0
2024-01-03 18:33:06,597:INFO:    plotly-resampler: Not installed
2024-01-03 18:33:06,597:INFO:             kaleido: 0.2.1
2024-01-03 18:33:06,597:INFO:           schemdraw: 0.15
2024-01-03 18:33:06,597:INFO:         statsmodels: 0.14.1
2024-01-03 18:33:06,597:INFO:              sktime: 0.21.1
2024-01-03 18:33:06,597:INFO:               tbats: 1.1.3
2024-01-03 18:33:06,597:INFO:            pmdarima: 2.0.4
2024-01-03 18:33:06,597:INFO:              psutil: 5.9.0
2024-01-03 18:33:06,597:INFO:          markupsafe: 2.1.1
2024-01-03 18:33:06,597:INFO:             pickle5: Not installed
2024-01-03 18:33:06,597:INFO:         cloudpickle: 3.0.0
2024-01-03 18:33:06,597:INFO:         deprecation: 2.1.0
2024-01-03 18:33:06,597:INFO:              xxhash: 3.4.1
2024-01-03 18:33:06,597:INFO:           wurlitzer: Not installed
2024-01-03 18:33:06,597:INFO:PyCaret optional dependencies:
2024-01-03 18:33:06,597:INFO:                shap: Not installed
2024-01-03 18:33:06,597:INFO:           interpret: Not installed
2024-01-03 18:33:06,597:INFO:                umap: Not installed
2024-01-03 18:33:06,597:INFO:     ydata_profiling: Not installed
2024-01-03 18:33:06,597:INFO:  explainerdashboard: Not installed
2024-01-03 18:33:06,597:INFO:             autoviz: Not installed
2024-01-03 18:33:06,597:INFO:           fairlearn: Not installed
2024-01-03 18:33:06,598:INFO:          deepchecks: Not installed
2024-01-03 18:33:06,598:INFO:             xgboost: Not installed
2024-01-03 18:33:06,598:INFO:            catboost: Not installed
2024-01-03 18:33:06,598:INFO:              kmodes: Not installed
2024-01-03 18:33:06,598:INFO:             mlxtend: 0.23.0
2024-01-03 18:33:06,598:INFO:       statsforecast: Not installed
2024-01-03 18:33:06,598:INFO:        tune_sklearn: Not installed
2024-01-03 18:33:06,598:INFO:                 ray: Not installed
2024-01-03 18:33:06,598:INFO:            hyperopt: Not installed
2024-01-03 18:33:06,598:INFO:              optuna: Not installed
2024-01-03 18:33:06,598:INFO:               skopt: Not installed
2024-01-03 18:33:06,598:INFO:              mlflow: Not installed
2024-01-03 18:33:06,598:INFO:              gradio: Not installed
2024-01-03 18:33:06,598:INFO:             fastapi: Not installed
2024-01-03 18:33:06,598:INFO:             uvicorn: Not installed
2024-01-03 18:33:06,598:INFO:              m2cgen: Not installed
2024-01-03 18:33:06,598:INFO:           evidently: Not installed
2024-01-03 18:33:06,598:INFO:               fugue: Not installed
2024-01-03 18:33:06,598:INFO:           streamlit: Not installed
2024-01-03 18:33:06,598:INFO:             prophet: Not installed
2024-01-03 18:33:06,598:INFO:None
2024-01-03 18:33:06,598:INFO:Set up data.
2024-01-03 18:33:06,620:INFO:Set up folding strategy.
2024-01-03 18:33:06,620:INFO:Set up train/test split.
2024-01-03 18:33:06,647:INFO:Set up index.
2024-01-03 18:33:06,647:INFO:Assigning column types.
2024-01-03 18:33:06,651:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:33:06,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:33:06,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:33:06,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:33:06,768:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:33:06,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,789:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:33:06,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:33:06,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,879:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:33:06,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,902:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:33:06,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:06,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:07,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:07,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:07,008:INFO:Preparing preprocessing pipeline...
2024-01-03 18:33:07,009:INFO:Set up label encoding.
2024-01-03 18:33:07,009:INFO:Set up simple imputation.
2024-01-03 18:33:07,010:INFO:Set up encoding of categorical features.
2024-01-03 18:33:07,095:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:33:07,105:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:33:07,105:INFO:Creating final display dataframe.
2024-01-03 18:33:07,364:INFO:Setup _display_container:                     Description             Value
0                    Session id              7010
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (14483, 2)
5        Transformed data shape        (14483, 2)
6   Transformed train set shape        (10138, 2)
7    Transformed test set shape         (4345, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              ff63
2024-01-03 18:33:07,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:07,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:07,477:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:07,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:33:07,478:INFO:setup() successfully completed in 0.88s...............
2024-01-03 18:33:07,478:INFO:Initializing compare_models()
2024-01-03 18:33:07,478:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-03 18:33:07,478:INFO:Checking exceptions
2024-01-03 18:33:07,480:INFO:Preparing display monitor
2024-01-03 18:33:07,502:INFO:Initializing Logistic Regression
2024-01-03 18:33:07,502:INFO:Total runtime is 0.0 minutes
2024-01-03 18:33:07,506:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:07,507:INFO:Initializing create_model()
2024-01-03 18:33:07,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:07,507:INFO:Checking exceptions
2024-01-03 18:33:07,507:INFO:Importing libraries
2024-01-03 18:33:07,507:INFO:Copying training dataset
2024-01-03 18:33:07,510:INFO:Defining folds
2024-01-03 18:33:07,510:INFO:Declaring metric variables
2024-01-03 18:33:07,513:INFO:Importing untrained model
2024-01-03 18:33:07,516:INFO:Logistic Regression Imported successfully
2024-01-03 18:33:07,522:INFO:Starting cross validation
2024-01-03 18:33:07,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:11,308:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,319:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,322:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,323:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,325:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,328:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,330:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,332:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,333:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,346:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,382:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,393:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,400:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,407:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,425:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,437:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,443:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,447:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,460:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,471:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,473:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,481:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,484:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,489:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,491:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,495:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,496:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,499:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,509:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,516:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,521:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,526:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,526:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,529:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:11,530:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,532:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:11,545:INFO:Calculating mean and std
2024-01-03 18:33:11,545:INFO:Creating metrics dataframe
2024-01-03 18:33:11,548:INFO:Uploading results into container
2024-01-03 18:33:11,549:INFO:Uploading model into container now
2024-01-03 18:33:11,549:INFO:_master_model_container: 1
2024-01-03 18:33:11,549:INFO:_display_container: 2
2024-01-03 18:33:11,550:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7010, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 18:33:11,550:INFO:create_model() successfully completed......................................
2024-01-03 18:33:11,814:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:11,814:INFO:Creating metrics dataframe
2024-01-03 18:33:11,821:INFO:Initializing K Neighbors Classifier
2024-01-03 18:33:11,821:INFO:Total runtime is 0.07198025782903035 minutes
2024-01-03 18:33:11,824:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:11,824:INFO:Initializing create_model()
2024-01-03 18:33:11,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:11,824:INFO:Checking exceptions
2024-01-03 18:33:11,824:INFO:Importing libraries
2024-01-03 18:33:11,824:INFO:Copying training dataset
2024-01-03 18:33:11,828:INFO:Defining folds
2024-01-03 18:33:11,828:INFO:Declaring metric variables
2024-01-03 18:33:11,831:INFO:Importing untrained model
2024-01-03 18:33:11,833:INFO:K Neighbors Classifier Imported successfully
2024-01-03 18:33:11,839:INFO:Starting cross validation
2024-01-03 18:33:11,840:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:12,283:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,286:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,293:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,297:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,299:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,303:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,303:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,307:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,395:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,397:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,398:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,406:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,407:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,409:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,412:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,413:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,416:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,416:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,419:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,420:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,489:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,494:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,502:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,508:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,508:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,511:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,513:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,517:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,535:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,545:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,549:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,554:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,672:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,678:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,682:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,686:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,756:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,761:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,764:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:12,766:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:12,774:INFO:Calculating mean and std
2024-01-03 18:33:12,775:INFO:Creating metrics dataframe
2024-01-03 18:33:12,778:INFO:Uploading results into container
2024-01-03 18:33:12,778:INFO:Uploading model into container now
2024-01-03 18:33:12,779:INFO:_master_model_container: 2
2024-01-03 18:33:12,779:INFO:_display_container: 2
2024-01-03 18:33:12,779:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 18:33:12,779:INFO:create_model() successfully completed......................................
2024-01-03 18:33:13,040:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:13,040:INFO:Creating metrics dataframe
2024-01-03 18:33:13,047:INFO:Initializing Naive Bayes
2024-01-03 18:33:13,047:INFO:Total runtime is 0.09241614341735839 minutes
2024-01-03 18:33:13,049:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:13,049:INFO:Initializing create_model()
2024-01-03 18:33:13,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:13,049:INFO:Checking exceptions
2024-01-03 18:33:13,049:INFO:Importing libraries
2024-01-03 18:33:13,049:INFO:Copying training dataset
2024-01-03 18:33:13,053:INFO:Defining folds
2024-01-03 18:33:13,053:INFO:Declaring metric variables
2024-01-03 18:33:13,056:INFO:Importing untrained model
2024-01-03 18:33:13,059:INFO:Naive Bayes Imported successfully
2024-01-03 18:33:13,064:INFO:Starting cross validation
2024-01-03 18:33:13,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:13,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,157:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,159:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,165:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,168:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,170:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,175:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,192:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,198:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,199:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,208:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,209:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,210:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,214:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,216:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,217:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,218:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,223:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,223:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,225:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,225:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,225:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,229:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,231:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,231:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,233:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,235:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,237:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,243:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,247:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,260:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,262:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,266:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,267:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,269:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,271:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,272:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,273:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,281:INFO:Calculating mean and std
2024-01-03 18:33:13,282:INFO:Creating metrics dataframe
2024-01-03 18:33:13,285:INFO:Uploading results into container
2024-01-03 18:33:13,286:INFO:Uploading model into container now
2024-01-03 18:33:13,286:INFO:_master_model_container: 3
2024-01-03 18:33:13,286:INFO:_display_container: 2
2024-01-03 18:33:13,286:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 18:33:13,286:INFO:create_model() successfully completed......................................
2024-01-03 18:33:13,551:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:13,551:INFO:Creating metrics dataframe
2024-01-03 18:33:13,558:INFO:Initializing Decision Tree Classifier
2024-01-03 18:33:13,558:INFO:Total runtime is 0.10093764861424763 minutes
2024-01-03 18:33:13,560:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:13,561:INFO:Initializing create_model()
2024-01-03 18:33:13,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:13,561:INFO:Checking exceptions
2024-01-03 18:33:13,561:INFO:Importing libraries
2024-01-03 18:33:13,561:INFO:Copying training dataset
2024-01-03 18:33:13,566:INFO:Defining folds
2024-01-03 18:33:13,566:INFO:Declaring metric variables
2024-01-03 18:33:13,570:INFO:Importing untrained model
2024-01-03 18:33:13,572:INFO:Decision Tree Classifier Imported successfully
2024-01-03 18:33:13,579:INFO:Starting cross validation
2024-01-03 18:33:13,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:13,735:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,744:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,745:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,747:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,751:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,757:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,762:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,762:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,762:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,765:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,768:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,769:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,769:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,769:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,774:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,774:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,774:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,775:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,779:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,780:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,780:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,785:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,787:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,792:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,793:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,796:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,805:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,806:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,809:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,810:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,813:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,814:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,840:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,844:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,845:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,848:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,849:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,851:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,852:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:13,855:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:13,863:INFO:Calculating mean and std
2024-01-03 18:33:13,864:INFO:Creating metrics dataframe
2024-01-03 18:33:13,866:INFO:Uploading results into container
2024-01-03 18:33:13,866:INFO:Uploading model into container now
2024-01-03 18:33:13,867:INFO:_master_model_container: 4
2024-01-03 18:33:13,867:INFO:_display_container: 2
2024-01-03 18:33:13,867:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7010, splitter='best')
2024-01-03 18:33:13,867:INFO:create_model() successfully completed......................................
2024-01-03 18:33:14,128:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:14,128:INFO:Creating metrics dataframe
2024-01-03 18:33:14,135:INFO:Initializing SVM - Linear Kernel
2024-01-03 18:33:14,135:INFO:Total runtime is 0.11055547793706257 minutes
2024-01-03 18:33:14,138:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:14,138:INFO:Initializing create_model()
2024-01-03 18:33:14,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:14,138:INFO:Checking exceptions
2024-01-03 18:33:14,139:INFO:Importing libraries
2024-01-03 18:33:14,139:INFO:Copying training dataset
2024-01-03 18:33:14,144:INFO:Defining folds
2024-01-03 18:33:14,144:INFO:Declaring metric variables
2024-01-03 18:33:14,147:INFO:Importing untrained model
2024-01-03 18:33:14,150:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 18:33:14,156:INFO:Starting cross validation
2024-01-03 18:33:14,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:14,283:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:33:14,283:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:33:14,284:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:33:14,288:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,288:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,288:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,288:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,289:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:33:14,289:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,291:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:33:14,293:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,295:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,298:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,298:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,298:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,298:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,300:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,302:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:33:14,304:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,304:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,305:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,305:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,305:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,307:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,308:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,308:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,308:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,309:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,309:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,310:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,311:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,313:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,315:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,315:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,318:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,320:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,325:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,330:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,371:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:33:14,373:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,376:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:33:14,378:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,379:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,382:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,383:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,384:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,387:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,389:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,397:INFO:Calculating mean and std
2024-01-03 18:33:14,398:INFO:Creating metrics dataframe
2024-01-03 18:33:14,400:INFO:Uploading results into container
2024-01-03 18:33:14,400:INFO:Uploading model into container now
2024-01-03 18:33:14,401:INFO:_master_model_container: 5
2024-01-03 18:33:14,401:INFO:_display_container: 2
2024-01-03 18:33:14,401:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7010, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 18:33:14,401:INFO:create_model() successfully completed......................................
2024-01-03 18:33:14,662:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:14,662:INFO:Creating metrics dataframe
2024-01-03 18:33:14,669:INFO:Initializing Ridge Classifier
2024-01-03 18:33:14,669:INFO:Total runtime is 0.11944241921106973 minutes
2024-01-03 18:33:14,672:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:14,672:INFO:Initializing create_model()
2024-01-03 18:33:14,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:14,672:INFO:Checking exceptions
2024-01-03 18:33:14,672:INFO:Importing libraries
2024-01-03 18:33:14,673:INFO:Copying training dataset
2024-01-03 18:33:14,676:INFO:Defining folds
2024-01-03 18:33:14,676:INFO:Declaring metric variables
2024-01-03 18:33:14,679:INFO:Importing untrained model
2024-01-03 18:33:14,682:INFO:Ridge Classifier Imported successfully
2024-01-03 18:33:14,689:INFO:Starting cross validation
2024-01-03 18:33:14,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:14,770:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,774:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,788:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,792:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,792:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,793:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,796:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,798:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,798:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,802:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,805:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,807:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,812:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,813:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,814:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,817:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,818:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,818:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,819:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,820:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,823:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,826:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,832:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,833:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,834:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,838:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,839:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,840:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,844:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,845:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,850:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,850:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,853:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,856:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,857:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,861:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,863:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,866:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,869:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,879:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,881:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,886:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:33:14,888:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,889:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,891:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,894:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,895:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,901:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:14,904:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:14,911:INFO:Calculating mean and std
2024-01-03 18:33:14,912:INFO:Creating metrics dataframe
2024-01-03 18:33:14,915:INFO:Uploading results into container
2024-01-03 18:33:14,915:INFO:Uploading model into container now
2024-01-03 18:33:14,915:INFO:_master_model_container: 6
2024-01-03 18:33:14,915:INFO:_display_container: 2
2024-01-03 18:33:14,916:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7010, solver='auto',
                tol=0.0001)
2024-01-03 18:33:14,916:INFO:create_model() successfully completed......................................
2024-01-03 18:33:15,187:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:15,187:INFO:Creating metrics dataframe
2024-01-03 18:33:15,194:INFO:Initializing Random Forest Classifier
2024-01-03 18:33:15,194:INFO:Total runtime is 0.12820547024408974 minutes
2024-01-03 18:33:15,196:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:15,196:INFO:Initializing create_model()
2024-01-03 18:33:15,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:15,196:INFO:Checking exceptions
2024-01-03 18:33:15,196:INFO:Importing libraries
2024-01-03 18:33:15,197:INFO:Copying training dataset
2024-01-03 18:33:15,201:INFO:Defining folds
2024-01-03 18:33:15,202:INFO:Declaring metric variables
2024-01-03 18:33:15,204:INFO:Importing untrained model
2024-01-03 18:33:15,207:INFO:Random Forest Classifier Imported successfully
2024-01-03 18:33:15,213:INFO:Starting cross validation
2024-01-03 18:33:15,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:15,660:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,675:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,691:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,698:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,698:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,701:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,707:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,707:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:15,707:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,712:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,718:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:15,718:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,719:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:15,721:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,725:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,725:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,728:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:15,730:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:15,735:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,738:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,753:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,763:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,770:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:15,774:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,796:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,804:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,809:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:15,811:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,830:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,837:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,841:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:15,846:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:15,997:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,003:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,006:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,008:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,009:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,013:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,017:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,020:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,028:INFO:Calculating mean and std
2024-01-03 18:33:16,028:INFO:Creating metrics dataframe
2024-01-03 18:33:16,031:INFO:Uploading results into container
2024-01-03 18:33:16,031:INFO:Uploading model into container now
2024-01-03 18:33:16,031:INFO:_master_model_container: 7
2024-01-03 18:33:16,032:INFO:_display_container: 2
2024-01-03 18:33:16,032:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7010, verbose=0, warm_start=False)
2024-01-03 18:33:16,032:INFO:create_model() successfully completed......................................
2024-01-03 18:33:16,298:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:16,298:INFO:Creating metrics dataframe
2024-01-03 18:33:16,307:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 18:33:16,307:INFO:Total runtime is 0.14674349625905353 minutes
2024-01-03 18:33:16,309:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:16,309:INFO:Initializing create_model()
2024-01-03 18:33:16,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:16,309:INFO:Checking exceptions
2024-01-03 18:33:16,309:INFO:Importing libraries
2024-01-03 18:33:16,310:INFO:Copying training dataset
2024-01-03 18:33:16,313:INFO:Defining folds
2024-01-03 18:33:16,313:INFO:Declaring metric variables
2024-01-03 18:33:16,315:INFO:Importing untrained model
2024-01-03 18:33:16,319:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 18:33:16,324:INFO:Starting cross validation
2024-01-03 18:33:16,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:16,420:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,421:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,421:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,430:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,431:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,441:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,442:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,443:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,445:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,448:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,452:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,453:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,455:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,455:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,455:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,456:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,461:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,462:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,462:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,462:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,464:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,466:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,466:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,467:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,467:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,469:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,470:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,474:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,474:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,478:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,481:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,483:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,487:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,487:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,488:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,491:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,495:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,521:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,527:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 18:33:16,533:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,538:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,538:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,541:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,544:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,544:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,547:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,550:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,558:INFO:Calculating mean and std
2024-01-03 18:33:16,559:INFO:Creating metrics dataframe
2024-01-03 18:33:16,561:INFO:Uploading results into container
2024-01-03 18:33:16,561:INFO:Uploading model into container now
2024-01-03 18:33:16,562:INFO:_master_model_container: 8
2024-01-03 18:33:16,562:INFO:_display_container: 2
2024-01-03 18:33:16,562:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 18:33:16,562:INFO:create_model() successfully completed......................................
2024-01-03 18:33:16,810:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:16,810:INFO:Creating metrics dataframe
2024-01-03 18:33:16,820:INFO:Initializing Ada Boost Classifier
2024-01-03 18:33:16,820:INFO:Total runtime is 0.15529908339182533 minutes
2024-01-03 18:33:16,823:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:16,823:INFO:Initializing create_model()
2024-01-03 18:33:16,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:16,824:INFO:Checking exceptions
2024-01-03 18:33:16,824:INFO:Importing libraries
2024-01-03 18:33:16,824:INFO:Copying training dataset
2024-01-03 18:33:16,828:INFO:Defining folds
2024-01-03 18:33:16,828:INFO:Declaring metric variables
2024-01-03 18:33:16,831:INFO:Importing untrained model
2024-01-03 18:33:16,833:INFO:Ada Boost Classifier Imported successfully
2024-01-03 18:33:16,839:INFO:Starting cross validation
2024-01-03 18:33:16,840:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:16,926:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,940:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,945:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,951:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,952:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,956:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,956:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,958:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,962:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,962:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,967:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,967:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,970:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,972:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,973:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,974:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,979:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,979:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,979:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,980:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,980:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,981:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,983:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,987:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,989:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,989:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,992:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:16,995:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:16,996:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,000:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,001:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,034:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,039:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,041:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,042:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,045:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,046:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,049:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,051:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,060:INFO:Calculating mean and std
2024-01-03 18:33:17,061:INFO:Creating metrics dataframe
2024-01-03 18:33:17,063:INFO:Uploading results into container
2024-01-03 18:33:17,063:INFO:Uploading model into container now
2024-01-03 18:33:17,063:INFO:_master_model_container: 9
2024-01-03 18:33:17,063:INFO:_display_container: 2
2024-01-03 18:33:17,064:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7010)
2024-01-03 18:33:17,064:INFO:create_model() successfully completed......................................
2024-01-03 18:33:17,329:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:17,329:INFO:Creating metrics dataframe
2024-01-03 18:33:17,338:INFO:Initializing Gradient Boosting Classifier
2024-01-03 18:33:17,338:INFO:Total runtime is 0.1639362017313639 minutes
2024-01-03 18:33:17,340:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:17,341:INFO:Initializing create_model()
2024-01-03 18:33:17,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:17,341:INFO:Checking exceptions
2024-01-03 18:33:17,341:INFO:Importing libraries
2024-01-03 18:33:17,341:INFO:Copying training dataset
2024-01-03 18:33:17,345:INFO:Defining folds
2024-01-03 18:33:17,345:INFO:Declaring metric variables
2024-01-03 18:33:17,349:INFO:Importing untrained model
2024-01-03 18:33:17,352:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 18:33:17,357:INFO:Starting cross validation
2024-01-03 18:33:17,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:17,675:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,683:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,687:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,690:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,693:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,694:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,698:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,701:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,701:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,706:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,708:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,713:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,717:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,720:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,730:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,731:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,731:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,733:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,734:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,737:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,739:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,743:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,743:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,744:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,744:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,745:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,748:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,750:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,752:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,753:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,754:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,756:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,909:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,911:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,915:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,916:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,920:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,920:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:17,923:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,924:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:17,934:INFO:Calculating mean and std
2024-01-03 18:33:17,935:INFO:Creating metrics dataframe
2024-01-03 18:33:17,938:INFO:Uploading results into container
2024-01-03 18:33:17,938:INFO:Uploading model into container now
2024-01-03 18:33:17,939:INFO:_master_model_container: 10
2024-01-03 18:33:17,939:INFO:_display_container: 2
2024-01-03 18:33:17,939:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 18:33:17,939:INFO:create_model() successfully completed......................................
2024-01-03 18:33:18,190:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:18,191:INFO:Creating metrics dataframe
2024-01-03 18:33:18,198:INFO:Initializing Linear Discriminant Analysis
2024-01-03 18:33:18,198:INFO:Total runtime is 0.1782713691393534 minutes
2024-01-03 18:33:18,201:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:18,201:INFO:Initializing create_model()
2024-01-03 18:33:18,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:18,201:INFO:Checking exceptions
2024-01-03 18:33:18,201:INFO:Importing libraries
2024-01-03 18:33:18,201:INFO:Copying training dataset
2024-01-03 18:33:18,205:INFO:Defining folds
2024-01-03 18:33:18,205:INFO:Declaring metric variables
2024-01-03 18:33:18,208:INFO:Importing untrained model
2024-01-03 18:33:18,211:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 18:33:18,216:INFO:Starting cross validation
2024-01-03 18:33:18,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:18,311:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,313:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,325:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,326:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,332:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,332:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,333:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,337:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,339:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,340:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,346:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,347:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,347:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,351:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,354:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,357:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,357:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,358:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,359:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,360:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,362:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,363:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,366:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,370:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,370:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,371:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,374:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,377:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,380:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,385:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,389:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,393:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,413:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,419:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,421:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,422:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,425:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,427:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,430:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:18,432:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:18,441:INFO:Calculating mean and std
2024-01-03 18:33:18,442:INFO:Creating metrics dataframe
2024-01-03 18:33:18,445:INFO:Uploading results into container
2024-01-03 18:33:18,445:INFO:Uploading model into container now
2024-01-03 18:33:18,445:INFO:_master_model_container: 11
2024-01-03 18:33:18,445:INFO:_display_container: 2
2024-01-03 18:33:18,446:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 18:33:18,446:INFO:create_model() successfully completed......................................
2024-01-03 18:33:18,701:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:18,702:INFO:Creating metrics dataframe
2024-01-03 18:33:18,710:INFO:Initializing Extra Trees Classifier
2024-01-03 18:33:18,710:INFO:Total runtime is 0.18680251042048132 minutes
2024-01-03 18:33:18,712:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:18,713:INFO:Initializing create_model()
2024-01-03 18:33:18,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:18,713:INFO:Checking exceptions
2024-01-03 18:33:18,713:INFO:Importing libraries
2024-01-03 18:33:18,713:INFO:Copying training dataset
2024-01-03 18:33:18,717:INFO:Defining folds
2024-01-03 18:33:18,717:INFO:Declaring metric variables
2024-01-03 18:33:18,720:INFO:Importing untrained model
2024-01-03 18:33:18,724:INFO:Extra Trees Classifier Imported successfully
2024-01-03 18:33:18,728:INFO:Starting cross validation
2024-01-03 18:33:18,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:19,074:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,078:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,088:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,097:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,102:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,102:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,104:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,109:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,122:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,123:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,127:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,134:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,136:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,138:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,143:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,148:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,154:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,163:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,203:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,204:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,214:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,216:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,220:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,222:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,225:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,227:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,279:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,288:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,292:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,296:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,382:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,382:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,387:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,388:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,390:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,392:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:19,393:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,394:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:19,404:INFO:Calculating mean and std
2024-01-03 18:33:19,404:INFO:Creating metrics dataframe
2024-01-03 18:33:19,407:INFO:Uploading results into container
2024-01-03 18:33:19,407:INFO:Uploading model into container now
2024-01-03 18:33:19,408:INFO:_master_model_container: 12
2024-01-03 18:33:19,408:INFO:_display_container: 2
2024-01-03 18:33:19,408:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7010, verbose=0, warm_start=False)
2024-01-03 18:33:19,408:INFO:create_model() successfully completed......................................
2024-01-03 18:33:19,667:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:19,667:INFO:Creating metrics dataframe
2024-01-03 18:33:19,676:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 18:33:19,676:INFO:Total runtime is 0.20289867321650182 minutes
2024-01-03 18:33:19,679:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:19,679:INFO:Initializing create_model()
2024-01-03 18:33:19,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:19,679:INFO:Checking exceptions
2024-01-03 18:33:19,679:INFO:Importing libraries
2024-01-03 18:33:19,679:INFO:Copying training dataset
2024-01-03 18:33:19,683:INFO:Defining folds
2024-01-03 18:33:19,683:INFO:Declaring metric variables
2024-01-03 18:33:19,687:INFO:Importing untrained model
2024-01-03 18:33:19,690:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:33:19,697:INFO:Starting cross validation
2024-01-03 18:33:19,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:20,127:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,128:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,129:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,140:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,145:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,150:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,152:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,152:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,153:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,159:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,164:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,214:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,228:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,236:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,242:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,243:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,253:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,261:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,266:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,309:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,314:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,319:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,325:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,326:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,330:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,331:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,335:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,393:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,403:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,403:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,409:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,409:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,412:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,413:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,427:INFO:Calculating mean and std
2024-01-03 18:33:20,429:INFO:Creating metrics dataframe
2024-01-03 18:33:20,432:INFO:Uploading results into container
2024-01-03 18:33:20,433:INFO:Uploading model into container now
2024-01-03 18:33:20,433:INFO:_master_model_container: 13
2024-01-03 18:33:20,433:INFO:_display_container: 2
2024-01-03 18:33:20,434:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:33:20,434:INFO:create_model() successfully completed......................................
2024-01-03 18:33:20,700:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:20,701:INFO:Creating metrics dataframe
2024-01-03 18:33:20,710:INFO:Initializing Dummy Classifier
2024-01-03 18:33:20,710:INFO:Total runtime is 0.22013770739237462 minutes
2024-01-03 18:33:20,713:INFO:SubProcess create_model() called ==================================
2024-01-03 18:33:20,713:INFO:Initializing create_model()
2024-01-03 18:33:20,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08E20D5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:20,713:INFO:Checking exceptions
2024-01-03 18:33:20,713:INFO:Importing libraries
2024-01-03 18:33:20,713:INFO:Copying training dataset
2024-01-03 18:33:20,716:INFO:Defining folds
2024-01-03 18:33:20,717:INFO:Declaring metric variables
2024-01-03 18:33:20,720:INFO:Importing untrained model
2024-01-03 18:33:20,723:INFO:Dummy Classifier Imported successfully
2024-01-03 18:33:20,728:INFO:Starting cross validation
2024-01-03 18:33:20,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:33:20,820:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,822:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,825:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,832:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,833:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,838:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,839:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,839:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,844:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,844:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,844:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,849:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,850:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,855:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,861:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,864:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,866:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,870:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,872:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,872:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,873:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,875:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,876:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,878:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,880:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,883:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,883:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,890:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,891:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,895:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,897:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,902:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,922:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,923:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,929:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,930:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,935:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,935:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:33:20,938:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,938:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:33:20,947:INFO:Calculating mean and std
2024-01-03 18:33:20,948:INFO:Creating metrics dataframe
2024-01-03 18:33:20,950:INFO:Uploading results into container
2024-01-03 18:33:20,951:INFO:Uploading model into container now
2024-01-03 18:33:20,951:INFO:_master_model_container: 14
2024-01-03 18:33:20,951:INFO:_display_container: 2
2024-01-03 18:33:20,952:INFO:DummyClassifier(constant=None, random_state=7010, strategy='prior')
2024-01-03 18:33:20,952:INFO:create_model() successfully completed......................................
2024-01-03 18:33:21,211:INFO:SubProcess create_model() end ==================================
2024-01-03 18:33:21,211:INFO:Creating metrics dataframe
2024-01-03 18:33:21,228:INFO:Initializing create_model()
2024-01-03 18:33:21,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7010, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:21,228:INFO:Checking exceptions
2024-01-03 18:33:21,229:INFO:Importing libraries
2024-01-03 18:33:21,229:INFO:Copying training dataset
2024-01-03 18:33:21,232:INFO:Defining folds
2024-01-03 18:33:21,232:INFO:Declaring metric variables
2024-01-03 18:33:21,232:INFO:Importing untrained model
2024-01-03 18:33:21,232:INFO:Declaring custom model
2024-01-03 18:33:21,232:INFO:Logistic Regression Imported successfully
2024-01-03 18:33:21,233:INFO:Cross validation set to False
2024-01-03 18:33:21,233:INFO:Fitting Model
2024-01-03 18:33:21,275:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7010, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 18:33:21,275:INFO:create_model() successfully completed......................................
2024-01-03 18:33:21,553:INFO:Initializing create_model()
2024-01-03 18:33:21,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:21,553:INFO:Checking exceptions
2024-01-03 18:33:21,555:INFO:Importing libraries
2024-01-03 18:33:21,555:INFO:Copying training dataset
2024-01-03 18:33:21,558:INFO:Defining folds
2024-01-03 18:33:21,559:INFO:Declaring metric variables
2024-01-03 18:33:21,559:INFO:Importing untrained model
2024-01-03 18:33:21,559:INFO:Declaring custom model
2024-01-03 18:33:21,559:INFO:K Neighbors Classifier Imported successfully
2024-01-03 18:33:21,560:INFO:Cross validation set to False
2024-01-03 18:33:21,560:INFO:Fitting Model
2024-01-03 18:33:21,590:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 18:33:21,590:INFO:create_model() successfully completed......................................
2024-01-03 18:33:21,842:INFO:Initializing create_model()
2024-01-03 18:33:21,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:21,842:INFO:Checking exceptions
2024-01-03 18:33:21,843:INFO:Importing libraries
2024-01-03 18:33:21,843:INFO:Copying training dataset
2024-01-03 18:33:21,846:INFO:Defining folds
2024-01-03 18:33:21,846:INFO:Declaring metric variables
2024-01-03 18:33:21,846:INFO:Importing untrained model
2024-01-03 18:33:21,846:INFO:Declaring custom model
2024-01-03 18:33:21,847:INFO:Naive Bayes Imported successfully
2024-01-03 18:33:21,848:INFO:Cross validation set to False
2024-01-03 18:33:21,848:INFO:Fitting Model
2024-01-03 18:33:21,878:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 18:33:21,878:INFO:create_model() successfully completed......................................
2024-01-03 18:33:22,138:INFO:Initializing create_model()
2024-01-03 18:33:22,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7010, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:22,138:INFO:Checking exceptions
2024-01-03 18:33:22,139:INFO:Importing libraries
2024-01-03 18:33:22,139:INFO:Copying training dataset
2024-01-03 18:33:22,142:INFO:Defining folds
2024-01-03 18:33:22,142:INFO:Declaring metric variables
2024-01-03 18:33:22,142:INFO:Importing untrained model
2024-01-03 18:33:22,142:INFO:Declaring custom model
2024-01-03 18:33:22,143:INFO:Decision Tree Classifier Imported successfully
2024-01-03 18:33:22,143:INFO:Cross validation set to False
2024-01-03 18:33:22,144:INFO:Fitting Model
2024-01-03 18:33:22,172:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7010, splitter='best')
2024-01-03 18:33:22,172:INFO:create_model() successfully completed......................................
2024-01-03 18:33:22,433:INFO:Initializing create_model()
2024-01-03 18:33:22,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08C870A10>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7010, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:33:22,433:INFO:Checking exceptions
2024-01-03 18:33:22,435:INFO:Importing libraries
2024-01-03 18:33:22,435:INFO:Copying training dataset
2024-01-03 18:33:22,440:INFO:Defining folds
2024-01-03 18:33:22,440:INFO:Declaring metric variables
2024-01-03 18:33:22,440:INFO:Importing untrained model
2024-01-03 18:33:22,441:INFO:Declaring custom model
2024-01-03 18:33:22,441:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 18:33:22,442:INFO:Cross validation set to False
2024-01-03 18:33:22,442:INFO:Fitting Model
2024-01-03 18:33:22,473:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7010, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 18:33:22,473:INFO:create_model() successfully completed......................................
2024-01-03 18:33:22,745:INFO:_master_model_container: 14
2024-01-03 18:33:22,745:INFO:_display_container: 2
2024-01-03 18:33:22,746:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7010, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7010, splitter='best'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7010, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-01-03 18:33:22,746:INFO:compare_models() successfully completed......................................
2024-01-03 18:34:20,855:INFO:PyCaret ClassificationExperiment
2024-01-03 18:34:20,855:INFO:Logging name: clf-default-name
2024-01-03 18:34:20,855:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:34:20,855:INFO:version 3.2.0
2024-01-03 18:34:20,855:INFO:Initializing setup()
2024-01-03 18:34:20,855:INFO:self.USI: b936
2024-01-03 18:34:20,856:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:34:20,856:INFO:Checking environment
2024-01-03 18:34:20,856:INFO:python_version: 3.11.5
2024-01-03 18:34:20,856:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:34:20,856:INFO:machine: AMD64
2024-01-03 18:34:20,856:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:34:20,856:INFO:Memory: svmem(total=16893386752, available=2658713600, percent=84.3, used=14234673152, free=2658713600)
2024-01-03 18:34:20,856:INFO:Physical Core: 4
2024-01-03 18:34:20,856:INFO:Logical Core: 8
2024-01-03 18:34:20,856:INFO:Checking libraries
2024-01-03 18:34:20,856:INFO:System:
2024-01-03 18:34:20,856:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:34:20,856:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:34:20,856:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:34:20,856:INFO:PyCaret required dependencies:
2024-01-03 18:34:20,856:INFO:                 pip: 23.3.1
2024-01-03 18:34:20,856:INFO:          setuptools: 68.2.2
2024-01-03 18:34:20,856:INFO:             pycaret: 3.2.0
2024-01-03 18:34:20,856:INFO:             IPython: 8.15.0
2024-01-03 18:34:20,856:INFO:          ipywidgets: 8.0.4
2024-01-03 18:34:20,856:INFO:                tqdm: 4.66.1
2024-01-03 18:34:20,856:INFO:               numpy: 1.25.2
2024-01-03 18:34:20,856:INFO:              pandas: 1.5.3
2024-01-03 18:34:20,856:INFO:              jinja2: 3.1.2
2024-01-03 18:34:20,856:INFO:               scipy: 1.10.1
2024-01-03 18:34:20,857:INFO:              joblib: 1.2.0
2024-01-03 18:34:20,857:INFO:             sklearn: 1.2.2
2024-01-03 18:34:20,857:INFO:                pyod: 1.1.2
2024-01-03 18:34:20,857:INFO:            imblearn: 0.11.0
2024-01-03 18:34:20,857:INFO:   category_encoders: 2.6.3
2024-01-03 18:34:20,857:INFO:            lightgbm: 4.2.0
2024-01-03 18:34:20,857:INFO:               numba: 0.58.1
2024-01-03 18:34:20,857:INFO:            requests: 2.31.0
2024-01-03 18:34:20,857:INFO:          matplotlib: 3.6.0
2024-01-03 18:34:20,857:INFO:          scikitplot: 0.3.7
2024-01-03 18:34:20,857:INFO:         yellowbrick: 1.5
2024-01-03 18:34:20,857:INFO:              plotly: 5.18.0
2024-01-03 18:34:20,857:INFO:    plotly-resampler: Not installed
2024-01-03 18:34:20,857:INFO:             kaleido: 0.2.1
2024-01-03 18:34:20,857:INFO:           schemdraw: 0.15
2024-01-03 18:34:20,857:INFO:         statsmodels: 0.14.1
2024-01-03 18:34:20,857:INFO:              sktime: 0.21.1
2024-01-03 18:34:20,857:INFO:               tbats: 1.1.3
2024-01-03 18:34:20,857:INFO:            pmdarima: 2.0.4
2024-01-03 18:34:20,857:INFO:              psutil: 5.9.0
2024-01-03 18:34:20,857:INFO:          markupsafe: 2.1.1
2024-01-03 18:34:20,857:INFO:             pickle5: Not installed
2024-01-03 18:34:20,857:INFO:         cloudpickle: 3.0.0
2024-01-03 18:34:20,857:INFO:         deprecation: 2.1.0
2024-01-03 18:34:20,857:INFO:              xxhash: 3.4.1
2024-01-03 18:34:20,857:INFO:           wurlitzer: Not installed
2024-01-03 18:34:20,857:INFO:PyCaret optional dependencies:
2024-01-03 18:34:20,857:INFO:                shap: Not installed
2024-01-03 18:34:20,857:INFO:           interpret: Not installed
2024-01-03 18:34:20,857:INFO:                umap: Not installed
2024-01-03 18:34:20,857:INFO:     ydata_profiling: Not installed
2024-01-03 18:34:20,857:INFO:  explainerdashboard: Not installed
2024-01-03 18:34:20,857:INFO:             autoviz: Not installed
2024-01-03 18:34:20,858:INFO:           fairlearn: Not installed
2024-01-03 18:34:20,858:INFO:          deepchecks: Not installed
2024-01-03 18:34:20,858:INFO:             xgboost: Not installed
2024-01-03 18:34:20,858:INFO:            catboost: Not installed
2024-01-03 18:34:20,858:INFO:              kmodes: Not installed
2024-01-03 18:34:20,858:INFO:             mlxtend: 0.23.0
2024-01-03 18:34:20,858:INFO:       statsforecast: Not installed
2024-01-03 18:34:20,858:INFO:        tune_sklearn: Not installed
2024-01-03 18:34:20,858:INFO:                 ray: Not installed
2024-01-03 18:34:20,858:INFO:            hyperopt: Not installed
2024-01-03 18:34:20,858:INFO:              optuna: Not installed
2024-01-03 18:34:20,858:INFO:               skopt: Not installed
2024-01-03 18:34:20,858:INFO:              mlflow: Not installed
2024-01-03 18:34:20,858:INFO:              gradio: Not installed
2024-01-03 18:34:20,858:INFO:             fastapi: Not installed
2024-01-03 18:34:20,858:INFO:             uvicorn: Not installed
2024-01-03 18:34:20,858:INFO:              m2cgen: Not installed
2024-01-03 18:34:20,858:INFO:           evidently: Not installed
2024-01-03 18:34:20,858:INFO:               fugue: Not installed
2024-01-03 18:34:20,858:INFO:           streamlit: Not installed
2024-01-03 18:34:20,858:INFO:             prophet: Not installed
2024-01-03 18:34:20,858:INFO:None
2024-01-03 18:34:20,858:INFO:Set up data.
2024-01-03 18:34:20,882:INFO:Set up folding strategy.
2024-01-03 18:34:20,882:INFO:Set up train/test split.
2024-01-03 18:34:20,909:INFO:Set up index.
2024-01-03 18:34:20,909:INFO:Assigning column types.
2024-01-03 18:34:20,912:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:34:20,972:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:34:20,973:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:34:21,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:34:21,049:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:34:21,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,071:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:34:21,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:34:21,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:34:21,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,182:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:34:21,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,294:INFO:Preparing preprocessing pipeline...
2024-01-03 18:34:21,294:INFO:Set up label encoding.
2024-01-03 18:34:21,294:INFO:Set up simple imputation.
2024-01-03 18:34:21,296:INFO:Set up encoding of categorical features.
2024-01-03 18:34:21,373:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:34:21,378:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:34:21,378:INFO:Creating final display dataframe.
2024-01-03 18:34:21,628:INFO:Setup _display_container:                     Description             Value
0                    Session id              7554
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (14483, 2)
5        Transformed data shape        (14483, 2)
6   Transformed train set shape        (10138, 2)
7    Transformed test set shape         (4345, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              b936
2024-01-03 18:34:21,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,685:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:34:21,742:INFO:setup() successfully completed in 0.89s...............
2024-01-03 18:34:21,742:INFO:Initializing compare_models()
2024-01-03 18:34:21,742:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=10, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 10, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-03 18:34:21,742:INFO:Checking exceptions
2024-01-03 18:34:21,745:INFO:Preparing display monitor
2024-01-03 18:34:21,763:INFO:Initializing Logistic Regression
2024-01-03 18:34:21,763:INFO:Total runtime is 0.0 minutes
2024-01-03 18:34:21,765:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:21,765:INFO:Initializing create_model()
2024-01-03 18:34:21,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:21,766:INFO:Checking exceptions
2024-01-03 18:34:21,766:INFO:Importing libraries
2024-01-03 18:34:21,766:INFO:Copying training dataset
2024-01-03 18:34:21,769:INFO:Defining folds
2024-01-03 18:34:21,769:INFO:Declaring metric variables
2024-01-03 18:34:21,771:INFO:Importing untrained model
2024-01-03 18:34:21,774:INFO:Logistic Regression Imported successfully
2024-01-03 18:34:21,779:INFO:Starting cross validation
2024-01-03 18:34:21,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:21,894:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,897:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,899:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,907:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,908:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,910:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,914:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:21,914:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,916:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:21,917:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,918:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,918:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,921:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:21,922:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,923:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,925:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,927:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,928:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,928:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,929:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:21,930:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,934:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,936:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:21,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,940:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,942:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,942:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,948:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:21,949:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:21,952:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,952:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:21,993:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,000:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,002:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,007:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,008:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,014:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,021:INFO:Calculating mean and std
2024-01-03 18:34:22,022:INFO:Creating metrics dataframe
2024-01-03 18:34:22,024:INFO:Uploading results into container
2024-01-03 18:34:22,024:INFO:Uploading model into container now
2024-01-03 18:34:22,025:INFO:_master_model_container: 1
2024-01-03 18:34:22,025:INFO:_display_container: 2
2024-01-03 18:34:22,025:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7554, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 18:34:22,025:INFO:create_model() successfully completed......................................
2024-01-03 18:34:22,293:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:22,293:INFO:Creating metrics dataframe
2024-01-03 18:34:22,299:INFO:Initializing K Neighbors Classifier
2024-01-03 18:34:22,299:INFO:Total runtime is 0.008927241961161295 minutes
2024-01-03 18:34:22,301:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:22,302:INFO:Initializing create_model()
2024-01-03 18:34:22,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:22,302:INFO:Checking exceptions
2024-01-03 18:34:22,302:INFO:Importing libraries
2024-01-03 18:34:22,302:INFO:Copying training dataset
2024-01-03 18:34:22,306:INFO:Defining folds
2024-01-03 18:34:22,306:INFO:Declaring metric variables
2024-01-03 18:34:22,309:INFO:Importing untrained model
2024-01-03 18:34:22,311:INFO:K Neighbors Classifier Imported successfully
2024-01-03 18:34:22,316:INFO:Starting cross validation
2024-01-03 18:34:22,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:22,832:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,841:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,845:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:22,849:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,873:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,875:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,883:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,884:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,888:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:22,889:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:22,892:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,893:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,953:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,960:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,962:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,968:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:22,969:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,972:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:22,974:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:22,978:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,043:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,051:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,053:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,058:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,061:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,062:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,067:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,071:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,108:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,117:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,125:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,238:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,247:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,255:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,321:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,327:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,332:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,341:INFO:Calculating mean and std
2024-01-03 18:34:23,342:INFO:Creating metrics dataframe
2024-01-03 18:34:23,344:INFO:Uploading results into container
2024-01-03 18:34:23,344:INFO:Uploading model into container now
2024-01-03 18:34:23,345:INFO:_master_model_container: 2
2024-01-03 18:34:23,345:INFO:_display_container: 2
2024-01-03 18:34:23,345:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 18:34:23,345:INFO:create_model() successfully completed......................................
2024-01-03 18:34:23,591:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:23,591:INFO:Creating metrics dataframe
2024-01-03 18:34:23,598:INFO:Initializing Naive Bayes
2024-01-03 18:34:23,598:INFO:Total runtime is 0.030584585666656495 minutes
2024-01-03 18:34:23,600:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:23,600:INFO:Initializing create_model()
2024-01-03 18:34:23,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:23,601:INFO:Checking exceptions
2024-01-03 18:34:23,601:INFO:Importing libraries
2024-01-03 18:34:23,601:INFO:Copying training dataset
2024-01-03 18:34:23,604:INFO:Defining folds
2024-01-03 18:34:23,604:INFO:Declaring metric variables
2024-01-03 18:34:23,606:INFO:Importing untrained model
2024-01-03 18:34:23,609:INFO:Naive Bayes Imported successfully
2024-01-03 18:34:23,616:INFO:Starting cross validation
2024-01-03 18:34:23,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:23,697:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,707:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,708:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,712:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,714:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,718:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,720:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,723:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,726:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,729:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,733:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,734:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,740:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,743:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,745:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,754:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,754:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,755:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,760:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,763:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,763:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,763:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,765:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,767:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,770:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,772:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,776:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:23,780:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,800:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,805:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,808:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,810:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,813:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,818:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:23,825:INFO:Calculating mean and std
2024-01-03 18:34:23,826:INFO:Creating metrics dataframe
2024-01-03 18:34:23,829:INFO:Uploading results into container
2024-01-03 18:34:23,829:INFO:Uploading model into container now
2024-01-03 18:34:23,830:INFO:_master_model_container: 3
2024-01-03 18:34:23,830:INFO:_display_container: 2
2024-01-03 18:34:23,830:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 18:34:23,830:INFO:create_model() successfully completed......................................
2024-01-03 18:34:24,079:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:24,079:INFO:Creating metrics dataframe
2024-01-03 18:34:24,088:INFO:Initializing Decision Tree Classifier
2024-01-03 18:34:24,088:INFO:Total runtime is 0.03874121507008871 minutes
2024-01-03 18:34:24,090:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:24,090:INFO:Initializing create_model()
2024-01-03 18:34:24,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:24,091:INFO:Checking exceptions
2024-01-03 18:34:24,091:INFO:Importing libraries
2024-01-03 18:34:24,091:INFO:Copying training dataset
2024-01-03 18:34:24,094:INFO:Defining folds
2024-01-03 18:34:24,094:INFO:Declaring metric variables
2024-01-03 18:34:24,098:INFO:Importing untrained model
2024-01-03 18:34:24,101:INFO:Decision Tree Classifier Imported successfully
2024-01-03 18:34:24,106:INFO:Starting cross validation
2024-01-03 18:34:24,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:24,193:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,198:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,200:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,204:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,209:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,211:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,211:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,215:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,215:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,216:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,218:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,219:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,219:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,222:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,226:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,226:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,230:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,233:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,236:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,237:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,237:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,237:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,240:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,248:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,248:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,250:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,254:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,258:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,259:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,262:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,266:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,288:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,294:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,295:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,299:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,300:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,305:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,312:INFO:Calculating mean and std
2024-01-03 18:34:24,313:INFO:Creating metrics dataframe
2024-01-03 18:34:24,315:INFO:Uploading results into container
2024-01-03 18:34:24,316:INFO:Uploading model into container now
2024-01-03 18:34:24,316:INFO:_master_model_container: 4
2024-01-03 18:34:24,316:INFO:_display_container: 2
2024-01-03 18:34:24,316:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7554, splitter='best')
2024-01-03 18:34:24,316:INFO:create_model() successfully completed......................................
2024-01-03 18:34:24,558:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:24,559:INFO:Creating metrics dataframe
2024-01-03 18:34:24,565:INFO:Initializing SVM - Linear Kernel
2024-01-03 18:34:24,566:INFO:Total runtime is 0.046712593237559004 minutes
2024-01-03 18:34:24,568:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:24,568:INFO:Initializing create_model()
2024-01-03 18:34:24,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:24,569:INFO:Checking exceptions
2024-01-03 18:34:24,569:INFO:Importing libraries
2024-01-03 18:34:24,569:INFO:Copying training dataset
2024-01-03 18:34:24,573:INFO:Defining folds
2024-01-03 18:34:24,573:INFO:Declaring metric variables
2024-01-03 18:34:24,576:INFO:Importing untrained model
2024-01-03 18:34:24,579:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 18:34:24,585:INFO:Starting cross validation
2024-01-03 18:34:24,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:24,662:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,666:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,676:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,682:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,683:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,684:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,687:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,687:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,688:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,698:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,699:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,699:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,703:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,704:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,706:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,709:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,710:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,710:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,712:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,715:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,715:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,717:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,718:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,721:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,722:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,723:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,725:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,726:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,727:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,734:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,737:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,737:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,739:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,743:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,743:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:24,748:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,761:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,763:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,768:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,771:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:34:24,773:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,774:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,779:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,784:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:24,791:INFO:Calculating mean and std
2024-01-03 18:34:24,792:INFO:Creating metrics dataframe
2024-01-03 18:34:24,795:INFO:Uploading results into container
2024-01-03 18:34:24,795:INFO:Uploading model into container now
2024-01-03 18:34:24,795:INFO:_master_model_container: 5
2024-01-03 18:34:24,795:INFO:_display_container: 2
2024-01-03 18:34:24,796:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7554, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 18:34:24,796:INFO:create_model() successfully completed......................................
2024-01-03 18:34:25,044:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:25,044:INFO:Creating metrics dataframe
2024-01-03 18:34:25,051:INFO:Initializing Ridge Classifier
2024-01-03 18:34:25,051:INFO:Total runtime is 0.05480211575826009 minutes
2024-01-03 18:34:25,053:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:25,054:INFO:Initializing create_model()
2024-01-03 18:34:25,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:25,054:INFO:Checking exceptions
2024-01-03 18:34:25,054:INFO:Importing libraries
2024-01-03 18:34:25,054:INFO:Copying training dataset
2024-01-03 18:34:25,057:INFO:Defining folds
2024-01-03 18:34:25,057:INFO:Declaring metric variables
2024-01-03 18:34:25,060:INFO:Importing untrained model
2024-01-03 18:34:25,063:INFO:Ridge Classifier Imported successfully
2024-01-03 18:34:25,069:INFO:Starting cross validation
2024-01-03 18:34:25,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:25,158:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,163:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,164:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,164:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,165:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,168:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,168:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,169:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,175:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,179:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,179:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,181:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:25,184:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,185:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:25,186:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:25,186:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

er, msg_start, len(result))

2024-01-03 18:34:25,188:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,189:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,190:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,191:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,193:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,194:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,195:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,198:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,201:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:25,204:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,206:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,209:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,213:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,214:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,214:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:25,218:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,218:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,228:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,233:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:25,235:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,251:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,253:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,257:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:34:25,258:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,260:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,264:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,265:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,270:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:25,278:INFO:Calculating mean and std
2024-01-03 18:34:25,279:INFO:Creating metrics dataframe
2024-01-03 18:34:25,281:INFO:Uploading results into container
2024-01-03 18:34:25,282:INFO:Uploading model into container now
2024-01-03 18:34:25,282:INFO:_master_model_container: 6
2024-01-03 18:34:25,282:INFO:_display_container: 2
2024-01-03 18:34:25,283:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7554, solver='auto',
                tol=0.0001)
2024-01-03 18:34:25,283:INFO:create_model() successfully completed......................................
2024-01-03 18:34:25,530:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:25,530:INFO:Creating metrics dataframe
2024-01-03 18:34:25,537:INFO:Initializing Random Forest Classifier
2024-01-03 18:34:25,537:INFO:Total runtime is 0.06289082765579224 minutes
2024-01-03 18:34:25,539:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:25,539:INFO:Initializing create_model()
2024-01-03 18:34:25,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:25,539:INFO:Checking exceptions
2024-01-03 18:34:25,539:INFO:Importing libraries
2024-01-03 18:34:25,540:INFO:Copying training dataset
2024-01-03 18:34:25,543:INFO:Defining folds
2024-01-03 18:34:25,543:INFO:Declaring metric variables
2024-01-03 18:34:25,545:INFO:Importing untrained model
2024-01-03 18:34:25,549:INFO:Random Forest Classifier Imported successfully
2024-01-03 18:34:25,554:INFO:Starting cross validation
2024-01-03 18:34:25,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:25,973:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,001:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,002:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,007:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,012:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,020:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,026:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,027:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,034:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,035:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,035:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,035:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,037:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,043:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,044:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,046:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,051:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,058:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,065:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,069:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,069:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,081:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,092:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,118:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,123:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,123:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,127:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,130:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,131:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,135:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,139:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,309:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,311:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,314:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,317:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,320:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,323:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,331:INFO:Calculating mean and std
2024-01-03 18:34:26,332:INFO:Creating metrics dataframe
2024-01-03 18:34:26,334:INFO:Uploading results into container
2024-01-03 18:34:26,335:INFO:Uploading model into container now
2024-01-03 18:34:26,335:INFO:_master_model_container: 7
2024-01-03 18:34:26,335:INFO:_display_container: 2
2024-01-03 18:34:26,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7554, verbose=0, warm_start=False)
2024-01-03 18:34:26,335:INFO:create_model() successfully completed......................................
2024-01-03 18:34:26,583:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:26,583:INFO:Creating metrics dataframe
2024-01-03 18:34:26,590:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 18:34:26,590:INFO:Total runtime is 0.0804487943649292 minutes
2024-01-03 18:34:26,592:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:26,592:INFO:Initializing create_model()
2024-01-03 18:34:26,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:26,593:INFO:Checking exceptions
2024-01-03 18:34:26,593:INFO:Importing libraries
2024-01-03 18:34:26,593:INFO:Copying training dataset
2024-01-03 18:34:26,596:INFO:Defining folds
2024-01-03 18:34:26,596:INFO:Declaring metric variables
2024-01-03 18:34:26,599:INFO:Importing untrained model
2024-01-03 18:34:26,601:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 18:34:26,608:INFO:Starting cross validation
2024-01-03 18:34:26,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:26,700:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,701:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,706:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,711:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,711:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,717:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,717:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,718:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,722:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,723:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,723:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,727:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,730:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,733:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,735:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,735:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,741:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,741:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,741:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,743:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,744:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,745:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,746:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,750:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,751:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,754:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,755:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,761:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:26,764:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,793:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,798:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,798:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,802:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,802:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,807:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:26,817:INFO:Calculating mean and std
2024-01-03 18:34:26,818:INFO:Creating metrics dataframe
2024-01-03 18:34:26,821:INFO:Uploading results into container
2024-01-03 18:34:26,822:INFO:Uploading model into container now
2024-01-03 18:34:26,822:INFO:_master_model_container: 8
2024-01-03 18:34:26,822:INFO:_display_container: 2
2024-01-03 18:34:26,822:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 18:34:26,822:INFO:create_model() successfully completed......................................
2024-01-03 18:34:27,069:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:27,069:INFO:Creating metrics dataframe
2024-01-03 18:34:27,077:INFO:Initializing Ada Boost Classifier
2024-01-03 18:34:27,077:INFO:Total runtime is 0.08855669101079305 minutes
2024-01-03 18:34:27,080:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:27,080:INFO:Initializing create_model()
2024-01-03 18:34:27,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:27,080:INFO:Checking exceptions
2024-01-03 18:34:27,080:INFO:Importing libraries
2024-01-03 18:34:27,080:INFO:Copying training dataset
2024-01-03 18:34:27,083:INFO:Defining folds
2024-01-03 18:34:27,083:INFO:Declaring metric variables
2024-01-03 18:34:27,086:INFO:Importing untrained model
2024-01-03 18:34:27,089:INFO:Ada Boost Classifier Imported successfully
2024-01-03 18:34:27,095:INFO:Starting cross validation
2024-01-03 18:34:27,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:27,181:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,192:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,199:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:27,204:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,300:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,310:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,321:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,459:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,471:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,477:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:27,481:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,482:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,483:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,489:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,493:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,494:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,498:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,499:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:27,500:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:27,504:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,506:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,508:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,509:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,510:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:27,511:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,515:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,517:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,520:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,523:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,528:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,529:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:27,534:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,624:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,629:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,632:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:27,634:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:27,641:INFO:Calculating mean and std
2024-01-03 18:34:27,642:INFO:Creating metrics dataframe
2024-01-03 18:34:27,645:INFO:Uploading results into container
2024-01-03 18:34:27,645:INFO:Uploading model into container now
2024-01-03 18:34:27,645:INFO:_master_model_container: 9
2024-01-03 18:34:27,645:INFO:_display_container: 2
2024-01-03 18:34:27,646:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7554)
2024-01-03 18:34:27,646:INFO:create_model() successfully completed......................................
2024-01-03 18:34:27,892:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:27,892:INFO:Creating metrics dataframe
2024-01-03 18:34:27,900:INFO:Initializing Gradient Boosting Classifier
2024-01-03 18:34:27,900:INFO:Total runtime is 0.1022778828938802 minutes
2024-01-03 18:34:27,903:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:27,903:INFO:Initializing create_model()
2024-01-03 18:34:27,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:27,903:INFO:Checking exceptions
2024-01-03 18:34:27,903:INFO:Importing libraries
2024-01-03 18:34:27,904:INFO:Copying training dataset
2024-01-03 18:34:27,908:INFO:Defining folds
2024-01-03 18:34:27,908:INFO:Declaring metric variables
2024-01-03 18:34:27,911:INFO:Importing untrained model
2024-01-03 18:34:27,914:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 18:34:27,921:INFO:Starting cross validation
2024-01-03 18:34:27,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:28,272:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,283:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,289:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,294:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,305:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,306:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,308:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,316:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,318:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,319:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,322:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,325:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,326:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,329:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,330:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,331:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,334:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,343:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,344:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,351:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,353:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,353:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,358:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,360:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,361:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,366:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,371:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,373:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,384:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,388:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,390:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,499:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,505:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,510:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,518:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,523:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,529:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,537:INFO:Calculating mean and std
2024-01-03 18:34:28,537:INFO:Creating metrics dataframe
2024-01-03 18:34:28,540:INFO:Uploading results into container
2024-01-03 18:34:28,540:INFO:Uploading model into container now
2024-01-03 18:34:28,540:INFO:_master_model_container: 10
2024-01-03 18:34:28,540:INFO:_display_container: 2
2024-01-03 18:34:28,540:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7554, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 18:34:28,541:INFO:create_model() successfully completed......................................
2024-01-03 18:34:28,783:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:28,783:INFO:Creating metrics dataframe
2024-01-03 18:34:28,791:INFO:Initializing Linear Discriminant Analysis
2024-01-03 18:34:28,791:INFO:Total runtime is 0.11712805032730103 minutes
2024-01-03 18:34:28,793:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:28,794:INFO:Initializing create_model()
2024-01-03 18:34:28,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:28,794:INFO:Checking exceptions
2024-01-03 18:34:28,794:INFO:Importing libraries
2024-01-03 18:34:28,794:INFO:Copying training dataset
2024-01-03 18:34:28,798:INFO:Defining folds
2024-01-03 18:34:28,799:INFO:Declaring metric variables
2024-01-03 18:34:28,802:INFO:Importing untrained model
2024-01-03 18:34:28,804:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 18:34:28,808:INFO:Starting cross validation
2024-01-03 18:34:28,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:28,910:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,910:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,918:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,920:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,921:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,924:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,926:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,926:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,927:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,931:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,931:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,931:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,934:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,934:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,940:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,940:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,941:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,944:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,945:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,948:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,951:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,953:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,955:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,958:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,960:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,962:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,965:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,969:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:28,972:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:28,976:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,000:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,005:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,006:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,014:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,016:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,024:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,033:INFO:Calculating mean and std
2024-01-03 18:34:29,034:INFO:Creating metrics dataframe
2024-01-03 18:34:29,036:INFO:Uploading results into container
2024-01-03 18:34:29,037:INFO:Uploading model into container now
2024-01-03 18:34:29,037:INFO:_master_model_container: 11
2024-01-03 18:34:29,037:INFO:_display_container: 2
2024-01-03 18:34:29,037:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 18:34:29,037:INFO:create_model() successfully completed......................................
2024-01-03 18:34:29,283:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:29,283:INFO:Creating metrics dataframe
2024-01-03 18:34:29,291:INFO:Initializing Extra Trees Classifier
2024-01-03 18:34:29,291:INFO:Total runtime is 0.12546676794687908 minutes
2024-01-03 18:34:29,294:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:29,294:INFO:Initializing create_model()
2024-01-03 18:34:29,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:29,294:INFO:Checking exceptions
2024-01-03 18:34:29,294:INFO:Importing libraries
2024-01-03 18:34:29,295:INFO:Copying training dataset
2024-01-03 18:34:29,298:INFO:Defining folds
2024-01-03 18:34:29,298:INFO:Declaring metric variables
2024-01-03 18:34:29,300:INFO:Importing untrained model
2024-01-03 18:34:29,303:INFO:Extra Trees Classifier Imported successfully
2024-01-03 18:34:29,310:INFO:Starting cross validation
2024-01-03 18:34:29,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:29,651:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,662:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,693:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,695:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,704:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:29,707:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,713:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:29,715:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,718:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,727:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,739:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:29,746:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,750:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,757:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,763:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:29,766:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,768:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,777:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,783:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,784:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:29,789:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,793:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,796:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,802:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,804:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,809:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:29,812:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,836:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,842:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,847:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:29,851:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,973:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,973:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,978:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,978:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,984:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,985:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:29,993:INFO:Calculating mean and std
2024-01-03 18:34:29,994:INFO:Creating metrics dataframe
2024-01-03 18:34:29,996:INFO:Uploading results into container
2024-01-03 18:34:29,997:INFO:Uploading model into container now
2024-01-03 18:34:29,997:INFO:_master_model_container: 12
2024-01-03 18:34:29,997:INFO:_display_container: 2
2024-01-03 18:34:29,997:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7554, verbose=0, warm_start=False)
2024-01-03 18:34:29,998:INFO:create_model() successfully completed......................................
2024-01-03 18:34:30,263:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:30,264:INFO:Creating metrics dataframe
2024-01-03 18:34:30,272:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 18:34:30,272:INFO:Total runtime is 0.14180485804875692 minutes
2024-01-03 18:34:30,275:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:30,275:INFO:Initializing create_model()
2024-01-03 18:34:30,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:30,275:INFO:Checking exceptions
2024-01-03 18:34:30,275:INFO:Importing libraries
2024-01-03 18:34:30,275:INFO:Copying training dataset
2024-01-03 18:34:30,279:INFO:Defining folds
2024-01-03 18:34:30,279:INFO:Declaring metric variables
2024-01-03 18:34:30,282:INFO:Importing untrained model
2024-01-03 18:34:30,285:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:34:30,289:INFO:Starting cross validation
2024-01-03 18:34:30,291:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:30,601:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,613:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:30,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,627:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,630:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,631:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,632:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,636:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:30,638:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:30,641:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,642:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,643:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,648:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:30,653:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,708:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,720:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,726:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:30,727:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,731:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,735:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,738:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,746:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,748:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,753:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:30,754:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,758:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,765:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,775:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,843:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,853:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,853:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,859:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:30,863:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,863:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:30,879:INFO:Calculating mean and std
2024-01-03 18:34:30,880:INFO:Creating metrics dataframe
2024-01-03 18:34:30,885:INFO:Uploading results into container
2024-01-03 18:34:30,886:INFO:Uploading model into container now
2024-01-03 18:34:30,886:INFO:_master_model_container: 13
2024-01-03 18:34:30,887:INFO:_display_container: 2
2024-01-03 18:34:30,887:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7554, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:34:30,887:INFO:create_model() successfully completed......................................
2024-01-03 18:34:31,144:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:31,145:INFO:Creating metrics dataframe
2024-01-03 18:34:31,153:INFO:Initializing Dummy Classifier
2024-01-03 18:34:31,153:INFO:Total runtime is 0.1564905563990275 minutes
2024-01-03 18:34:31,156:INFO:SubProcess create_model() called ==================================
2024-01-03 18:34:31,156:INFO:Initializing create_model()
2024-01-03 18:34:31,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DCE9750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:31,156:INFO:Checking exceptions
2024-01-03 18:34:31,156:INFO:Importing libraries
2024-01-03 18:34:31,156:INFO:Copying training dataset
2024-01-03 18:34:31,159:INFO:Defining folds
2024-01-03 18:34:31,160:INFO:Declaring metric variables
2024-01-03 18:34:31,162:INFO:Importing untrained model
2024-01-03 18:34:31,165:INFO:Dummy Classifier Imported successfully
2024-01-03 18:34:31,172:INFO:Starting cross validation
2024-01-03 18:34:31,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:34:31,244:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,260:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,267:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,272:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,272:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,277:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,284:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,286:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,288:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,290:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,290:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,292:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,295:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,297:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,298:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,301:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,303:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,303:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,305:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,307:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,308:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,308:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,310:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,312:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,312:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,313:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,314:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,315:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,319:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,325:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,331:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,334:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,350:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,355:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,358:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,360:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,366:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,371:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,374:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:34:31,377:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:34:31,385:INFO:Calculating mean and std
2024-01-03 18:34:31,385:INFO:Creating metrics dataframe
2024-01-03 18:34:31,388:INFO:Uploading results into container
2024-01-03 18:34:31,388:INFO:Uploading model into container now
2024-01-03 18:34:31,389:INFO:_master_model_container: 14
2024-01-03 18:34:31,389:INFO:_display_container: 2
2024-01-03 18:34:31,389:INFO:DummyClassifier(constant=None, random_state=7554, strategy='prior')
2024-01-03 18:34:31,389:INFO:create_model() successfully completed......................................
2024-01-03 18:34:31,632:INFO:SubProcess create_model() end ==================================
2024-01-03 18:34:31,632:INFO:Creating metrics dataframe
2024-01-03 18:34:31,647:INFO:Initializing create_model()
2024-01-03 18:34:31,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7554, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:31,647:INFO:Checking exceptions
2024-01-03 18:34:31,648:INFO:Importing libraries
2024-01-03 18:34:31,649:INFO:Copying training dataset
2024-01-03 18:34:31,651:INFO:Defining folds
2024-01-03 18:34:31,651:INFO:Declaring metric variables
2024-01-03 18:34:31,651:INFO:Importing untrained model
2024-01-03 18:34:31,651:INFO:Declaring custom model
2024-01-03 18:34:31,652:INFO:Logistic Regression Imported successfully
2024-01-03 18:34:31,652:INFO:Cross validation set to False
2024-01-03 18:34:31,653:INFO:Fitting Model
2024-01-03 18:34:31,693:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7554, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 18:34:31,693:INFO:create_model() successfully completed......................................
2024-01-03 18:34:31,944:INFO:Initializing create_model()
2024-01-03 18:34:31,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:31,944:INFO:Checking exceptions
2024-01-03 18:34:31,945:INFO:Importing libraries
2024-01-03 18:34:31,945:INFO:Copying training dataset
2024-01-03 18:34:31,949:INFO:Defining folds
2024-01-03 18:34:31,949:INFO:Declaring metric variables
2024-01-03 18:34:31,949:INFO:Importing untrained model
2024-01-03 18:34:31,949:INFO:Declaring custom model
2024-01-03 18:34:31,949:INFO:K Neighbors Classifier Imported successfully
2024-01-03 18:34:31,950:INFO:Cross validation set to False
2024-01-03 18:34:31,950:INFO:Fitting Model
2024-01-03 18:34:31,980:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 18:34:31,980:INFO:create_model() successfully completed......................................
2024-01-03 18:34:32,228:INFO:Initializing create_model()
2024-01-03 18:34:32,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:32,229:INFO:Checking exceptions
2024-01-03 18:34:32,230:INFO:Importing libraries
2024-01-03 18:34:32,231:INFO:Copying training dataset
2024-01-03 18:34:32,235:INFO:Defining folds
2024-01-03 18:34:32,235:INFO:Declaring metric variables
2024-01-03 18:34:32,235:INFO:Importing untrained model
2024-01-03 18:34:32,235:INFO:Declaring custom model
2024-01-03 18:34:32,235:INFO:Naive Bayes Imported successfully
2024-01-03 18:34:32,236:INFO:Cross validation set to False
2024-01-03 18:34:32,236:INFO:Fitting Model
2024-01-03 18:34:32,266:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 18:34:32,267:INFO:create_model() successfully completed......................................
2024-01-03 18:34:32,519:INFO:Initializing create_model()
2024-01-03 18:34:32,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7554, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:32,519:INFO:Checking exceptions
2024-01-03 18:34:32,520:INFO:Importing libraries
2024-01-03 18:34:32,520:INFO:Copying training dataset
2024-01-03 18:34:32,524:INFO:Defining folds
2024-01-03 18:34:32,524:INFO:Declaring metric variables
2024-01-03 18:34:32,524:INFO:Importing untrained model
2024-01-03 18:34:32,524:INFO:Declaring custom model
2024-01-03 18:34:32,524:INFO:Decision Tree Classifier Imported successfully
2024-01-03 18:34:32,525:INFO:Cross validation set to False
2024-01-03 18:34:32,525:INFO:Fitting Model
2024-01-03 18:34:32,552:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7554, splitter='best')
2024-01-03 18:34:32,552:INFO:create_model() successfully completed......................................
2024-01-03 18:34:32,796:INFO:Initializing create_model()
2024-01-03 18:34:32,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7554, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:32,797:INFO:Checking exceptions
2024-01-03 18:34:32,798:INFO:Importing libraries
2024-01-03 18:34:32,798:INFO:Copying training dataset
2024-01-03 18:34:32,802:INFO:Defining folds
2024-01-03 18:34:32,802:INFO:Declaring metric variables
2024-01-03 18:34:32,802:INFO:Importing untrained model
2024-01-03 18:34:32,802:INFO:Declaring custom model
2024-01-03 18:34:32,802:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 18:34:32,803:INFO:Cross validation set to False
2024-01-03 18:34:32,803:INFO:Fitting Model
2024-01-03 18:34:32,834:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7554, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 18:34:32,834:INFO:create_model() successfully completed......................................
2024-01-03 18:34:33,079:INFO:Initializing create_model()
2024-01-03 18:34:33,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7554, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:33,079:INFO:Checking exceptions
2024-01-03 18:34:33,081:INFO:Importing libraries
2024-01-03 18:34:33,081:INFO:Copying training dataset
2024-01-03 18:34:33,084:INFO:Defining folds
2024-01-03 18:34:33,085:INFO:Declaring metric variables
2024-01-03 18:34:33,085:INFO:Importing untrained model
2024-01-03 18:34:33,085:INFO:Declaring custom model
2024-01-03 18:34:33,085:INFO:Ridge Classifier Imported successfully
2024-01-03 18:34:33,086:INFO:Cross validation set to False
2024-01-03 18:34:33,086:INFO:Fitting Model
2024-01-03 18:34:33,116:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7554, solver='auto',
                tol=0.0001)
2024-01-03 18:34:33,116:INFO:create_model() successfully completed......................................
2024-01-03 18:34:33,364:INFO:Initializing create_model()
2024-01-03 18:34:33,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7554, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:33,364:INFO:Checking exceptions
2024-01-03 18:34:33,365:INFO:Importing libraries
2024-01-03 18:34:33,365:INFO:Copying training dataset
2024-01-03 18:34:33,369:INFO:Defining folds
2024-01-03 18:34:33,369:INFO:Declaring metric variables
2024-01-03 18:34:33,369:INFO:Importing untrained model
2024-01-03 18:34:33,369:INFO:Declaring custom model
2024-01-03 18:34:33,370:INFO:Random Forest Classifier Imported successfully
2024-01-03 18:34:33,370:INFO:Cross validation set to False
2024-01-03 18:34:33,370:INFO:Fitting Model
2024-01-03 18:34:33,519:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7554, verbose=0, warm_start=False)
2024-01-03 18:34:33,519:INFO:create_model() successfully completed......................................
2024-01-03 18:34:33,765:INFO:Initializing create_model()
2024-01-03 18:34:33,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:33,766:INFO:Checking exceptions
2024-01-03 18:34:33,767:INFO:Importing libraries
2024-01-03 18:34:33,768:INFO:Copying training dataset
2024-01-03 18:34:33,771:INFO:Defining folds
2024-01-03 18:34:33,771:INFO:Declaring metric variables
2024-01-03 18:34:33,771:INFO:Importing untrained model
2024-01-03 18:34:33,771:INFO:Declaring custom model
2024-01-03 18:34:33,771:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 18:34:33,772:INFO:Cross validation set to False
2024-01-03 18:34:33,772:INFO:Fitting Model
2024-01-03 18:34:33,798:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 18:34:33,799:INFO:create_model() successfully completed......................................
2024-01-03 18:34:34,048:INFO:Initializing create_model()
2024-01-03 18:34:34,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7554, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:34,048:INFO:Checking exceptions
2024-01-03 18:34:34,050:INFO:Importing libraries
2024-01-03 18:34:34,050:INFO:Copying training dataset
2024-01-03 18:34:34,053:INFO:Defining folds
2024-01-03 18:34:34,053:INFO:Declaring metric variables
2024-01-03 18:34:34,053:INFO:Importing untrained model
2024-01-03 18:34:34,053:INFO:Declaring custom model
2024-01-03 18:34:34,054:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 18:34:34,054:INFO:Cross validation set to False
2024-01-03 18:34:34,054:INFO:Fitting Model
2024-01-03 18:34:34,215:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7554, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 18:34:34,215:INFO:create_model() successfully completed......................................
2024-01-03 18:34:34,465:INFO:Initializing create_model()
2024-01-03 18:34:34,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08D823B90>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:34:34,465:INFO:Checking exceptions
2024-01-03 18:34:34,466:INFO:Importing libraries
2024-01-03 18:34:34,466:INFO:Copying training dataset
2024-01-03 18:34:34,469:INFO:Defining folds
2024-01-03 18:34:34,469:INFO:Declaring metric variables
2024-01-03 18:34:34,470:INFO:Importing untrained model
2024-01-03 18:34:34,470:INFO:Declaring custom model
2024-01-03 18:34:34,470:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 18:34:34,471:INFO:Cross validation set to False
2024-01-03 18:34:34,471:INFO:Fitting Model
2024-01-03 18:34:34,498:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 18:34:34,498:INFO:create_model() successfully completed......................................
2024-01-03 18:34:34,758:INFO:_master_model_container: 14
2024-01-03 18:34:34,758:INFO:_display_container: 2
2024-01-03 18:34:34,760:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7554, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7554, splitter='best'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7554, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7554, solver='auto',
                tol=0.0001), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7554, verbose=0, warm_start=False), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7554, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2024-01-03 18:34:34,760:INFO:compare_models() successfully completed......................................
2024-01-03 18:36:17,586:INFO:PyCaret ClassificationExperiment
2024-01-03 18:36:17,586:INFO:Logging name: clf-default-name
2024-01-03 18:36:17,586:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:36:17,586:INFO:version 3.2.0
2024-01-03 18:36:17,586:INFO:Initializing setup()
2024-01-03 18:36:17,587:INFO:self.USI: 2246
2024-01-03 18:36:17,587:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:36:17,587:INFO:Checking environment
2024-01-03 18:36:17,587:INFO:python_version: 3.11.5
2024-01-03 18:36:17,587:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:36:17,587:INFO:machine: AMD64
2024-01-03 18:36:17,587:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:36:17,587:INFO:Memory: svmem(total=16893386752, available=2723528704, percent=83.9, used=14169858048, free=2723528704)
2024-01-03 18:36:17,587:INFO:Physical Core: 4
2024-01-03 18:36:17,587:INFO:Logical Core: 8
2024-01-03 18:36:17,587:INFO:Checking libraries
2024-01-03 18:36:17,587:INFO:System:
2024-01-03 18:36:17,587:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:36:17,587:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:36:17,587:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:36:17,587:INFO:PyCaret required dependencies:
2024-01-03 18:36:17,587:INFO:                 pip: 23.3.1
2024-01-03 18:36:17,587:INFO:          setuptools: 68.2.2
2024-01-03 18:36:17,587:INFO:             pycaret: 3.2.0
2024-01-03 18:36:17,587:INFO:             IPython: 8.15.0
2024-01-03 18:36:17,587:INFO:          ipywidgets: 8.0.4
2024-01-03 18:36:17,587:INFO:                tqdm: 4.66.1
2024-01-03 18:36:17,588:INFO:               numpy: 1.25.2
2024-01-03 18:36:17,588:INFO:              pandas: 1.5.3
2024-01-03 18:36:17,588:INFO:              jinja2: 3.1.2
2024-01-03 18:36:17,588:INFO:               scipy: 1.10.1
2024-01-03 18:36:17,588:INFO:              joblib: 1.2.0
2024-01-03 18:36:17,588:INFO:             sklearn: 1.2.2
2024-01-03 18:36:17,588:INFO:                pyod: 1.1.2
2024-01-03 18:36:17,588:INFO:            imblearn: 0.11.0
2024-01-03 18:36:17,588:INFO:   category_encoders: 2.6.3
2024-01-03 18:36:17,588:INFO:            lightgbm: 4.2.0
2024-01-03 18:36:17,588:INFO:               numba: 0.58.1
2024-01-03 18:36:17,588:INFO:            requests: 2.31.0
2024-01-03 18:36:17,588:INFO:          matplotlib: 3.6.0
2024-01-03 18:36:17,588:INFO:          scikitplot: 0.3.7
2024-01-03 18:36:17,588:INFO:         yellowbrick: 1.5
2024-01-03 18:36:17,589:INFO:              plotly: 5.18.0
2024-01-03 18:36:17,589:INFO:    plotly-resampler: Not installed
2024-01-03 18:36:17,589:INFO:             kaleido: 0.2.1
2024-01-03 18:36:17,589:INFO:           schemdraw: 0.15
2024-01-03 18:36:17,589:INFO:         statsmodels: 0.14.1
2024-01-03 18:36:17,589:INFO:              sktime: 0.21.1
2024-01-03 18:36:17,589:INFO:               tbats: 1.1.3
2024-01-03 18:36:17,589:INFO:            pmdarima: 2.0.4
2024-01-03 18:36:17,589:INFO:              psutil: 5.9.0
2024-01-03 18:36:17,589:INFO:          markupsafe: 2.1.1
2024-01-03 18:36:17,589:INFO:             pickle5: Not installed
2024-01-03 18:36:17,589:INFO:         cloudpickle: 3.0.0
2024-01-03 18:36:17,589:INFO:         deprecation: 2.1.0
2024-01-03 18:36:17,589:INFO:              xxhash: 3.4.1
2024-01-03 18:36:17,589:INFO:           wurlitzer: Not installed
2024-01-03 18:36:17,589:INFO:PyCaret optional dependencies:
2024-01-03 18:36:17,589:INFO:                shap: Not installed
2024-01-03 18:36:17,589:INFO:           interpret: Not installed
2024-01-03 18:36:17,589:INFO:                umap: Not installed
2024-01-03 18:36:17,589:INFO:     ydata_profiling: Not installed
2024-01-03 18:36:17,589:INFO:  explainerdashboard: Not installed
2024-01-03 18:36:17,590:INFO:             autoviz: Not installed
2024-01-03 18:36:17,590:INFO:           fairlearn: Not installed
2024-01-03 18:36:17,590:INFO:          deepchecks: Not installed
2024-01-03 18:36:17,590:INFO:             xgboost: Not installed
2024-01-03 18:36:17,590:INFO:            catboost: Not installed
2024-01-03 18:36:17,590:INFO:              kmodes: Not installed
2024-01-03 18:36:17,590:INFO:             mlxtend: 0.23.0
2024-01-03 18:36:17,590:INFO:       statsforecast: Not installed
2024-01-03 18:36:17,590:INFO:        tune_sklearn: Not installed
2024-01-03 18:36:17,590:INFO:                 ray: Not installed
2024-01-03 18:36:17,590:INFO:            hyperopt: Not installed
2024-01-03 18:36:17,590:INFO:              optuna: Not installed
2024-01-03 18:36:17,590:INFO:               skopt: Not installed
2024-01-03 18:36:17,590:INFO:              mlflow: Not installed
2024-01-03 18:36:17,590:INFO:              gradio: Not installed
2024-01-03 18:36:17,590:INFO:             fastapi: Not installed
2024-01-03 18:36:17,590:INFO:             uvicorn: Not installed
2024-01-03 18:36:17,590:INFO:              m2cgen: Not installed
2024-01-03 18:36:17,590:INFO:           evidently: Not installed
2024-01-03 18:36:17,590:INFO:               fugue: Not installed
2024-01-03 18:36:17,590:INFO:           streamlit: Not installed
2024-01-03 18:36:17,590:INFO:             prophet: Not installed
2024-01-03 18:36:17,591:INFO:None
2024-01-03 18:36:17,591:INFO:Set up data.
2024-01-03 18:36:17,616:INFO:Set up folding strategy.
2024-01-03 18:36:17,616:INFO:Set up train/test split.
2024-01-03 18:36:17,616:INFO:Set up data.
2024-01-03 18:36:17,642:INFO:Set up index.
2024-01-03 18:38:59,103:INFO:PyCaret ClassificationExperiment
2024-01-03 18:38:59,103:INFO:Logging name: clf-default-name
2024-01-03 18:38:59,103:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:38:59,103:INFO:version 3.2.0
2024-01-03 18:38:59,103:INFO:Initializing setup()
2024-01-03 18:38:59,103:INFO:self.USI: 23f4
2024-01-03 18:38:59,104:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:38:59,104:INFO:Checking environment
2024-01-03 18:38:59,104:INFO:python_version: 3.11.5
2024-01-03 18:38:59,104:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:38:59,104:INFO:machine: AMD64
2024-01-03 18:38:59,104:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:38:59,104:INFO:Memory: svmem(total=16893386752, available=3611262976, percent=78.6, used=13282123776, free=3611262976)
2024-01-03 18:38:59,104:INFO:Physical Core: 4
2024-01-03 18:38:59,104:INFO:Logical Core: 8
2024-01-03 18:38:59,104:INFO:Checking libraries
2024-01-03 18:38:59,104:INFO:System:
2024-01-03 18:38:59,104:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:38:59,104:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:38:59,104:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:38:59,104:INFO:PyCaret required dependencies:
2024-01-03 18:38:59,104:INFO:                 pip: 23.3.1
2024-01-03 18:38:59,104:INFO:          setuptools: 68.2.2
2024-01-03 18:38:59,104:INFO:             pycaret: 3.2.0
2024-01-03 18:38:59,104:INFO:             IPython: 8.15.0
2024-01-03 18:38:59,104:INFO:          ipywidgets: 8.0.4
2024-01-03 18:38:59,104:INFO:                tqdm: 4.66.1
2024-01-03 18:38:59,104:INFO:               numpy: 1.25.2
2024-01-03 18:38:59,104:INFO:              pandas: 1.5.3
2024-01-03 18:38:59,104:INFO:              jinja2: 3.1.2
2024-01-03 18:38:59,104:INFO:               scipy: 1.10.1
2024-01-03 18:38:59,104:INFO:              joblib: 1.2.0
2024-01-03 18:38:59,105:INFO:             sklearn: 1.2.2
2024-01-03 18:38:59,105:INFO:                pyod: 1.1.2
2024-01-03 18:38:59,105:INFO:            imblearn: 0.11.0
2024-01-03 18:38:59,105:INFO:   category_encoders: 2.6.3
2024-01-03 18:38:59,105:INFO:            lightgbm: 4.2.0
2024-01-03 18:38:59,105:INFO:               numba: 0.58.1
2024-01-03 18:38:59,105:INFO:            requests: 2.31.0
2024-01-03 18:38:59,105:INFO:          matplotlib: 3.6.0
2024-01-03 18:38:59,105:INFO:          scikitplot: 0.3.7
2024-01-03 18:38:59,105:INFO:         yellowbrick: 1.5
2024-01-03 18:38:59,105:INFO:              plotly: 5.18.0
2024-01-03 18:38:59,105:INFO:    plotly-resampler: Not installed
2024-01-03 18:38:59,105:INFO:             kaleido: 0.2.1
2024-01-03 18:38:59,105:INFO:           schemdraw: 0.15
2024-01-03 18:38:59,105:INFO:         statsmodels: 0.14.1
2024-01-03 18:38:59,105:INFO:              sktime: 0.21.1
2024-01-03 18:38:59,105:INFO:               tbats: 1.1.3
2024-01-03 18:38:59,105:INFO:            pmdarima: 2.0.4
2024-01-03 18:38:59,105:INFO:              psutil: 5.9.0
2024-01-03 18:38:59,105:INFO:          markupsafe: 2.1.1
2024-01-03 18:38:59,105:INFO:             pickle5: Not installed
2024-01-03 18:38:59,105:INFO:         cloudpickle: 3.0.0
2024-01-03 18:38:59,105:INFO:         deprecation: 2.1.0
2024-01-03 18:38:59,105:INFO:              xxhash: 3.4.1
2024-01-03 18:38:59,105:INFO:           wurlitzer: Not installed
2024-01-03 18:38:59,105:INFO:PyCaret optional dependencies:
2024-01-03 18:38:59,105:INFO:                shap: Not installed
2024-01-03 18:38:59,105:INFO:           interpret: Not installed
2024-01-03 18:38:59,105:INFO:                umap: Not installed
2024-01-03 18:38:59,105:INFO:     ydata_profiling: Not installed
2024-01-03 18:38:59,105:INFO:  explainerdashboard: Not installed
2024-01-03 18:38:59,105:INFO:             autoviz: Not installed
2024-01-03 18:38:59,106:INFO:           fairlearn: Not installed
2024-01-03 18:38:59,106:INFO:          deepchecks: Not installed
2024-01-03 18:38:59,106:INFO:             xgboost: Not installed
2024-01-03 18:38:59,106:INFO:            catboost: Not installed
2024-01-03 18:38:59,106:INFO:              kmodes: Not installed
2024-01-03 18:38:59,106:INFO:             mlxtend: 0.23.0
2024-01-03 18:38:59,106:INFO:       statsforecast: Not installed
2024-01-03 18:38:59,106:INFO:        tune_sklearn: Not installed
2024-01-03 18:38:59,106:INFO:                 ray: Not installed
2024-01-03 18:38:59,106:INFO:            hyperopt: Not installed
2024-01-03 18:38:59,106:INFO:              optuna: Not installed
2024-01-03 18:38:59,106:INFO:               skopt: Not installed
2024-01-03 18:38:59,106:INFO:              mlflow: Not installed
2024-01-03 18:38:59,106:INFO:              gradio: Not installed
2024-01-03 18:38:59,106:INFO:             fastapi: Not installed
2024-01-03 18:38:59,106:INFO:             uvicorn: Not installed
2024-01-03 18:38:59,106:INFO:              m2cgen: Not installed
2024-01-03 18:38:59,106:INFO:           evidently: Not installed
2024-01-03 18:38:59,106:INFO:               fugue: Not installed
2024-01-03 18:38:59,106:INFO:           streamlit: Not installed
2024-01-03 18:38:59,106:INFO:             prophet: Not installed
2024-01-03 18:38:59,106:INFO:None
2024-01-03 18:38:59,106:INFO:Set up data.
2024-01-03 18:38:59,122:INFO:Set up folding strategy.
2024-01-03 18:38:59,122:INFO:Set up train/test split.
2024-01-03 18:38:59,146:INFO:Set up index.
2024-01-03 18:38:59,147:INFO:Assigning column types.
2024-01-03 18:38:59,149:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:38:59,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:38:59,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:38:59,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:38:59,267:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:38:59,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,287:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:38:59,319:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:38:59,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,375:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:38:59,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:38:59,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,505:INFO:Preparing preprocessing pipeline...
2024-01-03 18:38:59,506:INFO:Set up label encoding.
2024-01-03 18:38:59,506:INFO:Set up simple imputation.
2024-01-03 18:38:59,507:INFO:Set up encoding of categorical features.
2024-01-03 18:38:59,585:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:38:59,589:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:38:59,589:INFO:Creating final display dataframe.
2024-01-03 18:38:59,836:INFO:Setup _display_container:                     Description             Value
0                    Session id              1857
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (14483, 2)
5        Transformed data shape        (14483, 2)
6   Transformed train set shape        (10138, 2)
7    Transformed test set shape         (4345, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              23f4
2024-01-03 18:38:59,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:38:59,951:INFO:setup() successfully completed in 0.85s...............
2024-01-03 18:38:59,951:INFO:Initializing compare_models()
2024-01-03 18:38:59,951:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-03 18:38:59,951:INFO:Checking exceptions
2024-01-03 18:38:59,954:INFO:Preparing display monitor
2024-01-03 18:38:59,975:INFO:Initializing Logistic Regression
2024-01-03 18:38:59,975:INFO:Total runtime is 0.0 minutes
2024-01-03 18:38:59,978:INFO:SubProcess create_model() called ==================================
2024-01-03 18:38:59,978:INFO:Initializing create_model()
2024-01-03 18:38:59,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:38:59,979:INFO:Checking exceptions
2024-01-03 18:38:59,979:INFO:Importing libraries
2024-01-03 18:38:59,979:INFO:Copying training dataset
2024-01-03 18:38:59,982:INFO:Defining folds
2024-01-03 18:38:59,982:INFO:Declaring metric variables
2024-01-03 18:38:59,985:INFO:Importing untrained model
2024-01-03 18:38:59,987:INFO:Logistic Regression Imported successfully
2024-01-03 18:38:59,991:INFO:Starting cross validation
2024-01-03 18:38:59,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:00,119:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,124:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,125:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,129:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,134:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,134:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,138:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,139:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,140:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,144:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:00,144:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,145:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,154:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,155:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,157:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,157:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,162:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,163:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:00,164:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:00,167:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:00,168:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,171:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,172:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,173:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,184:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,191:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,231:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,236:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,237:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,240:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:00,242:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,242:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,245:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:00,248:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:00,256:INFO:Calculating mean and std
2024-01-03 18:39:00,256:INFO:Creating metrics dataframe
2024-01-03 18:39:00,258:INFO:Uploading results into container
2024-01-03 18:39:00,259:INFO:Uploading model into container now
2024-01-03 18:39:00,259:INFO:_master_model_container: 1
2024-01-03 18:39:00,259:INFO:_display_container: 2
2024-01-03 18:39:00,260:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1857, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 18:39:00,260:INFO:create_model() successfully completed......................................
2024-01-03 18:39:00,531:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:00,532:INFO:Creating metrics dataframe
2024-01-03 18:39:00,537:INFO:Initializing K Neighbors Classifier
2024-01-03 18:39:00,537:INFO:Total runtime is 0.009368689854939778 minutes
2024-01-03 18:39:00,539:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:00,539:INFO:Initializing create_model()
2024-01-03 18:39:00,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:00,539:INFO:Checking exceptions
2024-01-03 18:39:00,539:INFO:Importing libraries
2024-01-03 18:39:00,540:INFO:Copying training dataset
2024-01-03 18:39:00,543:INFO:Defining folds
2024-01-03 18:39:00,543:INFO:Declaring metric variables
2024-01-03 18:39:00,545:INFO:Importing untrained model
2024-01-03 18:39:00,548:INFO:K Neighbors Classifier Imported successfully
2024-01-03 18:39:00,554:INFO:Starting cross validation
2024-01-03 18:39:00,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:01,072:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,081:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,091:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,100:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,109:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,109:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,118:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,121:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,127:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,131:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,196:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,206:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,211:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,215:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,220:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,229:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,231:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,237:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,241:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,248:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,260:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,306:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,314:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,319:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,322:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,380:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,388:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,396:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,524:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,525:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,529:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,530:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,532:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,533:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,535:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,535:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,543:INFO:Calculating mean and std
2024-01-03 18:39:01,544:INFO:Creating metrics dataframe
2024-01-03 18:39:01,546:INFO:Uploading results into container
2024-01-03 18:39:01,546:INFO:Uploading model into container now
2024-01-03 18:39:01,547:INFO:_master_model_container: 2
2024-01-03 18:39:01,547:INFO:_display_container: 2
2024-01-03 18:39:01,547:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 18:39:01,547:INFO:create_model() successfully completed......................................
2024-01-03 18:39:01,791:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:01,792:INFO:Creating metrics dataframe
2024-01-03 18:39:01,798:INFO:Initializing Naive Bayes
2024-01-03 18:39:01,799:INFO:Total runtime is 0.030402656396230063 minutes
2024-01-03 18:39:01,801:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:01,801:INFO:Initializing create_model()
2024-01-03 18:39:01,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:01,801:INFO:Checking exceptions
2024-01-03 18:39:01,801:INFO:Importing libraries
2024-01-03 18:39:01,801:INFO:Copying training dataset
2024-01-03 18:39:01,805:INFO:Defining folds
2024-01-03 18:39:01,805:INFO:Declaring metric variables
2024-01-03 18:39:01,807:INFO:Importing untrained model
2024-01-03 18:39:01,811:INFO:Naive Bayes Imported successfully
2024-01-03 18:39:01,817:INFO:Starting cross validation
2024-01-03 18:39:01,818:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:01,892:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,902:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,904:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,912:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,914:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,919:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,924:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,926:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,929:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,932:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,936:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,937:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,942:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,942:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,945:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,947:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,948:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,948:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,952:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,954:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,955:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,958:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,964:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,965:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,974:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,980:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,986:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,991:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,995:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:01,996:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:01,998:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,001:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,004:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:02,006:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,014:INFO:Calculating mean and std
2024-01-03 18:39:02,015:INFO:Creating metrics dataframe
2024-01-03 18:39:02,018:INFO:Uploading results into container
2024-01-03 18:39:02,019:INFO:Uploading model into container now
2024-01-03 18:39:02,019:INFO:_master_model_container: 3
2024-01-03 18:39:02,019:INFO:_display_container: 2
2024-01-03 18:39:02,020:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 18:39:02,020:INFO:create_model() successfully completed......................................
2024-01-03 18:39:02,282:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:02,282:INFO:Creating metrics dataframe
2024-01-03 18:39:02,290:INFO:Initializing Decision Tree Classifier
2024-01-03 18:39:02,290:INFO:Total runtime is 0.038591925303141275 minutes
2024-01-03 18:39:02,293:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:02,293:INFO:Initializing create_model()
2024-01-03 18:39:02,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:02,294:INFO:Checking exceptions
2024-01-03 18:39:02,294:INFO:Importing libraries
2024-01-03 18:39:02,294:INFO:Copying training dataset
2024-01-03 18:39:02,298:INFO:Defining folds
2024-01-03 18:39:02,298:INFO:Declaring metric variables
2024-01-03 18:39:02,301:INFO:Importing untrained model
2024-01-03 18:39:02,304:INFO:Decision Tree Classifier Imported successfully
2024-01-03 18:39:02,309:INFO:Starting cross validation
2024-01-03 18:39:02,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:02,415:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,422:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,425:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,428:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,428:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,431:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,431:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,433:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,436:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,438:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,438:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,441:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,441:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,444:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:02,446:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,447:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,447:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:02,447:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:02,448:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,450:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,450:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,452:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,452:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,456:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,459:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,462:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:02,466:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,470:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,506:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,511:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,512:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,516:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:02,517:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,518:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,520:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:02,522:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,530:INFO:Calculating mean and std
2024-01-03 18:39:02,531:INFO:Creating metrics dataframe
2024-01-03 18:39:02,533:INFO:Uploading results into container
2024-01-03 18:39:02,534:INFO:Uploading model into container now
2024-01-03 18:39:02,534:INFO:_master_model_container: 4
2024-01-03 18:39:02,534:INFO:_display_container: 2
2024-01-03 18:39:02,534:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1857, splitter='best')
2024-01-03 18:39:02,534:INFO:create_model() successfully completed......................................
2024-01-03 18:39:02,817:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:02,817:INFO:Creating metrics dataframe
2024-01-03 18:39:02,825:INFO:Initializing SVM - Linear Kernel
2024-01-03 18:39:02,825:INFO:Total runtime is 0.04750236670176188 minutes
2024-01-03 18:39:02,827:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:02,827:INFO:Initializing create_model()
2024-01-03 18:39:02,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:02,828:INFO:Checking exceptions
2024-01-03 18:39:02,828:INFO:Importing libraries
2024-01-03 18:39:02,828:INFO:Copying training dataset
2024-01-03 18:39:02,832:INFO:Defining folds
2024-01-03 18:39:02,832:INFO:Declaring metric variables
2024-01-03 18:39:02,835:INFO:Importing untrained model
2024-01-03 18:39:02,838:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 18:39:02,844:INFO:Starting cross validation
2024-01-03 18:39:02,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:02,947:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:02,951:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,961:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:02,963:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,965:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,972:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,972:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:02,975:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,977:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,979:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:02,982:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:02,984:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,986:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,987:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,987:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,993:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:02,996:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,997:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:02,998:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,002:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,005:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:03,007:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,008:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,009:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,020:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:03,021:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,024:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,029:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,035:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,036:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,036:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:03,041:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,044:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,048:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,051:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,060:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,063:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:03,067:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,074:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:39:03,076:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,077:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,080:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,083:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,085:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,088:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,091:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,099:INFO:Calculating mean and std
2024-01-03 18:39:03,100:INFO:Creating metrics dataframe
2024-01-03 18:39:03,103:INFO:Uploading results into container
2024-01-03 18:39:03,103:INFO:Uploading model into container now
2024-01-03 18:39:03,103:INFO:_master_model_container: 5
2024-01-03 18:39:03,104:INFO:_display_container: 2
2024-01-03 18:39:03,104:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1857, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 18:39:03,104:INFO:create_model() successfully completed......................................
2024-01-03 18:39:03,371:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:03,371:INFO:Creating metrics dataframe
2024-01-03 18:39:03,380:INFO:Initializing Ridge Classifier
2024-01-03 18:39:03,380:INFO:Total runtime is 0.05675488313039144 minutes
2024-01-03 18:39:03,382:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:03,382:INFO:Initializing create_model()
2024-01-03 18:39:03,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:03,383:INFO:Checking exceptions
2024-01-03 18:39:03,383:INFO:Importing libraries
2024-01-03 18:39:03,383:INFO:Copying training dataset
2024-01-03 18:39:03,386:INFO:Defining folds
2024-01-03 18:39:03,386:INFO:Declaring metric variables
2024-01-03 18:39:03,389:INFO:Importing untrained model
2024-01-03 18:39:03,391:INFO:Ridge Classifier Imported successfully
2024-01-03 18:39:03,397:INFO:Starting cross validation
2024-01-03 18:39:03,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:03,472:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,475:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,485:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,486:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,490:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,491:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,494:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,495:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,497:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,498:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,501:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,506:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,508:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,512:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

er, msg_start, len(result))

2024-01-03 18:39:03,515:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,517:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,519:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,519:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,520:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,523:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,523:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,527:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,530:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,534:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,535:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,535:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,536:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,537:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,540:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,540:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,540:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,543:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,544:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,544:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,554:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,575:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,577:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,577:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:39:03,580:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,583:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,585:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,586:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,588:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,588:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:03,590:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:03,598:INFO:Calculating mean and std
2024-01-03 18:39:03,599:INFO:Creating metrics dataframe
2024-01-03 18:39:03,601:INFO:Uploading results into container
2024-01-03 18:39:03,601:INFO:Uploading model into container now
2024-01-03 18:39:03,601:INFO:_master_model_container: 6
2024-01-03 18:39:03,601:INFO:_display_container: 2
2024-01-03 18:39:03,602:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1857, solver='auto',
                tol=0.0001)
2024-01-03 18:39:03,602:INFO:create_model() successfully completed......................................
2024-01-03 18:39:03,873:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:03,873:INFO:Creating metrics dataframe
2024-01-03 18:39:03,882:INFO:Initializing Random Forest Classifier
2024-01-03 18:39:03,882:INFO:Total runtime is 0.06512838999430338 minutes
2024-01-03 18:39:03,885:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:03,885:INFO:Initializing create_model()
2024-01-03 18:39:03,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:03,885:INFO:Checking exceptions
2024-01-03 18:39:03,885:INFO:Importing libraries
2024-01-03 18:39:03,885:INFO:Copying training dataset
2024-01-03 18:39:03,888:INFO:Defining folds
2024-01-03 18:39:03,888:INFO:Declaring metric variables
2024-01-03 18:39:03,891:INFO:Importing untrained model
2024-01-03 18:39:03,894:INFO:Random Forest Classifier Imported successfully
2024-01-03 18:39:03,900:INFO:Starting cross validation
2024-01-03 18:39:03,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:04,345:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,356:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,364:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,367:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,368:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,372:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,378:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,382:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,388:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:04,389:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,393:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,401:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,402:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,402:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,411:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,413:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,418:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:04,419:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:04,420:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,422:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,423:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,500:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,511:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,517:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:04,523:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,538:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,549:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,561:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,686:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,691:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,695:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:04,697:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,701:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,706:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,714:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:04,717:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:04,724:INFO:Calculating mean and std
2024-01-03 18:39:04,725:INFO:Creating metrics dataframe
2024-01-03 18:39:04,728:INFO:Uploading results into container
2024-01-03 18:39:04,729:INFO:Uploading model into container now
2024-01-03 18:39:04,729:INFO:_master_model_container: 7
2024-01-03 18:39:04,729:INFO:_display_container: 2
2024-01-03 18:39:04,730:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1857, verbose=0, warm_start=False)
2024-01-03 18:39:04,730:INFO:create_model() successfully completed......................................
2024-01-03 18:39:04,995:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:04,995:INFO:Creating metrics dataframe
2024-01-03 18:39:05,003:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 18:39:05,003:INFO:Total runtime is 0.08381498654683431 minutes
2024-01-03 18:39:05,005:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:05,005:INFO:Initializing create_model()
2024-01-03 18:39:05,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:05,005:INFO:Checking exceptions
2024-01-03 18:39:05,006:INFO:Importing libraries
2024-01-03 18:39:05,006:INFO:Copying training dataset
2024-01-03 18:39:05,009:INFO:Defining folds
2024-01-03 18:39:05,009:INFO:Declaring metric variables
2024-01-03 18:39:05,013:INFO:Importing untrained model
2024-01-03 18:39:05,016:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 18:39:05,022:INFO:Starting cross validation
2024-01-03 18:39:05,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:05,123:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,129:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,136:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,139:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,148:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,150:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,151:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,156:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,158:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,158:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,161:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,167:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,168:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,169:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,171:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,173:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,173:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,174:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,182:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,182:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,187:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,191:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,205:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,215:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,233:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,235:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,238:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,240:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,241:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,243:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,244:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,246:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,254:INFO:Calculating mean and std
2024-01-03 18:39:05,255:INFO:Creating metrics dataframe
2024-01-03 18:39:05,257:INFO:Uploading results into container
2024-01-03 18:39:05,257:INFO:Uploading model into container now
2024-01-03 18:39:05,257:INFO:_master_model_container: 8
2024-01-03 18:39:05,257:INFO:_display_container: 2
2024-01-03 18:39:05,258:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 18:39:05,258:INFO:create_model() successfully completed......................................
2024-01-03 18:39:05,526:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:05,527:INFO:Creating metrics dataframe
2024-01-03 18:39:05,536:INFO:Initializing Ada Boost Classifier
2024-01-03 18:39:05,536:INFO:Total runtime is 0.09268526633580526 minutes
2024-01-03 18:39:05,538:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:05,538:INFO:Initializing create_model()
2024-01-03 18:39:05,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:05,538:INFO:Checking exceptions
2024-01-03 18:39:05,538:INFO:Importing libraries
2024-01-03 18:39:05,538:INFO:Copying training dataset
2024-01-03 18:39:05,541:INFO:Defining folds
2024-01-03 18:39:05,541:INFO:Declaring metric variables
2024-01-03 18:39:05,544:INFO:Importing untrained model
2024-01-03 18:39:05,548:INFO:Ada Boost Classifier Imported successfully
2024-01-03 18:39:05,553:INFO:Starting cross validation
2024-01-03 18:39:05,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:05,749:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,757:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,764:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,770:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,775:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,777:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,782:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,978:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,978:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,979:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,981:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,987:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,989:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,989:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,989:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,994:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:05,996:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,997:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,997:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:05,999:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,000:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:06,001:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,002:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,002:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,004:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,005:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:06,010:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,010:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,021:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,027:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:06,031:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,120:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,126:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,126:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,132:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,132:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,135:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:06,138:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,146:INFO:Calculating mean and std
2024-01-03 18:39:06,147:INFO:Creating metrics dataframe
2024-01-03 18:39:06,149:INFO:Uploading results into container
2024-01-03 18:39:06,150:INFO:Uploading model into container now
2024-01-03 18:39:06,150:INFO:_master_model_container: 9
2024-01-03 18:39:06,150:INFO:_display_container: 2
2024-01-03 18:39:06,150:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1857)
2024-01-03 18:39:06,151:INFO:create_model() successfully completed......................................
2024-01-03 18:39:06,402:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:06,402:INFO:Creating metrics dataframe
2024-01-03 18:39:06,410:INFO:Initializing Gradient Boosting Classifier
2024-01-03 18:39:06,411:INFO:Total runtime is 0.107252569993337 minutes
2024-01-03 18:39:06,414:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:06,415:INFO:Initializing create_model()
2024-01-03 18:39:06,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:06,415:INFO:Checking exceptions
2024-01-03 18:39:06,415:INFO:Importing libraries
2024-01-03 18:39:06,415:INFO:Copying training dataset
2024-01-03 18:39:06,418:INFO:Defining folds
2024-01-03 18:39:06,418:INFO:Declaring metric variables
2024-01-03 18:39:06,421:INFO:Importing untrained model
2024-01-03 18:39:06,424:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 18:39:06,431:INFO:Starting cross validation
2024-01-03 18:39:06,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:06,765:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,770:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,774:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,778:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,781:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,785:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,789:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,789:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,791:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:06,792:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,796:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,801:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,815:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,816:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,822:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,823:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,823:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,829:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,829:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:06,833:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,835:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,836:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,839:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,842:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:06,846:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

er, msg_start, len(result))

2024-01-03 18:39:06,847:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:06,850:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,019:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,021:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,024:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,027:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,028:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:07,031:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,031:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:07,035:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,043:INFO:Calculating mean and std
2024-01-03 18:39:07,044:INFO:Creating metrics dataframe
2024-01-03 18:39:07,047:INFO:Uploading results into container
2024-01-03 18:39:07,048:INFO:Uploading model into container now
2024-01-03 18:39:07,048:INFO:_master_model_container: 10
2024-01-03 18:39:07,048:INFO:_display_container: 2
2024-01-03 18:39:07,049:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1857, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 18:39:07,049:INFO:create_model() successfully completed......................................
2024-01-03 18:39:07,303:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:07,304:INFO:Creating metrics dataframe
2024-01-03 18:39:07,311:INFO:Initializing Linear Discriminant Analysis
2024-01-03 18:39:07,311:INFO:Total runtime is 0.1222736954689026 minutes
2024-01-03 18:39:07,314:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:07,314:INFO:Initializing create_model()
2024-01-03 18:39:07,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:07,314:INFO:Checking exceptions
2024-01-03 18:39:07,314:INFO:Importing libraries
2024-01-03 18:39:07,314:INFO:Copying training dataset
2024-01-03 18:39:07,319:INFO:Defining folds
2024-01-03 18:39:07,319:INFO:Declaring metric variables
2024-01-03 18:39:07,322:INFO:Importing untrained model
2024-01-03 18:39:07,326:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 18:39:07,331:INFO:Starting cross validation
2024-01-03 18:39:07,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:07,422:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,433:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,434:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,444:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,445:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,454:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,455:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,459:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,462:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,467:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,469:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,473:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,473:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:07,479:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,481:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:07,481:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,482:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,486:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,487:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,490:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,495:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:07,499:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:07,500:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,500:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,503:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,509:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,517:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,530:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,535:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,538:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,540:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:07,543:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,546:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,549:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:07,551:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:07,559:INFO:Calculating mean and std
2024-01-03 18:39:07,559:INFO:Creating metrics dataframe
2024-01-03 18:39:07,563:INFO:Uploading results into container
2024-01-03 18:39:07,563:INFO:Uploading model into container now
2024-01-03 18:39:07,563:INFO:_master_model_container: 11
2024-01-03 18:39:07,563:INFO:_display_container: 2
2024-01-03 18:39:07,564:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 18:39:07,564:INFO:create_model() successfully completed......................................
2024-01-03 18:39:07,821:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:07,821:INFO:Creating metrics dataframe
2024-01-03 18:39:07,831:INFO:Initializing Extra Trees Classifier
2024-01-03 18:39:07,831:INFO:Total runtime is 0.13094491163889568 minutes
2024-01-03 18:39:07,833:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:07,834:INFO:Initializing create_model()
2024-01-03 18:39:07,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:07,834:INFO:Checking exceptions
2024-01-03 18:39:07,834:INFO:Importing libraries
2024-01-03 18:39:07,834:INFO:Copying training dataset
2024-01-03 18:39:07,837:INFO:Defining folds
2024-01-03 18:39:07,837:INFO:Declaring metric variables
2024-01-03 18:39:07,840:INFO:Importing untrained model
2024-01-03 18:39:07,842:INFO:Extra Trees Classifier Imported successfully
2024-01-03 18:39:07,849:INFO:Starting cross validation
2024-01-03 18:39:07,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:08,201:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,208:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,211:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,236:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,242:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,247:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,252:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,255:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,257:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,265:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,266:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,271:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:08,277:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,282:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,292:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,295:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,298:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:08,302:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,306:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,312:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:08,317:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,335:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,343:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,346:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:08,350:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,374:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,381:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,390:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,503:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,509:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,510:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,512:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:08,515:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,516:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,519:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:08,521:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:08,529:INFO:Calculating mean and std
2024-01-03 18:39:08,530:INFO:Creating metrics dataframe
2024-01-03 18:39:08,533:INFO:Uploading results into container
2024-01-03 18:39:08,533:INFO:Uploading model into container now
2024-01-03 18:39:08,533:INFO:_master_model_container: 12
2024-01-03 18:39:08,533:INFO:_display_container: 2
2024-01-03 18:39:08,534:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1857, verbose=0, warm_start=False)
2024-01-03 18:39:08,534:INFO:create_model() successfully completed......................................
2024-01-03 18:39:08,786:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:08,786:INFO:Creating metrics dataframe
2024-01-03 18:39:08,795:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 18:39:08,795:INFO:Total runtime is 0.14700085719426476 minutes
2024-01-03 18:39:08,798:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:08,799:INFO:Initializing create_model()
2024-01-03 18:39:08,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:08,799:INFO:Checking exceptions
2024-01-03 18:39:08,799:INFO:Importing libraries
2024-01-03 18:39:08,799:INFO:Copying training dataset
2024-01-03 18:39:08,803:INFO:Defining folds
2024-01-03 18:39:08,804:INFO:Declaring metric variables
2024-01-03 18:39:08,806:INFO:Importing untrained model
2024-01-03 18:39:08,809:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:39:08,816:INFO:Starting cross validation
2024-01-03 18:39:08,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:09,181:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,184:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,193:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,194:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,198:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,201:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,206:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,206:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,206:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,212:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,212:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,217:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,255:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,256:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,269:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,270:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,276:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,277:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,281:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,282:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,329:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,336:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,337:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,339:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,348:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,348:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,349:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,353:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,354:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,358:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,359:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,427:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,437:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,443:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,448:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,448:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,461:INFO:Calculating mean and std
2024-01-03 18:39:09,463:INFO:Creating metrics dataframe
2024-01-03 18:39:09,466:INFO:Uploading results into container
2024-01-03 18:39:09,467:INFO:Uploading model into container now
2024-01-03 18:39:09,467:INFO:_master_model_container: 13
2024-01-03 18:39:09,467:INFO:_display_container: 2
2024-01-03 18:39:09,468:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1857, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:39:09,468:INFO:create_model() successfully completed......................................
2024-01-03 18:39:09,778:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:09,778:INFO:Creating metrics dataframe
2024-01-03 18:39:09,786:INFO:Initializing Dummy Classifier
2024-01-03 18:39:09,786:INFO:Total runtime is 0.16351771354675296 minutes
2024-01-03 18:39:09,788:INFO:SubProcess create_model() called ==================================
2024-01-03 18:39:09,788:INFO:Initializing create_model()
2024-01-03 18:39:09,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DBC4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:09,788:INFO:Checking exceptions
2024-01-03 18:39:09,788:INFO:Importing libraries
2024-01-03 18:39:09,788:INFO:Copying training dataset
2024-01-03 18:39:09,793:INFO:Defining folds
2024-01-03 18:39:09,793:INFO:Declaring metric variables
2024-01-03 18:39:09,795:INFO:Importing untrained model
2024-01-03 18:39:09,798:INFO:Dummy Classifier Imported successfully
2024-01-03 18:39:09,803:INFO:Starting cross validation
2024-01-03 18:39:09,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:39:09,874:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,885:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,891:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,897:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,899:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,902:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,903:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,910:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,913:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,914:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,914:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,917:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,920:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,921:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,922:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,923:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,926:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,926:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,927:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,931:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,933:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,935:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,936:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,937:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,942:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,943:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,943:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,946:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,947:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,951:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,955:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,981:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,989:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,992:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:09,995:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:09,996:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:10,002:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:10,005:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:39:10,007:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:39:10,016:INFO:Calculating mean and std
2024-01-03 18:39:10,017:INFO:Creating metrics dataframe
2024-01-03 18:39:10,019:INFO:Uploading results into container
2024-01-03 18:39:10,020:INFO:Uploading model into container now
2024-01-03 18:39:10,020:INFO:_master_model_container: 14
2024-01-03 18:39:10,020:INFO:_display_container: 2
2024-01-03 18:39:10,020:INFO:DummyClassifier(constant=None, random_state=1857, strategy='prior')
2024-01-03 18:39:10,020:INFO:create_model() successfully completed......................................
2024-01-03 18:39:10,294:INFO:SubProcess create_model() end ==================================
2024-01-03 18:39:10,294:INFO:Creating metrics dataframe
2024-01-03 18:39:10,309:INFO:Initializing create_model()
2024-01-03 18:39:10,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1857, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:10,310:INFO:Checking exceptions
2024-01-03 18:39:10,312:INFO:Importing libraries
2024-01-03 18:39:10,312:INFO:Copying training dataset
2024-01-03 18:39:10,314:INFO:Defining folds
2024-01-03 18:39:10,314:INFO:Declaring metric variables
2024-01-03 18:39:10,315:INFO:Importing untrained model
2024-01-03 18:39:10,315:INFO:Declaring custom model
2024-01-03 18:39:10,315:INFO:Logistic Regression Imported successfully
2024-01-03 18:39:10,316:INFO:Cross validation set to False
2024-01-03 18:39:10,316:INFO:Fitting Model
2024-01-03 18:39:10,355:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1857, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 18:39:10,356:INFO:create_model() successfully completed......................................
2024-01-03 18:39:10,630:INFO:Initializing create_model()
2024-01-03 18:39:10,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:10,630:INFO:Checking exceptions
2024-01-03 18:39:10,632:INFO:Importing libraries
2024-01-03 18:39:10,632:INFO:Copying training dataset
2024-01-03 18:39:10,634:INFO:Defining folds
2024-01-03 18:39:10,634:INFO:Declaring metric variables
2024-01-03 18:39:10,634:INFO:Importing untrained model
2024-01-03 18:39:10,634:INFO:Declaring custom model
2024-01-03 18:39:10,635:INFO:K Neighbors Classifier Imported successfully
2024-01-03 18:39:10,635:INFO:Cross validation set to False
2024-01-03 18:39:10,635:INFO:Fitting Model
2024-01-03 18:39:10,666:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 18:39:10,666:INFO:create_model() successfully completed......................................
2024-01-03 18:39:10,922:INFO:Initializing create_model()
2024-01-03 18:39:10,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1857, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:10,922:INFO:Checking exceptions
2024-01-03 18:39:10,923:INFO:Importing libraries
2024-01-03 18:39:10,923:INFO:Copying training dataset
2024-01-03 18:39:10,926:INFO:Defining folds
2024-01-03 18:39:10,926:INFO:Declaring metric variables
2024-01-03 18:39:10,926:INFO:Importing untrained model
2024-01-03 18:39:10,927:INFO:Declaring custom model
2024-01-03 18:39:10,927:INFO:Decision Tree Classifier Imported successfully
2024-01-03 18:39:10,928:INFO:Cross validation set to False
2024-01-03 18:39:10,928:INFO:Fitting Model
2024-01-03 18:39:10,956:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1857, splitter='best')
2024-01-03 18:39:10,956:INFO:create_model() successfully completed......................................
2024-01-03 18:39:11,220:INFO:Initializing create_model()
2024-01-03 18:39:11,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1857, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:11,220:INFO:Checking exceptions
2024-01-03 18:39:11,222:INFO:Importing libraries
2024-01-03 18:39:11,222:INFO:Copying training dataset
2024-01-03 18:39:11,224:INFO:Defining folds
2024-01-03 18:39:11,224:INFO:Declaring metric variables
2024-01-03 18:39:11,224:INFO:Importing untrained model
2024-01-03 18:39:11,224:INFO:Declaring custom model
2024-01-03 18:39:11,225:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 18:39:11,225:INFO:Cross validation set to False
2024-01-03 18:39:11,226:INFO:Fitting Model
2024-01-03 18:39:11,253:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1857, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 18:39:11,253:INFO:create_model() successfully completed......................................
2024-01-03 18:39:11,509:INFO:Initializing create_model()
2024-01-03 18:39:11,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0FC2EF850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1857, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:11,510:INFO:Checking exceptions
2024-01-03 18:39:11,512:INFO:Importing libraries
2024-01-03 18:39:11,513:INFO:Copying training dataset
2024-01-03 18:39:11,515:INFO:Defining folds
2024-01-03 18:39:11,515:INFO:Declaring metric variables
2024-01-03 18:39:11,515:INFO:Importing untrained model
2024-01-03 18:39:11,516:INFO:Declaring custom model
2024-01-03 18:39:11,516:INFO:Ridge Classifier Imported successfully
2024-01-03 18:39:11,516:INFO:Cross validation set to False
2024-01-03 18:39:11,516:INFO:Fitting Model
2024-01-03 18:39:11,548:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1857, solver='auto',
                tol=0.0001)
2024-01-03 18:39:11,548:INFO:create_model() successfully completed......................................
2024-01-03 18:39:11,812:INFO:_master_model_container: 14
2024-01-03 18:39:11,812:INFO:_display_container: 2
2024-01-03 18:39:11,813:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1857, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1857, splitter='best'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1857, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1857, solver='auto',
                tol=0.0001)]
2024-01-03 18:39:11,813:INFO:compare_models() successfully completed......................................
2024-01-03 18:39:46,730:INFO:PyCaret ClassificationExperiment
2024-01-03 18:39:46,730:INFO:Logging name: clf-default-name
2024-01-03 18:39:46,730:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:39:46,730:INFO:version 3.2.0
2024-01-03 18:39:46,730:INFO:Initializing setup()
2024-01-03 18:39:46,730:INFO:self.USI: 2453
2024-01-03 18:39:46,730:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:39:46,731:INFO:Checking environment
2024-01-03 18:39:46,731:INFO:python_version: 3.11.5
2024-01-03 18:39:46,731:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:39:46,731:INFO:machine: AMD64
2024-01-03 18:39:46,731:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:39:46,731:INFO:Memory: svmem(total=16893386752, available=3648249856, percent=78.4, used=13245136896, free=3648249856)
2024-01-03 18:39:46,731:INFO:Physical Core: 4
2024-01-03 18:39:46,731:INFO:Logical Core: 8
2024-01-03 18:39:46,731:INFO:Checking libraries
2024-01-03 18:39:46,731:INFO:System:
2024-01-03 18:39:46,731:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:39:46,731:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:39:46,731:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:39:46,731:INFO:PyCaret required dependencies:
2024-01-03 18:39:46,731:INFO:                 pip: 23.3.1
2024-01-03 18:39:46,731:INFO:          setuptools: 68.2.2
2024-01-03 18:39:46,731:INFO:             pycaret: 3.2.0
2024-01-03 18:39:46,731:INFO:             IPython: 8.15.0
2024-01-03 18:39:46,731:INFO:          ipywidgets: 8.0.4
2024-01-03 18:39:46,731:INFO:                tqdm: 4.66.1
2024-01-03 18:39:46,731:INFO:               numpy: 1.25.2
2024-01-03 18:39:46,731:INFO:              pandas: 1.5.3
2024-01-03 18:39:46,731:INFO:              jinja2: 3.1.2
2024-01-03 18:39:46,731:INFO:               scipy: 1.10.1
2024-01-03 18:39:46,731:INFO:              joblib: 1.2.0
2024-01-03 18:39:46,731:INFO:             sklearn: 1.2.2
2024-01-03 18:39:46,731:INFO:                pyod: 1.1.2
2024-01-03 18:39:46,731:INFO:            imblearn: 0.11.0
2024-01-03 18:39:46,732:INFO:   category_encoders: 2.6.3
2024-01-03 18:39:46,732:INFO:            lightgbm: 4.2.0
2024-01-03 18:39:46,732:INFO:               numba: 0.58.1
2024-01-03 18:39:46,732:INFO:            requests: 2.31.0
2024-01-03 18:39:46,732:INFO:          matplotlib: 3.6.0
2024-01-03 18:39:46,732:INFO:          scikitplot: 0.3.7
2024-01-03 18:39:46,732:INFO:         yellowbrick: 1.5
2024-01-03 18:39:46,732:INFO:              plotly: 5.18.0
2024-01-03 18:39:46,732:INFO:    plotly-resampler: Not installed
2024-01-03 18:39:46,732:INFO:             kaleido: 0.2.1
2024-01-03 18:39:46,732:INFO:           schemdraw: 0.15
2024-01-03 18:39:46,732:INFO:         statsmodels: 0.14.1
2024-01-03 18:39:46,732:INFO:              sktime: 0.21.1
2024-01-03 18:39:46,732:INFO:               tbats: 1.1.3
2024-01-03 18:39:46,732:INFO:            pmdarima: 2.0.4
2024-01-03 18:39:46,732:INFO:              psutil: 5.9.0
2024-01-03 18:39:46,732:INFO:          markupsafe: 2.1.1
2024-01-03 18:39:46,732:INFO:             pickle5: Not installed
2024-01-03 18:39:46,732:INFO:         cloudpickle: 3.0.0
2024-01-03 18:39:46,733:INFO:         deprecation: 2.1.0
2024-01-03 18:39:46,733:INFO:              xxhash: 3.4.1
2024-01-03 18:39:46,733:INFO:           wurlitzer: Not installed
2024-01-03 18:39:46,733:INFO:PyCaret optional dependencies:
2024-01-03 18:39:46,733:INFO:                shap: Not installed
2024-01-03 18:39:46,733:INFO:           interpret: Not installed
2024-01-03 18:39:46,733:INFO:                umap: Not installed
2024-01-03 18:39:46,733:INFO:     ydata_profiling: Not installed
2024-01-03 18:39:46,733:INFO:  explainerdashboard: Not installed
2024-01-03 18:39:46,733:INFO:             autoviz: Not installed
2024-01-03 18:39:46,733:INFO:           fairlearn: Not installed
2024-01-03 18:39:46,733:INFO:          deepchecks: Not installed
2024-01-03 18:39:46,733:INFO:             xgboost: Not installed
2024-01-03 18:39:46,733:INFO:            catboost: Not installed
2024-01-03 18:39:46,733:INFO:              kmodes: Not installed
2024-01-03 18:39:46,733:INFO:             mlxtend: 0.23.0
2024-01-03 18:39:46,734:INFO:       statsforecast: Not installed
2024-01-03 18:39:46,734:INFO:        tune_sklearn: Not installed
2024-01-03 18:39:46,734:INFO:                 ray: Not installed
2024-01-03 18:39:46,734:INFO:            hyperopt: Not installed
2024-01-03 18:39:46,734:INFO:              optuna: Not installed
2024-01-03 18:39:46,734:INFO:               skopt: Not installed
2024-01-03 18:39:46,734:INFO:              mlflow: Not installed
2024-01-03 18:39:46,734:INFO:              gradio: Not installed
2024-01-03 18:39:46,734:INFO:             fastapi: Not installed
2024-01-03 18:39:46,734:INFO:             uvicorn: Not installed
2024-01-03 18:39:46,734:INFO:              m2cgen: Not installed
2024-01-03 18:39:46,734:INFO:           evidently: Not installed
2024-01-03 18:39:46,734:INFO:               fugue: Not installed
2024-01-03 18:39:46,734:INFO:           streamlit: Not installed
2024-01-03 18:39:46,734:INFO:             prophet: Not installed
2024-01-03 18:39:46,734:INFO:None
2024-01-03 18:39:46,735:INFO:Set up data.
2024-01-03 18:39:46,755:INFO:Set up folding strategy.
2024-01-03 18:39:46,756:INFO:Set up train/test split.
2024-01-03 18:39:46,780:INFO:Set up index.
2024-01-03 18:39:46,780:INFO:Assigning column types.
2024-01-03 18:39:46,782:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:39:46,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:39:46,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:39:46,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:46,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:46,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:39:46,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:39:46,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:46,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:46,907:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:39:46,939:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:39:46,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:46,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:46,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:39:47,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,014:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:39:47,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,122:INFO:Preparing preprocessing pipeline...
2024-01-03 18:39:47,123:INFO:Set up label encoding.
2024-01-03 18:39:47,123:INFO:Set up simple imputation.
2024-01-03 18:39:47,123:INFO:Set up encoding of categorical features.
2024-01-03 18:39:47,200:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:39:47,204:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:39:47,204:INFO:Creating final display dataframe.
2024-01-03 18:39:47,460:INFO:Setup _display_container:                     Description             Value
0                    Session id              2175
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (14483, 2)
5        Transformed data shape        (14483, 2)
6   Transformed train set shape        (10138, 2)
7    Transformed test set shape         (4345, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              2453
2024-01-03 18:39:47,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:39:47,570:INFO:setup() successfully completed in 0.84s...............
2024-01-03 18:39:47,570:INFO:Initializing create_model()
2024-01-03 18:39:47,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F09ED0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:39:47,571:INFO:Checking exceptions
2024-01-03 18:40:13,458:INFO:PyCaret ClassificationExperiment
2024-01-03 18:40:13,459:INFO:Logging name: clf-default-name
2024-01-03 18:40:13,459:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:40:13,459:INFO:version 3.2.0
2024-01-03 18:40:13,459:INFO:Initializing setup()
2024-01-03 18:40:13,459:INFO:self.USI: 9e7a
2024-01-03 18:40:13,459:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:40:13,459:INFO:Checking environment
2024-01-03 18:40:13,459:INFO:python_version: 3.11.5
2024-01-03 18:40:13,459:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:40:13,459:INFO:machine: AMD64
2024-01-03 18:40:13,459:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:40:13,459:INFO:Memory: svmem(total=16893386752, available=3647455232, percent=78.4, used=13245931520, free=3647455232)
2024-01-03 18:40:13,459:INFO:Physical Core: 4
2024-01-03 18:40:13,459:INFO:Logical Core: 8
2024-01-03 18:40:13,459:INFO:Checking libraries
2024-01-03 18:40:13,459:INFO:System:
2024-01-03 18:40:13,459:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:40:13,459:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:40:13,459:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:40:13,459:INFO:PyCaret required dependencies:
2024-01-03 18:40:13,459:INFO:                 pip: 23.3.1
2024-01-03 18:40:13,459:INFO:          setuptools: 68.2.2
2024-01-03 18:40:13,459:INFO:             pycaret: 3.2.0
2024-01-03 18:40:13,459:INFO:             IPython: 8.15.0
2024-01-03 18:40:13,459:INFO:          ipywidgets: 8.0.4
2024-01-03 18:40:13,460:INFO:                tqdm: 4.66.1
2024-01-03 18:40:13,460:INFO:               numpy: 1.25.2
2024-01-03 18:40:13,460:INFO:              pandas: 1.5.3
2024-01-03 18:40:13,460:INFO:              jinja2: 3.1.2
2024-01-03 18:40:13,460:INFO:               scipy: 1.10.1
2024-01-03 18:40:13,460:INFO:              joblib: 1.2.0
2024-01-03 18:40:13,460:INFO:             sklearn: 1.2.2
2024-01-03 18:40:13,460:INFO:                pyod: 1.1.2
2024-01-03 18:40:13,460:INFO:            imblearn: 0.11.0
2024-01-03 18:40:13,460:INFO:   category_encoders: 2.6.3
2024-01-03 18:40:13,460:INFO:            lightgbm: 4.2.0
2024-01-03 18:40:13,460:INFO:               numba: 0.58.1
2024-01-03 18:40:13,460:INFO:            requests: 2.31.0
2024-01-03 18:40:13,460:INFO:          matplotlib: 3.6.0
2024-01-03 18:40:13,460:INFO:          scikitplot: 0.3.7
2024-01-03 18:40:13,460:INFO:         yellowbrick: 1.5
2024-01-03 18:40:13,460:INFO:              plotly: 5.18.0
2024-01-03 18:40:13,460:INFO:    plotly-resampler: Not installed
2024-01-03 18:40:13,460:INFO:             kaleido: 0.2.1
2024-01-03 18:40:13,460:INFO:           schemdraw: 0.15
2024-01-03 18:40:13,460:INFO:         statsmodels: 0.14.1
2024-01-03 18:40:13,460:INFO:              sktime: 0.21.1
2024-01-03 18:40:13,460:INFO:               tbats: 1.1.3
2024-01-03 18:40:13,460:INFO:            pmdarima: 2.0.4
2024-01-03 18:40:13,460:INFO:              psutil: 5.9.0
2024-01-03 18:40:13,460:INFO:          markupsafe: 2.1.1
2024-01-03 18:40:13,460:INFO:             pickle5: Not installed
2024-01-03 18:40:13,460:INFO:         cloudpickle: 3.0.0
2024-01-03 18:40:13,460:INFO:         deprecation: 2.1.0
2024-01-03 18:40:13,461:INFO:              xxhash: 3.4.1
2024-01-03 18:40:13,461:INFO:           wurlitzer: Not installed
2024-01-03 18:40:13,461:INFO:PyCaret optional dependencies:
2024-01-03 18:40:13,461:INFO:                shap: Not installed
2024-01-03 18:40:13,461:INFO:           interpret: Not installed
2024-01-03 18:40:13,461:INFO:                umap: Not installed
2024-01-03 18:40:13,461:INFO:     ydata_profiling: Not installed
2024-01-03 18:40:13,461:INFO:  explainerdashboard: Not installed
2024-01-03 18:40:13,461:INFO:             autoviz: Not installed
2024-01-03 18:40:13,461:INFO:           fairlearn: Not installed
2024-01-03 18:40:13,461:INFO:          deepchecks: Not installed
2024-01-03 18:40:13,461:INFO:             xgboost: Not installed
2024-01-03 18:40:13,461:INFO:            catboost: Not installed
2024-01-03 18:40:13,461:INFO:              kmodes: Not installed
2024-01-03 18:40:13,461:INFO:             mlxtend: 0.23.0
2024-01-03 18:40:13,461:INFO:       statsforecast: Not installed
2024-01-03 18:40:13,461:INFO:        tune_sklearn: Not installed
2024-01-03 18:40:13,461:INFO:                 ray: Not installed
2024-01-03 18:40:13,461:INFO:            hyperopt: Not installed
2024-01-03 18:40:13,461:INFO:              optuna: Not installed
2024-01-03 18:40:13,461:INFO:               skopt: Not installed
2024-01-03 18:40:13,461:INFO:              mlflow: Not installed
2024-01-03 18:40:13,461:INFO:              gradio: Not installed
2024-01-03 18:40:13,461:INFO:             fastapi: Not installed
2024-01-03 18:40:13,461:INFO:             uvicorn: Not installed
2024-01-03 18:40:13,462:INFO:              m2cgen: Not installed
2024-01-03 18:40:13,462:INFO:           evidently: Not installed
2024-01-03 18:40:13,462:INFO:               fugue: Not installed
2024-01-03 18:40:13,462:INFO:           streamlit: Not installed
2024-01-03 18:40:13,462:INFO:             prophet: Not installed
2024-01-03 18:40:13,462:INFO:None
2024-01-03 18:40:13,462:INFO:Set up data.
2024-01-03 18:40:13,483:INFO:Set up folding strategy.
2024-01-03 18:40:13,483:INFO:Set up train/test split.
2024-01-03 18:40:13,497:INFO:Set up index.
2024-01-03 18:40:13,498:INFO:Assigning column types.
2024-01-03 18:40:13,499:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:40:13,531:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:40:13,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:40:13,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:40:13,584:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:40:13,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,608:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:40:13,640:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:40:13,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:40:13,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,717:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:40:13,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:13,824:INFO:Preparing preprocessing pipeline...
2024-01-03 18:40:13,825:INFO:Set up label encoding.
2024-01-03 18:40:13,825:INFO:Set up simple imputation.
2024-01-03 18:40:13,826:INFO:Set up encoding of categorical features.
2024-01-03 18:40:13,907:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:40:13,911:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:40:13,911:INFO:Creating final display dataframe.
2024-01-03 18:40:14,162:INFO:Setup _display_container:                     Description             Value
0                    Session id              3731
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (14483, 2)
5        Transformed data shape        (14483, 2)
6   Transformed train set shape        (10138, 2)
7    Transformed test set shape         (4345, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              9e7a
2024-01-03 18:40:14,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:14,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:14,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:14,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:40:14,277:INFO:setup() successfully completed in 0.82s...............
2024-01-03 18:40:14,277:INFO:Initializing create_model()
2024-01-03 18:40:14,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F08C90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:40:14,277:INFO:Checking exceptions
2024-01-03 18:40:14,278:INFO:Importing libraries
2024-01-03 18:40:14,278:INFO:Copying training dataset
2024-01-03 18:40:14,281:INFO:Defining folds
2024-01-03 18:40:14,281:INFO:Declaring metric variables
2024-01-03 18:40:14,281:INFO:Importing untrained model
2024-01-03 18:40:14,281:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:40:14,281:INFO:Starting cross validation
2024-01-03 18:40:14,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:40:14,627:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,637:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,640:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,643:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,647:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,650:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,655:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,656:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,661:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,666:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,666:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,672:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,677:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,678:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,684:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,688:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,728:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,739:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,745:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,745:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,749:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,755:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,757:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,766:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,767:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,773:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,777:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,794:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,802:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,808:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,812:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,856:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,858:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,865:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,868:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,871:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,873:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:40:14,874:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,877:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:40:14,890:INFO:Calculating mean and std
2024-01-03 18:40:14,890:INFO:Creating metrics dataframe
2024-01-03 18:40:14,892:INFO:Finalizing model
2024-01-03 18:40:14,937:INFO:[LightGBM] [Info] Number of positive: 3506, number of negative: 6632
2024-01-03 18:40:14,938:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.
2024-01-03 18:40:14,938:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:40:14,938:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:40:14,938:INFO:[LightGBM] [Info] Total Bins 4
2024-01-03 18:40:14,938:INFO:[LightGBM] [Info] Number of data points in the train set: 10138, number of used features: 1
2024-01-03 18:40:14,938:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345828 -> initscore=-0.637431
2024-01-03 18:40:14,938:INFO:[LightGBM] [Info] Start training from score -0.637431
2024-01-03 18:40:14,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:40:14,964:INFO:Uploading results into container
2024-01-03 18:40:14,964:INFO:Uploading model into container now
2024-01-03 18:40:14,965:INFO:_master_model_container: 1
2024-01-03 18:40:14,965:INFO:_display_container: 2
2024-01-03 18:40:14,965:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3731, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:40:14,965:INFO:create_model() successfully completed......................................
2024-01-03 18:41:34,601:INFO:PyCaret ClassificationExperiment
2024-01-03 18:41:34,601:INFO:Logging name: clf-default-name
2024-01-03 18:41:34,601:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:41:34,601:INFO:version 3.2.0
2024-01-03 18:41:34,601:INFO:Initializing setup()
2024-01-03 18:41:34,601:INFO:self.USI: 1836
2024-01-03 18:41:34,603:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:41:34,603:INFO:Checking environment
2024-01-03 18:41:34,603:INFO:python_version: 3.11.5
2024-01-03 18:41:34,603:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:41:34,603:INFO:machine: AMD64
2024-01-03 18:41:34,603:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:41:34,603:INFO:Memory: svmem(total=16893386752, available=4031696896, percent=76.1, used=12861689856, free=4031696896)
2024-01-03 18:41:34,603:INFO:Physical Core: 4
2024-01-03 18:41:34,603:INFO:Logical Core: 8
2024-01-03 18:41:34,603:INFO:Checking libraries
2024-01-03 18:41:34,603:INFO:System:
2024-01-03 18:41:34,603:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:41:34,603:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:41:34,603:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:41:34,603:INFO:PyCaret required dependencies:
2024-01-03 18:41:34,603:INFO:                 pip: 23.3.1
2024-01-03 18:41:34,603:INFO:          setuptools: 68.2.2
2024-01-03 18:41:34,603:INFO:             pycaret: 3.2.0
2024-01-03 18:41:34,603:INFO:             IPython: 8.15.0
2024-01-03 18:41:34,603:INFO:          ipywidgets: 8.0.4
2024-01-03 18:41:34,603:INFO:                tqdm: 4.66.1
2024-01-03 18:41:34,603:INFO:               numpy: 1.25.2
2024-01-03 18:41:34,603:INFO:              pandas: 1.5.3
2024-01-03 18:41:34,603:INFO:              jinja2: 3.1.2
2024-01-03 18:41:34,603:INFO:               scipy: 1.10.1
2024-01-03 18:41:34,603:INFO:              joblib: 1.2.0
2024-01-03 18:41:34,603:INFO:             sklearn: 1.2.2
2024-01-03 18:41:34,603:INFO:                pyod: 1.1.2
2024-01-03 18:41:34,603:INFO:            imblearn: 0.11.0
2024-01-03 18:41:34,603:INFO:   category_encoders: 2.6.3
2024-01-03 18:41:34,603:INFO:            lightgbm: 4.2.0
2024-01-03 18:41:34,603:INFO:               numba: 0.58.1
2024-01-03 18:41:34,603:INFO:            requests: 2.31.0
2024-01-03 18:41:34,603:INFO:          matplotlib: 3.6.0
2024-01-03 18:41:34,603:INFO:          scikitplot: 0.3.7
2024-01-03 18:41:34,603:INFO:         yellowbrick: 1.5
2024-01-03 18:41:34,603:INFO:              plotly: 5.18.0
2024-01-03 18:41:34,603:INFO:    plotly-resampler: Not installed
2024-01-03 18:41:34,603:INFO:             kaleido: 0.2.1
2024-01-03 18:41:34,603:INFO:           schemdraw: 0.15
2024-01-03 18:41:34,603:INFO:         statsmodels: 0.14.1
2024-01-03 18:41:34,603:INFO:              sktime: 0.21.1
2024-01-03 18:41:34,603:INFO:               tbats: 1.1.3
2024-01-03 18:41:34,603:INFO:            pmdarima: 2.0.4
2024-01-03 18:41:34,603:INFO:              psutil: 5.9.0
2024-01-03 18:41:34,603:INFO:          markupsafe: 2.1.1
2024-01-03 18:41:34,603:INFO:             pickle5: Not installed
2024-01-03 18:41:34,603:INFO:         cloudpickle: 3.0.0
2024-01-03 18:41:34,603:INFO:         deprecation: 2.1.0
2024-01-03 18:41:34,603:INFO:              xxhash: 3.4.1
2024-01-03 18:41:34,603:INFO:           wurlitzer: Not installed
2024-01-03 18:41:34,603:INFO:PyCaret optional dependencies:
2024-01-03 18:41:34,603:INFO:                shap: Not installed
2024-01-03 18:41:34,603:INFO:           interpret: Not installed
2024-01-03 18:41:34,603:INFO:                umap: Not installed
2024-01-03 18:41:34,603:INFO:     ydata_profiling: Not installed
2024-01-03 18:41:34,603:INFO:  explainerdashboard: Not installed
2024-01-03 18:41:34,603:INFO:             autoviz: Not installed
2024-01-03 18:41:34,603:INFO:           fairlearn: Not installed
2024-01-03 18:41:34,604:INFO:          deepchecks: Not installed
2024-01-03 18:41:34,604:INFO:             xgboost: Not installed
2024-01-03 18:41:34,604:INFO:            catboost: Not installed
2024-01-03 18:41:34,604:INFO:              kmodes: Not installed
2024-01-03 18:41:34,604:INFO:             mlxtend: 0.23.0
2024-01-03 18:41:34,604:INFO:       statsforecast: Not installed
2024-01-03 18:41:34,604:INFO:        tune_sklearn: Not installed
2024-01-03 18:41:34,604:INFO:                 ray: Not installed
2024-01-03 18:41:34,604:INFO:            hyperopt: Not installed
2024-01-03 18:41:34,604:INFO:              optuna: Not installed
2024-01-03 18:41:34,604:INFO:               skopt: Not installed
2024-01-03 18:41:34,604:INFO:              mlflow: Not installed
2024-01-03 18:41:34,604:INFO:              gradio: Not installed
2024-01-03 18:41:34,604:INFO:             fastapi: Not installed
2024-01-03 18:41:34,604:INFO:             uvicorn: Not installed
2024-01-03 18:41:34,604:INFO:              m2cgen: Not installed
2024-01-03 18:41:34,604:INFO:           evidently: Not installed
2024-01-03 18:41:34,604:INFO:               fugue: Not installed
2024-01-03 18:41:34,604:INFO:           streamlit: Not installed
2024-01-03 18:41:34,604:INFO:             prophet: Not installed
2024-01-03 18:41:34,604:INFO:None
2024-01-03 18:41:34,604:INFO:Set up data.
2024-01-03 18:41:34,624:INFO:Set up folding strategy.
2024-01-03 18:41:34,625:INFO:Set up train/test split.
2024-01-03 18:41:34,647:INFO:Set up index.
2024-01-03 18:41:34,648:INFO:Assigning column types.
2024-01-03 18:41:34,651:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:41:34,702:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:41:34,703:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:41:34,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,765:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:41:34,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:41:34,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,786:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:41:34,817:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:41:34,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:41:34,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,894:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:41:34,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:34,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:35,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:35,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:35,001:INFO:Preparing preprocessing pipeline...
2024-01-03 18:41:35,002:INFO:Set up label encoding.
2024-01-03 18:41:35,002:INFO:Set up simple imputation.
2024-01-03 18:41:35,003:INFO:Set up encoding of categorical features.
2024-01-03 18:41:35,079:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:41:35,084:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:41:35,084:INFO:Creating final display dataframe.
2024-01-03 18:41:35,339:INFO:Setup _display_container:                     Description             Value
0                    Session id              1115
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (14483, 2)
5        Transformed data shape        (14483, 2)
6   Transformed train set shape        (10138, 2)
7    Transformed test set shape         (4345, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              1836
2024-01-03 18:41:35,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:35,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:35,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:35,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:41:35,448:INFO:setup() successfully completed in 0.85s...............
2024-01-03 18:41:35,448:INFO:Initializing create_model()
2024-01-03 18:41:35,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:41:35,448:INFO:Checking exceptions
2024-01-03 18:41:35,450:INFO:Importing libraries
2024-01-03 18:41:35,450:INFO:Copying training dataset
2024-01-03 18:41:35,452:INFO:Defining folds
2024-01-03 18:41:35,452:INFO:Declaring metric variables
2024-01-03 18:41:35,452:INFO:Importing untrained model
2024-01-03 18:41:35,452:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:41:35,453:INFO:Starting cross validation
2024-01-03 18:41:35,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:41:35,767:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,777:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,782:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,783:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:35,787:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,792:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,796:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,798:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:35,801:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,803:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,807:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,812:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,813:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:35,817:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,818:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:35,823:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,876:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,887:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,897:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,903:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:35,908:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,916:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,925:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,933:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,935:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,943:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:35,949:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:35,953:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:36,017:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:36,019:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:36,027:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:36,028:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:36,033:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:36,034:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:36,038:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:36,038:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:36,051:INFO:Calculating mean and std
2024-01-03 18:41:36,052:INFO:Creating metrics dataframe
2024-01-03 18:41:36,054:INFO:Finalizing model
2024-01-03 18:41:36,097:INFO:[LightGBM] [Info] Number of positive: 3506, number of negative: 6632
2024-01-03 18:41:36,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.
2024-01-03 18:41:36,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:36,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:36,097:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:36,097:INFO:[LightGBM] [Info] Number of data points in the train set: 10138, number of used features: 1
2024-01-03 18:41:36,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345828 -> initscore=-0.637431
2024-01-03 18:41:36,098:INFO:[LightGBM] [Info] Start training from score -0.637431
2024-01-03 18:41:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:36,126:INFO:Uploading results into container
2024-01-03 18:41:36,127:INFO:Uploading model into container now
2024-01-03 18:41:36,127:INFO:_master_model_container: 1
2024-01-03 18:41:36,127:INFO:_display_container: 2
2024-01-03 18:41:36,128:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:41:36,128:INFO:create_model() successfully completed......................................
2024-01-03 18:41:36,409:INFO:Initializing tune_model()
2024-01-03 18:41:36,409:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=True, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-01-03 18:41:36,410:INFO:Checking exceptions
2024-01-03 18:41:36,424:INFO:Copying training dataset
2024-01-03 18:41:36,426:INFO:Checking base model
2024-01-03 18:41:36,427:INFO:Base model : Light Gradient Boosting Machine
2024-01-03 18:41:36,430:INFO:Declaring metric variables
2024-01-03 18:41:36,433:INFO:Defining Hyperparameters
2024-01-03 18:41:36,694:INFO:Tuning with n_jobs=-1
2024-01-03 18:41:36,694:INFO:Initializing RandomizedSearchCV
2024-01-03 18:41:40,925:INFO:best_params: {'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 70, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 100, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.4}
2024-01-03 18:41:40,926:INFO:Hyperparameter search completed
2024-01-03 18:41:40,926:INFO:SubProcess create_model() called ==================================
2024-01-03 18:41:40,927:INFO:Initializing create_model()
2024-01-03 18:41:40,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C083AEA850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.7, 'reg_alpha': 0.005, 'num_leaves': 80, 'n_estimators': 70, 'min_split_gain': 0.1, 'min_child_samples': 100, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.4})
2024-01-03 18:41:40,927:INFO:Checking exceptions
2024-01-03 18:41:40,927:INFO:Importing libraries
2024-01-03 18:41:40,927:INFO:Copying training dataset
2024-01-03 18:41:40,933:INFO:Defining folds
2024-01-03 18:41:40,933:INFO:Declaring metric variables
2024-01-03 18:41:40,938:INFO:Importing untrained model
2024-01-03 18:41:40,938:INFO:Declaring custom model
2024-01-03 18:41:40,942:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:41:40,952:INFO:Starting cross validation
2024-01-03 18:41:40,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:41:41,185:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,187:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,188:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,195:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,197:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,198:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,201:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:41,204:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:41,204:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:41,206:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,208:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,209:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,243:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,247:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,254:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,258:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,260:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:41,265:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,268:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,315:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,319:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,325:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,326:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,329:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,331:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:41,336:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,336:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,339:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,342:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:41,347:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,390:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,390:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,400:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,406:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:41,409:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,409:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:41,423:INFO:Calculating mean and std
2024-01-03 18:41:41,424:INFO:Creating metrics dataframe
2024-01-03 18:41:41,429:INFO:Finalizing model
2024-01-03 18:41:41,470:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-03 18:41:41,470:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2024-01-03 18:41:41,471:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-03 18:41:41,473:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-03 18:41:41,473:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2024-01-03 18:41:41,473:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-03 18:41:41,473:INFO:[LightGBM] [Info] Number of positive: 3506, number of negative: 6632
2024-01-03 18:41:41,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.
2024-01-03 18:41:41,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:41,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:41,474:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:41,474:INFO:[LightGBM] [Info] Number of data points in the train set: 10138, number of used features: 1
2024-01-03 18:41:41,474:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345828 -> initscore=-0.637431
2024-01-03 18:41:41,474:INFO:[LightGBM] [Info] Start training from score -0.637431
2024-01-03 18:41:41,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:41,529:INFO:Uploading results into container
2024-01-03 18:41:41,530:INFO:Uploading model into container now
2024-01-03 18:41:41,530:INFO:_master_model_container: 2
2024-01-03 18:41:41,530:INFO:_display_container: 3
2024-01-03 18:41:41,531:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=100, min_child_weight=0.001,
               min_split_gain=0.1, n_estimators=70, n_jobs=-1, num_leaves=80,
               objective=None, random_state=1115, reg_alpha=0.005,
               reg_lambda=0.7, subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2024-01-03 18:41:41,531:INFO:create_model() successfully completed......................................
2024-01-03 18:41:41,813:INFO:SubProcess create_model() end ==================================
2024-01-03 18:41:41,813:INFO:choose_better activated
2024-01-03 18:41:41,816:INFO:SubProcess create_model() called ==================================
2024-01-03 18:41:41,816:INFO:Initializing create_model()
2024-01-03 18:41:41,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:41:41,816:INFO:Checking exceptions
2024-01-03 18:41:41,817:INFO:Importing libraries
2024-01-03 18:41:41,818:INFO:Copying training dataset
2024-01-03 18:41:41,820:INFO:Defining folds
2024-01-03 18:41:41,820:INFO:Declaring metric variables
2024-01-03 18:41:41,820:INFO:Importing untrained model
2024-01-03 18:41:41,820:INFO:Declaring custom model
2024-01-03 18:41:41,821:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:41:41,821:INFO:Starting cross validation
2024-01-03 18:41:41,822:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:41:42,045:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,046:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,051:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,054:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,055:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,058:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,062:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:42,062:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,064:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:42,065:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,066:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,068:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:42,069:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,072:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:42,073:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,076:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,121:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,130:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,133:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,143:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,151:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,177:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,187:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,189:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,192:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:42,198:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,201:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,209:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:42,213:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,252:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,254:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,261:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,264:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,267:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:42,269:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:42,270:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,273:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:42,286:INFO:Calculating mean and std
2024-01-03 18:41:42,287:INFO:Creating metrics dataframe
2024-01-03 18:41:42,289:INFO:Finalizing model
2024-01-03 18:41:42,331:INFO:[LightGBM] [Info] Number of positive: 3506, number of negative: 6632
2024-01-03 18:41:42,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.
2024-01-03 18:41:42,331:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:42,331:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:42,331:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:42,331:INFO:[LightGBM] [Info] Number of data points in the train set: 10138, number of used features: 1
2024-01-03 18:41:42,331:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345828 -> initscore=-0.637431
2024-01-03 18:41:42,331:INFO:[LightGBM] [Info] Start training from score -0.637431
2024-01-03 18:41:42,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:42,357:INFO:Uploading results into container
2024-01-03 18:41:42,358:INFO:Uploading model into container now
2024-01-03 18:41:42,358:INFO:_master_model_container: 3
2024-01-03 18:41:42,358:INFO:_display_container: 4
2024-01-03 18:41:42,358:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:41:42,359:INFO:create_model() successfully completed......................................
2024-01-03 18:41:42,634:INFO:SubProcess create_model() end ==================================
2024-01-03 18:41:42,635:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6544
2024-01-03 18:41:42,635:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=100, min_child_weight=0.001,
               min_split_gain=0.1, n_estimators=70, n_jobs=-1, num_leaves=80,
               objective=None, random_state=1115, reg_alpha=0.005,
               reg_lambda=0.7, subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Accuracy is 0.6544
2024-01-03 18:41:42,635:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-03 18:41:42,636:INFO:choose_better completed
2024-01-03 18:41:42,636:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-03 18:41:42,643:INFO:_master_model_container: 3
2024-01-03 18:41:42,643:INFO:_display_container: 3
2024-01-03 18:41:42,644:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:41:42,644:INFO:tune_model() successfully completed......................................
2024-01-03 18:41:42,895:INFO:Initializing calibrate_model()
2024-01-03 18:41:42,895:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1115, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=sigmoid, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2024-01-03 18:41:42,895:INFO:Checking exceptions
2024-01-03 18:41:42,896:INFO:Preloading libraries
2024-01-03 18:41:42,897:INFO:Preparing display monitor
2024-01-03 18:41:42,908:INFO:Getting model name
2024-01-03 18:41:42,908:INFO:Base model : Light Gradient Boosting Machine
2024-01-03 18:41:42,917:INFO:Importing untrained CalibratedClassifierCV
2024-01-03 18:41:42,917:INFO:SubProcess create_model() called ==================================
2024-01-03 18:41:42,918:INFO:Initializing create_model()
2024-01-03 18:41:42,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     importance_type='split',
                                                     learning_rate=0.1,
                                                     max_depth=-1,
                                                     min_child_samples=20,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, num_leaves=31,
                                                     objective=None,
                                                     random_state=1115,
                                                     reg_alpha=0.0,
                                                     reg_lambda=0.0,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08140D2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:41:42,918:INFO:Checking exceptions
2024-01-03 18:41:42,918:INFO:Importing libraries
2024-01-03 18:41:42,918:INFO:Copying training dataset
2024-01-03 18:41:42,921:INFO:Defining folds
2024-01-03 18:41:42,921:INFO:Declaring metric variables
2024-01-03 18:41:42,926:INFO:Importing untrained model
2024-01-03 18:41:42,926:INFO:Declaring custom model
2024-01-03 18:41:42,930:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:41:42,935:INFO:Starting cross validation
2024-01-03 18:41:42,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:41:43,022:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:43,024:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:43,027:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:43,037:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:43,042:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:43,047:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:43,053:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:43,064:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:43,913:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,914:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,923:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,925:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,929:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:43,933:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:43,933:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,934:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,937:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,943:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,955:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:43,992:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,004:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,010:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:44,011:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:44,016:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,094:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,106:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,107:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,112:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:44,113:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:44,117:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,118:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,125:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,138:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,144:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:44,148:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,166:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,176:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,183:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:44,188:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,467:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,468:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,482:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:44,482:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:41:44,486:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,486:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:41:44,499:INFO:Calculating mean and std
2024-01-03 18:41:44,501:INFO:Creating metrics dataframe
2024-01-03 18:41:44,506:INFO:Finalizing model
2024-01-03 18:41:44,545:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:44,552:INFO:[LightGBM] [Info] Number of positive: 2804, number of negative: 5306
2024-01-03 18:41:44,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.
2024-01-03 18:41:44,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:44,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:44,552:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:44,552:INFO:[LightGBM] [Info] Number of data points in the train set: 8110, number of used features: 1
2024-01-03 18:41:44,553:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345746 -> initscore=-0.637791
2024-01-03 18:41:44,553:INFO:[LightGBM] [Info] Start training from score -0.637791
2024-01-03 18:41:44,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,593:INFO:[LightGBM] [Info] Number of positive: 2805, number of negative: 5305
2024-01-03 18:41:44,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000031 seconds.
2024-01-03 18:41:44,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:44,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:44,593:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:44,593:INFO:[LightGBM] [Info] Number of data points in the train set: 8110, number of used features: 1
2024-01-03 18:41:44,593:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345869 -> initscore=-0.637246
2024-01-03 18:41:44,593:INFO:[LightGBM] [Info] Start training from score -0.637246
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,632:INFO:[LightGBM] [Info] Number of positive: 2805, number of negative: 5305
2024-01-03 18:41:44,632:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.
2024-01-03 18:41:44,632:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:44,632:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:44,632:INFO:[LightGBM] [Info] Total Bins 4
2024-01-03 18:41:44,632:INFO:[LightGBM] [Info] Number of data points in the train set: 8110, number of used features: 1
2024-01-03 18:41:44,632:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345869 -> initscore=-0.637246
2024-01-03 18:41:44,632:INFO:[LightGBM] [Info] Start training from score -0.637246
2024-01-03 18:41:44,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,669:INFO:[LightGBM] [Info] Number of positive: 2805, number of negative: 5306
2024-01-03 18:41:44,669:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.
2024-01-03 18:41:44,669:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:44,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:44,669:INFO:[LightGBM] [Info] Total Bins 4
2024-01-03 18:41:44,669:INFO:[LightGBM] [Info] Number of data points in the train set: 8111, number of used features: 1
2024-01-03 18:41:44,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345827 -> initscore=-0.637435
2024-01-03 18:41:44,669:INFO:[LightGBM] [Info] Start training from score -0.637435
2024-01-03 18:41:44,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,704:INFO:[LightGBM] [Info] Number of positive: 2805, number of negative: 5306
2024-01-03 18:41:44,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000025 seconds.
2024-01-03 18:41:44,705:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:44,705:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:44,705:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:44,705:INFO:[LightGBM] [Info] Number of data points in the train set: 8111, number of used features: 1
2024-01-03 18:41:44,705:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345827 -> initscore=-0.637435
2024-01-03 18:41:44,705:INFO:[LightGBM] [Info] Start training from score -0.637435
2024-01-03 18:41:44,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:44,741:INFO:Uploading results into container
2024-01-03 18:41:44,742:INFO:Uploading model into container now
2024-01-03 18:41:44,742:INFO:_master_model_container: 4
2024-01-03 18:41:44,742:INFO:_display_container: 4
2024-01-03 18:41:44,744:INFO:CalibratedClassifierCV(base_estimator=LGBMClassifier(boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     importance_type='split',
                                                     learning_rate=0.1,
                                                     max_depth=-1,
                                                     min_child_samples=20,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, num_leaves=31,
                                                     objective=None,
                                                     random_state=1115,
                                                     reg_alpha=0.0,
                                                     reg_lambda=0.0,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:41:44,744:INFO:create_model() successfully completed......................................
2024-01-03 18:41:45,018:INFO:SubProcess create_model() end ==================================
2024-01-03 18:41:45,029:INFO:_master_model_container: 4
2024-01-03 18:41:45,029:INFO:_display_container: 4
2024-01-03 18:41:45,030:INFO:CalibratedClassifierCV(base_estimator=LGBMClassifier(boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     importance_type='split',
                                                     learning_rate=0.1,
                                                     max_depth=-1,
                                                     min_child_samples=20,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, num_leaves=31,
                                                     objective=None,
                                                     random_state=1115,
                                                     reg_alpha=0.0,
                                                     reg_lambda=0.0,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:41:45,030:INFO:calibrate_model() successfully completed......................................
2024-01-03 18:41:45,297:INFO:Initializing finalize_model()
2024-01-03 18:41:45,297:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     importance_type='split',
                                                     learning_rate=0.1,
                                                     max_depth=-1,
                                                     min_child_samples=20,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, num_leaves=31,
                                                     objective=None,
                                                     random_state=1115,
                                                     reg_alpha=0.0,
                                                     reg_lambda=0.0,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-03 18:41:45,299:INFO:Finalizing CalibratedClassifierCV(base_estimator=LGBMClassifier(boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     importance_type='split',
                                                     learning_rate=0.1,
                                                     max_depth=-1,
                                                     min_child_samples=20,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, num_leaves=31,
                                                     objective=None,
                                                     random_state=1115,
                                                     reg_alpha=0.0,
                                                     reg_lambda=0.0,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:41:45,302:INFO:Initializing create_model()
2024-01-03 18:41:45,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     importance_type='split',
                                                     learning_rate=0.1,
                                                     max_depth=-1,
                                                     min_child_samples=20,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, num_leaves=31,
                                                     objective=None,
                                                     random_state=1115,
                                                     reg_alpha=0.0,
                                                     reg_lambda=0.0,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:41:45,302:INFO:Checking exceptions
2024-01-03 18:41:45,303:INFO:Importing libraries
2024-01-03 18:41:45,303:INFO:Copying training dataset
2024-01-03 18:41:45,303:INFO:Defining folds
2024-01-03 18:41:45,303:INFO:Declaring metric variables
2024-01-03 18:41:45,303:INFO:Importing untrained model
2024-01-03 18:41:45,303:INFO:Declaring custom model
2024-01-03 18:41:45,304:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:41:45,305:INFO:Cross validation set to False
2024-01-03 18:41:45,305:INFO:Fitting Model
2024-01-03 18:41:45,338:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:41:45,344:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:41:45,345:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.
2024-01-03 18:41:45,345:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:45,345:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:45,345:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:45,345:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:41:45,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:41:45,345:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:41:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,389:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:41:45,389:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.
2024-01-03 18:41:45,389:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:45,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:45,389:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:45,390:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:41:45,390:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:41:45,390:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:41:45,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,432:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:41:45,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.
2024-01-03 18:41:45,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:45,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:45,432:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:45,432:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:41:45,433:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:41:45,433:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:41:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,489:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7580
2024-01-03 18:41:45,489:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.
2024-01-03 18:41:45,489:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:45,489:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:45,489:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:45,489:INFO:[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1
2024-01-03 18:41:45,490:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345819 -> initscore=-0.637470
2024-01-03 18:41:45,490:INFO:[LightGBM] [Info] Start training from score -0.637470
2024-01-03 18:41:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,532:INFO:[LightGBM] [Info] Number of positive: 4008, number of negative: 7579
2024-01-03 18:41:45,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000035 seconds.
2024-01-03 18:41:45,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:41:45,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:41:45,532:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:41:45,532:INFO:[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1
2024-01-03 18:41:45,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345905 -> initscore=-0.637089
2024-01-03 18:41:45,532:INFO:[LightGBM] [Info] Start training from score -0.637089
2024-01-03 18:41:45,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:41:45,583:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.1,
                                                                      max_depth=-1,
                                                                      min_child_samples=20,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      num_leaves=31,
                                                                      objective=None,
                                                                      random_state=1115,
                                                                      reg_alpha=0.0,
                                                                      reg_lambda=0.0,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-01-03 18:41:45,583:INFO:create_model() successfully completed......................................
2024-01-03 18:41:45,857:INFO:_master_model_container: 4
2024-01-03 18:41:45,857:INFO:_display_container: 4
2024-01-03 18:41:45,863:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.1,
                                                                      max_depth=-1,
                                                                      min_child_samples=20,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      num_leaves=31,
                                                                      objective=None,
                                                                      random_state=1115,
                                                                      reg_alpha=0.0,
                                                                      reg_lambda=0.0,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-01-03 18:41:45,863:INFO:finalize_model() successfully completed......................................
2024-01-03 18:41:46,136:INFO:Initializing plot_model()
2024-01-03 18:41:46,137:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DC1CB50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.1,
                                                                      max_depth=-1,
                                                                      min_child_samples=20,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      num_leaves=31,
                                                                      objective=None,
                                                                      random_state=1115,
                                                                      reg_alpha=0.0,
                                                                      reg_lambda=0.0,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-01-03 18:41:46,137:INFO:Checking exceptions
2024-01-03 18:41:46,139:INFO:Preloading libraries
2024-01-03 18:41:46,156:INFO:Copying training dataset
2024-01-03 18:41:46,156:INFO:Plot type: confusion_matrix
2024-01-03 18:41:46,465:INFO:Fitting Model
2024-01-03 18:41:46,465:INFO:Scoring test/hold-out set
2024-01-03 18:41:46,647:INFO:Visual Rendered Successfully
2024-01-03 18:41:46,897:INFO:plot_model() successfully completed......................................
2024-01-03 18:45:59,032:INFO:PyCaret ClassificationExperiment
2024-01-03 18:45:59,032:INFO:Logging name: clf-default-name
2024-01-03 18:45:59,032:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:45:59,032:INFO:version 3.2.0
2024-01-03 18:45:59,032:INFO:Initializing setup()
2024-01-03 18:45:59,032:INFO:self.USI: b7d2
2024-01-03 18:45:59,032:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:45:59,032:INFO:Checking environment
2024-01-03 18:45:59,032:INFO:python_version: 3.11.5
2024-01-03 18:45:59,032:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:45:59,032:INFO:machine: AMD64
2024-01-03 18:45:59,032:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:45:59,032:INFO:Memory: svmem(total=16893386752, available=3567493120, percent=78.9, used=13325893632, free=3567493120)
2024-01-03 18:45:59,032:INFO:Physical Core: 4
2024-01-03 18:45:59,032:INFO:Logical Core: 8
2024-01-03 18:45:59,032:INFO:Checking libraries
2024-01-03 18:45:59,032:INFO:System:
2024-01-03 18:45:59,032:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:45:59,032:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:45:59,032:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:45:59,032:INFO:PyCaret required dependencies:
2024-01-03 18:45:59,032:INFO:                 pip: 23.3.1
2024-01-03 18:45:59,032:INFO:          setuptools: 68.2.2
2024-01-03 18:45:59,032:INFO:             pycaret: 3.2.0
2024-01-03 18:45:59,033:INFO:             IPython: 8.15.0
2024-01-03 18:45:59,033:INFO:          ipywidgets: 8.0.4
2024-01-03 18:45:59,033:INFO:                tqdm: 4.66.1
2024-01-03 18:45:59,033:INFO:               numpy: 1.25.2
2024-01-03 18:45:59,033:INFO:              pandas: 1.5.3
2024-01-03 18:45:59,033:INFO:              jinja2: 3.1.2
2024-01-03 18:45:59,033:INFO:               scipy: 1.10.1
2024-01-03 18:45:59,033:INFO:              joblib: 1.2.0
2024-01-03 18:45:59,033:INFO:             sklearn: 1.2.2
2024-01-03 18:45:59,033:INFO:                pyod: 1.1.2
2024-01-03 18:45:59,033:INFO:            imblearn: 0.11.0
2024-01-03 18:45:59,033:INFO:   category_encoders: 2.6.3
2024-01-03 18:45:59,033:INFO:            lightgbm: 4.2.0
2024-01-03 18:45:59,033:INFO:               numba: 0.58.1
2024-01-03 18:45:59,033:INFO:            requests: 2.31.0
2024-01-03 18:45:59,033:INFO:          matplotlib: 3.6.0
2024-01-03 18:45:59,033:INFO:          scikitplot: 0.3.7
2024-01-03 18:45:59,033:INFO:         yellowbrick: 1.5
2024-01-03 18:45:59,033:INFO:              plotly: 5.18.0
2024-01-03 18:45:59,033:INFO:    plotly-resampler: Not installed
2024-01-03 18:45:59,033:INFO:             kaleido: 0.2.1
2024-01-03 18:45:59,033:INFO:           schemdraw: 0.15
2024-01-03 18:45:59,033:INFO:         statsmodels: 0.14.1
2024-01-03 18:45:59,033:INFO:              sktime: 0.21.1
2024-01-03 18:45:59,033:INFO:               tbats: 1.1.3
2024-01-03 18:45:59,033:INFO:            pmdarima: 2.0.4
2024-01-03 18:45:59,033:INFO:              psutil: 5.9.0
2024-01-03 18:45:59,033:INFO:          markupsafe: 2.1.1
2024-01-03 18:45:59,033:INFO:             pickle5: Not installed
2024-01-03 18:45:59,033:INFO:         cloudpickle: 3.0.0
2024-01-03 18:45:59,033:INFO:         deprecation: 2.1.0
2024-01-03 18:45:59,033:INFO:              xxhash: 3.4.1
2024-01-03 18:45:59,033:INFO:           wurlitzer: Not installed
2024-01-03 18:45:59,033:INFO:PyCaret optional dependencies:
2024-01-03 18:45:59,034:INFO:                shap: Not installed
2024-01-03 18:45:59,034:INFO:           interpret: Not installed
2024-01-03 18:45:59,034:INFO:                umap: Not installed
2024-01-03 18:45:59,034:INFO:     ydata_profiling: Not installed
2024-01-03 18:45:59,034:INFO:  explainerdashboard: Not installed
2024-01-03 18:45:59,034:INFO:             autoviz: Not installed
2024-01-03 18:45:59,034:INFO:           fairlearn: Not installed
2024-01-03 18:45:59,034:INFO:          deepchecks: Not installed
2024-01-03 18:45:59,034:INFO:             xgboost: Not installed
2024-01-03 18:45:59,034:INFO:            catboost: Not installed
2024-01-03 18:45:59,034:INFO:              kmodes: Not installed
2024-01-03 18:45:59,034:INFO:             mlxtend: 0.23.0
2024-01-03 18:45:59,034:INFO:       statsforecast: Not installed
2024-01-03 18:45:59,034:INFO:        tune_sklearn: Not installed
2024-01-03 18:45:59,034:INFO:                 ray: Not installed
2024-01-03 18:45:59,034:INFO:            hyperopt: Not installed
2024-01-03 18:45:59,034:INFO:              optuna: Not installed
2024-01-03 18:45:59,034:INFO:               skopt: Not installed
2024-01-03 18:45:59,034:INFO:              mlflow: Not installed
2024-01-03 18:45:59,034:INFO:              gradio: Not installed
2024-01-03 18:45:59,034:INFO:             fastapi: Not installed
2024-01-03 18:45:59,034:INFO:             uvicorn: Not installed
2024-01-03 18:45:59,034:INFO:              m2cgen: Not installed
2024-01-03 18:45:59,034:INFO:           evidently: Not installed
2024-01-03 18:45:59,034:INFO:               fugue: Not installed
2024-01-03 18:45:59,034:INFO:           streamlit: Not installed
2024-01-03 18:45:59,034:INFO:             prophet: Not installed
2024-01-03 18:45:59,034:INFO:None
2024-01-03 18:45:59,034:INFO:Set up data.
2024-01-03 18:45:59,054:INFO:Set up folding strategy.
2024-01-03 18:45:59,054:INFO:Set up train/test split.
2024-01-03 18:45:59,054:INFO:Set up data.
2024-01-03 18:45:59,073:INFO:Set up index.
2024-01-03 18:46:21,832:INFO:PyCaret ClassificationExperiment
2024-01-03 18:46:21,832:INFO:Logging name: clf-default-name
2024-01-03 18:46:21,832:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:46:21,832:INFO:version 3.2.0
2024-01-03 18:46:21,832:INFO:Initializing setup()
2024-01-03 18:46:21,832:INFO:self.USI: da0a
2024-01-03 18:46:21,832:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:46:21,832:INFO:Checking environment
2024-01-03 18:46:21,832:INFO:python_version: 3.11.5
2024-01-03 18:46:21,832:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:46:21,832:INFO:machine: AMD64
2024-01-03 18:46:21,832:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:46:21,832:INFO:Memory: svmem(total=16893386752, available=3515092992, percent=79.2, used=13378293760, free=3515092992)
2024-01-03 18:46:21,833:INFO:Physical Core: 4
2024-01-03 18:46:21,833:INFO:Logical Core: 8
2024-01-03 18:46:21,833:INFO:Checking libraries
2024-01-03 18:46:21,833:INFO:System:
2024-01-03 18:46:21,833:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:46:21,833:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:46:21,833:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:46:21,833:INFO:PyCaret required dependencies:
2024-01-03 18:46:21,833:INFO:                 pip: 23.3.1
2024-01-03 18:46:21,833:INFO:          setuptools: 68.2.2
2024-01-03 18:46:21,833:INFO:             pycaret: 3.2.0
2024-01-03 18:46:21,833:INFO:             IPython: 8.15.0
2024-01-03 18:46:21,833:INFO:          ipywidgets: 8.0.4
2024-01-03 18:46:21,833:INFO:                tqdm: 4.66.1
2024-01-03 18:46:21,833:INFO:               numpy: 1.25.2
2024-01-03 18:46:21,833:INFO:              pandas: 1.5.3
2024-01-03 18:46:21,833:INFO:              jinja2: 3.1.2
2024-01-03 18:46:21,833:INFO:               scipy: 1.10.1
2024-01-03 18:46:21,833:INFO:              joblib: 1.2.0
2024-01-03 18:46:21,833:INFO:             sklearn: 1.2.2
2024-01-03 18:46:21,833:INFO:                pyod: 1.1.2
2024-01-03 18:46:21,833:INFO:            imblearn: 0.11.0
2024-01-03 18:46:21,833:INFO:   category_encoders: 2.6.3
2024-01-03 18:46:21,833:INFO:            lightgbm: 4.2.0
2024-01-03 18:46:21,833:INFO:               numba: 0.58.1
2024-01-03 18:46:21,833:INFO:            requests: 2.31.0
2024-01-03 18:46:21,834:INFO:          matplotlib: 3.6.0
2024-01-03 18:46:21,834:INFO:          scikitplot: 0.3.7
2024-01-03 18:46:21,834:INFO:         yellowbrick: 1.5
2024-01-03 18:46:21,834:INFO:              plotly: 5.18.0
2024-01-03 18:46:21,834:INFO:    plotly-resampler: Not installed
2024-01-03 18:46:21,834:INFO:             kaleido: 0.2.1
2024-01-03 18:46:21,834:INFO:           schemdraw: 0.15
2024-01-03 18:46:21,834:INFO:         statsmodels: 0.14.1
2024-01-03 18:46:21,834:INFO:              sktime: 0.21.1
2024-01-03 18:46:21,834:INFO:               tbats: 1.1.3
2024-01-03 18:46:21,834:INFO:            pmdarima: 2.0.4
2024-01-03 18:46:21,834:INFO:              psutil: 5.9.0
2024-01-03 18:46:21,834:INFO:          markupsafe: 2.1.1
2024-01-03 18:46:21,834:INFO:             pickle5: Not installed
2024-01-03 18:46:21,834:INFO:         cloudpickle: 3.0.0
2024-01-03 18:46:21,834:INFO:         deprecation: 2.1.0
2024-01-03 18:46:21,834:INFO:              xxhash: 3.4.1
2024-01-03 18:46:21,834:INFO:           wurlitzer: Not installed
2024-01-03 18:46:21,834:INFO:PyCaret optional dependencies:
2024-01-03 18:46:21,834:INFO:                shap: Not installed
2024-01-03 18:46:21,834:INFO:           interpret: Not installed
2024-01-03 18:46:21,834:INFO:                umap: Not installed
2024-01-03 18:46:21,834:INFO:     ydata_profiling: Not installed
2024-01-03 18:46:21,834:INFO:  explainerdashboard: Not installed
2024-01-03 18:46:21,834:INFO:             autoviz: Not installed
2024-01-03 18:46:21,834:INFO:           fairlearn: Not installed
2024-01-03 18:46:21,834:INFO:          deepchecks: Not installed
2024-01-03 18:46:21,834:INFO:             xgboost: Not installed
2024-01-03 18:46:21,834:INFO:            catboost: Not installed
2024-01-03 18:46:21,834:INFO:              kmodes: Not installed
2024-01-03 18:46:21,834:INFO:             mlxtend: 0.23.0
2024-01-03 18:46:21,834:INFO:       statsforecast: Not installed
2024-01-03 18:46:21,834:INFO:        tune_sklearn: Not installed
2024-01-03 18:46:21,835:INFO:                 ray: Not installed
2024-01-03 18:46:21,835:INFO:            hyperopt: Not installed
2024-01-03 18:46:21,835:INFO:              optuna: Not installed
2024-01-03 18:46:21,835:INFO:               skopt: Not installed
2024-01-03 18:46:21,835:INFO:              mlflow: Not installed
2024-01-03 18:46:21,835:INFO:              gradio: Not installed
2024-01-03 18:46:21,835:INFO:             fastapi: Not installed
2024-01-03 18:46:21,835:INFO:             uvicorn: Not installed
2024-01-03 18:46:21,835:INFO:              m2cgen: Not installed
2024-01-03 18:46:21,835:INFO:           evidently: Not installed
2024-01-03 18:46:21,835:INFO:               fugue: Not installed
2024-01-03 18:46:21,835:INFO:           streamlit: Not installed
2024-01-03 18:46:21,835:INFO:             prophet: Not installed
2024-01-03 18:46:21,835:INFO:None
2024-01-03 18:46:21,835:INFO:Set up data.
2024-01-03 18:46:21,858:INFO:Set up folding strategy.
2024-01-03 18:46:21,858:INFO:Set up train/test split.
2024-01-03 18:46:21,858:INFO:Set up data.
2024-01-03 18:46:21,871:INFO:Set up index.
2024-01-03 18:46:21,871:INFO:Assigning column types.
2024-01-03 18:46:21,874:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:46:21,908:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:46:21,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:46:21,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:21,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:21,961:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:46:21,962:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:46:21,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:21,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:21,982:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:46:22,014:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:46:22,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,066:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:46:22,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,086:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:46:22,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,193:INFO:Preparing preprocessing pipeline...
2024-01-03 18:46:22,194:INFO:Set up label encoding.
2024-01-03 18:46:22,194:INFO:Set up simple imputation.
2024-01-03 18:46:22,199:INFO:Set up encoding of categorical features.
2024-01-03 18:46:22,286:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:46:22,290:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:46:22,290:INFO:Creating final display dataframe.
2024-01-03 18:46:22,523:INFO:Setup _display_container:                     Description             Value
0                    Session id              1641
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (18264, 2)
5        Transformed data shape        (18264, 2)
6   Transformed train set shape        (14483, 2)
7    Transformed test set shape         (3781, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              da0a
2024-01-03 18:46:22,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:46:22,633:INFO:setup() successfully completed in 0.8s...............
2024-01-03 18:46:22,633:INFO:Initializing create_model()
2024-01-03 18:46:22,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:46:22,633:INFO:Checking exceptions
2024-01-03 18:46:22,635:INFO:Importing libraries
2024-01-03 18:46:22,635:INFO:Copying training dataset
2024-01-03 18:46:22,639:INFO:Defining folds
2024-01-03 18:46:22,639:INFO:Declaring metric variables
2024-01-03 18:46:22,639:INFO:Importing untrained model
2024-01-03 18:46:22,639:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:46:22,639:INFO:Starting cross validation
2024-01-03 18:46:22,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:46:22,891:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,893:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,901:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,901:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,905:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,907:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,916:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,916:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:22,918:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,920:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,922:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,924:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:22,926:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:22,930:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,932:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,985:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,994:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:22,999:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,007:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:23,007:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,013:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,015:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:23,022:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,046:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,055:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,059:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,067:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:23,068:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,072:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,076:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:23,081:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,127:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,128:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,140:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:23,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:23,152:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,152:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:23,171:INFO:Calculating mean and std
2024-01-03 18:46:23,171:INFO:Creating metrics dataframe
2024-01-03 18:46:23,173:INFO:Finalizing model
2024-01-03 18:46:23,227:INFO:[LightGBM] [Info] Number of positive: 5009, number of negative: 9474
2024-01-03 18:46:23,228:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000059 seconds.
2024-01-03 18:46:23,228:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:23,228:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:23,228:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:46:23,228:INFO:[LightGBM] [Info] Number of data points in the train set: 14483, number of used features: 1
2024-01-03 18:46:23,228:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345854 -> initscore=-0.637315
2024-01-03 18:46:23,229:INFO:[LightGBM] [Info] Start training from score -0.637315
2024-01-03 18:46:23,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:23,253:INFO:Uploading results into container
2024-01-03 18:46:23,253:INFO:Uploading model into container now
2024-01-03 18:46:23,254:INFO:_master_model_container: 1
2024-01-03 18:46:23,254:INFO:_display_container: 2
2024-01-03 18:46:23,254:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1641, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:46:23,254:INFO:create_model() successfully completed......................................
2024-01-03 18:46:23,550:INFO:Initializing tune_model()
2024-01-03 18:46:23,550:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1641, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=True, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-01-03 18:46:23,550:INFO:Checking exceptions
2024-01-03 18:46:23,565:INFO:Copying training dataset
2024-01-03 18:46:23,571:INFO:Checking base model
2024-01-03 18:46:23,571:INFO:Base model : Light Gradient Boosting Machine
2024-01-03 18:46:23,574:INFO:Declaring metric variables
2024-01-03 18:46:23,577:INFO:Defining Hyperparameters
2024-01-03 18:46:23,829:INFO:Tuning with n_jobs=-1
2024-01-03 18:46:23,829:INFO:Initializing RandomizedSearchCV
2024-01-03 18:46:30,107:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 60, 'actual_estimator__n_estimators': 110, 'actual_estimator__min_split_gain': 0, 'actual_estimator__min_child_samples': 16, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-01-03 18:46:30,108:INFO:Hyperparameter search completed
2024-01-03 18:46:30,108:INFO:SubProcess create_model() called ==================================
2024-01-03 18:46:30,109:INFO:Initializing create_model()
2024-01-03 18:46:30,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1641, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08AC2E190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.05, 'reg_alpha': 0.4, 'num_leaves': 60, 'n_estimators': 110, 'min_split_gain': 0, 'min_child_samples': 16, 'learning_rate': 0.001, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-01-03 18:46:30,109:INFO:Checking exceptions
2024-01-03 18:46:30,110:INFO:Importing libraries
2024-01-03 18:46:30,110:INFO:Copying training dataset
2024-01-03 18:46:30,118:INFO:Defining folds
2024-01-03 18:46:30,118:INFO:Declaring metric variables
2024-01-03 18:46:30,121:INFO:Importing untrained model
2024-01-03 18:46:30,121:INFO:Declaring custom model
2024-01-03 18:46:30,125:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:46:30,131:INFO:Starting cross validation
2024-01-03 18:46:30,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:46:30,533:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,535:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,538:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,548:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,549:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,550:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,553:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,557:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,559:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,562:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,564:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,564:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,565:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,569:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,573:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,580:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,604:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,627:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,634:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,652:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,669:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,677:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,679:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,686:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,692:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,702:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,708:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,710:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,738:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,792:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,794:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,806:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,807:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,814:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,815:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:30,820:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,820:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:30,840:INFO:Calculating mean and std
2024-01-03 18:46:30,841:INFO:Creating metrics dataframe
2024-01-03 18:46:30,847:INFO:Finalizing model
2024-01-03 18:46:30,901:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:30,901:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:30,901:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:30,905:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:30,905:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:30,905:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:30,905:INFO:[LightGBM] [Info] Number of positive: 5009, number of negative: 9474
2024-01-03 18:46:30,905:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000060 seconds.
2024-01-03 18:46:30,905:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:30,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:30,905:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:46:30,905:INFO:[LightGBM] [Info] Number of data points in the train set: 14483, number of used features: 1
2024-01-03 18:46:30,905:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345854 -> initscore=-0.637315
2024-01-03 18:46:30,906:INFO:[LightGBM] [Info] Start training from score -0.637315
2024-01-03 18:46:30,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:30,951:INFO:Uploading results into container
2024-01-03 18:46:30,952:INFO:Uploading model into container now
2024-01-03 18:46:30,952:INFO:_master_model_container: 2
2024-01-03 18:46:30,952:INFO:_display_container: 3
2024-01-03 18:46:30,953:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0,
               n_estimators=110, n_jobs=-1, num_leaves=60, objective=None,
               random_state=1641, reg_alpha=0.4, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:46:30,953:INFO:create_model() successfully completed......................................
2024-01-03 18:46:31,249:INFO:SubProcess create_model() end ==================================
2024-01-03 18:46:31,249:INFO:choose_better activated
2024-01-03 18:46:31,252:INFO:SubProcess create_model() called ==================================
2024-01-03 18:46:31,252:INFO:Initializing create_model()
2024-01-03 18:46:31,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1641, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:46:31,253:INFO:Checking exceptions
2024-01-03 18:46:31,254:INFO:Importing libraries
2024-01-03 18:46:31,254:INFO:Copying training dataset
2024-01-03 18:46:31,259:INFO:Defining folds
2024-01-03 18:46:31,259:INFO:Declaring metric variables
2024-01-03 18:46:31,259:INFO:Importing untrained model
2024-01-03 18:46:31,259:INFO:Declaring custom model
2024-01-03 18:46:31,260:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:46:31,261:INFO:Starting cross validation
2024-01-03 18:46:31,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:46:31,551:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,552:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,557:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,566:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,567:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,570:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,576:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,578:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,579:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,580:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,584:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,585:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,586:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,589:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,593:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,595:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,661:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,667:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,678:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,682:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,692:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,694:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,698:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,736:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,750:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,751:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,759:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,765:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,765:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,774:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,780:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,815:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,819:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,829:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,832:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,837:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,839:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:31,843:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,845:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:31,864:INFO:Calculating mean and std
2024-01-03 18:46:31,864:INFO:Creating metrics dataframe
2024-01-03 18:46:31,866:INFO:Finalizing model
2024-01-03 18:46:31,917:INFO:[LightGBM] [Info] Number of positive: 5009, number of negative: 9474
2024-01-03 18:46:31,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.
2024-01-03 18:46:31,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:31,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:31,918:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:46:31,918:INFO:[LightGBM] [Info] Number of data points in the train set: 14483, number of used features: 1
2024-01-03 18:46:31,918:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345854 -> initscore=-0.637315
2024-01-03 18:46:31,918:INFO:[LightGBM] [Info] Start training from score -0.637315
2024-01-03 18:46:31,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:31,945:INFO:Uploading results into container
2024-01-03 18:46:31,945:INFO:Uploading model into container now
2024-01-03 18:46:31,946:INFO:_master_model_container: 3
2024-01-03 18:46:31,946:INFO:_display_container: 4
2024-01-03 18:46:31,946:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1641, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:46:31,946:INFO:create_model() successfully completed......................................
2024-01-03 18:46:32,220:INFO:SubProcess create_model() end ==================================
2024-01-03 18:46:32,221:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1641, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.4074
2024-01-03 18:46:32,221:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0,
               n_estimators=110, n_jobs=-1, num_leaves=60, objective=None,
               random_state=1641, reg_alpha=0.4, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6541
2024-01-03 18:46:32,221:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0,
               n_estimators=110, n_jobs=-1, num_leaves=60, objective=None,
               random_state=1641, reg_alpha=0.4, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-03 18:46:32,221:INFO:choose_better completed
2024-01-03 18:46:32,229:INFO:_master_model_container: 3
2024-01-03 18:46:32,229:INFO:_display_container: 3
2024-01-03 18:46:32,229:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0,
               n_estimators=110, n_jobs=-1, num_leaves=60, objective=None,
               random_state=1641, reg_alpha=0.4, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:46:32,230:INFO:tune_model() successfully completed......................................
2024-01-03 18:46:32,494:INFO:Initializing calibrate_model()
2024-01-03 18:46:32,494:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0,
               n_estimators=110, n_jobs=-1, num_leaves=60, objective=None,
               random_state=1641, reg_alpha=0.4, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=sigmoid, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2024-01-03 18:46:32,494:INFO:Checking exceptions
2024-01-03 18:46:32,497:INFO:Preloading libraries
2024-01-03 18:46:32,497:INFO:Preparing display monitor
2024-01-03 18:46:32,545:INFO:Getting model name
2024-01-03 18:46:32,546:INFO:Base model : Light Gradient Boosting Machine
2024-01-03 18:46:32,554:INFO:Importing untrained CalibratedClassifierCV
2024-01-03 18:46:32,554:INFO:SubProcess create_model() called ==================================
2024-01-03 18:46:32,556:INFO:Initializing create_model()
2024-01-03 18:46:32,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.5,
                                                     importance_type='split',
                                                     learning_rate=0.001,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0,
                                                     n_estimators=110,
                                                     n_jobs=-1, num_leaves=60,
                                                     objective=None,
                                                     random_state=1641,
                                                     reg_alpha=0.4,
                                                     reg_lambda=0.05,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C088F17950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:46:32,556:INFO:Checking exceptions
2024-01-03 18:46:32,556:INFO:Importing libraries
2024-01-03 18:46:32,557:INFO:Copying training dataset
2024-01-03 18:46:32,565:INFO:Defining folds
2024-01-03 18:46:32,565:INFO:Declaring metric variables
2024-01-03 18:46:32,569:INFO:Importing untrained model
2024-01-03 18:46:32,569:INFO:Declaring custom model
2024-01-03 18:46:32,573:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:46:32,579:INFO:Starting cross validation
2024-01-03 18:46:32,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:46:32,679:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:32,682:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:32,696:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:32,717:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:32,723:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:32,733:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:32,742:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:34,014:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,032:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,034:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,041:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,048:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,049:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,058:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,064:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,070:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,086:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,103:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,142:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:34,151:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,157:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:34,161:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,168:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,176:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,177:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,183:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,185:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,191:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,254:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,270:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,280:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,286:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,304:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,319:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,322:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,328:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,334:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,337:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,345:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,351:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,757:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,766:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,771:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,779:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,779:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,785:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,788:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:46:34,794:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:46:34,813:INFO:Calculating mean and std
2024-01-03 18:46:34,814:INFO:Creating metrics dataframe
2024-01-03 18:46:34,819:INFO:Finalizing model
2024-01-03 18:46:34,870:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:34,874:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:34,874:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:34,875:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:34,877:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:34,877:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:34,877:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:34,877:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:46:34,877:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.
2024-01-03 18:46:34,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:34,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:34,878:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:46:34,878:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:46:34,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:46:34,878:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:46:34,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,907:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:34,907:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:34,907:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:34,931:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:34,931:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:34,931:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:34,934:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:34,934:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:34,934:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:34,934:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:46:34,934:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.
2024-01-03 18:46:34,934:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:34,934:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:34,934:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:46:34,934:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:46:34,935:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:46:34,935:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:46:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,965:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:34,965:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:34,965:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:34,987:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:34,987:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:34,987:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:34,990:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:34,990:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:34,990:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:34,990:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:46:34,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.
2024-01-03 18:46:34,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:34,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:34,990:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:46:34,991:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:46:34,991:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:46:34,991:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:46:34,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:34,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,018:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,018:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,018:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,040:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,043:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,043:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,043:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,043:INFO:[LightGBM] [Info] Number of positive: 4008, number of negative: 7579
2024-01-03 18:46:35,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.
2024-01-03 18:46:35,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:35,043:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:35,043:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:46:35,044:INFO:[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1
2024-01-03 18:46:35,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345905 -> initscore=-0.637089
2024-01-03 18:46:35,044:INFO:[LightGBM] [Info] Start training from score -0.637089
2024-01-03 18:46:35,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,073:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,073:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,073:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,095:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,096:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,096:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,098:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,098:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,098:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,098:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7580
2024-01-03 18:46:35,098:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.
2024-01-03 18:46:35,098:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:35,098:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:35,098:INFO:[LightGBM] [Info] Total Bins 4
2024-01-03 18:46:35,098:INFO:[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1
2024-01-03 18:46:35,099:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345819 -> initscore=-0.637470
2024-01-03 18:46:35,099:INFO:[LightGBM] [Info] Start training from score -0.637470
2024-01-03 18:46:35,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,125:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,125:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,125:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,145:INFO:Uploading results into container
2024-01-03 18:46:35,146:INFO:Uploading model into container now
2024-01-03 18:46:35,147:INFO:_master_model_container: 4
2024-01-03 18:46:35,147:INFO:_display_container: 4
2024-01-03 18:46:35,148:INFO:CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.5,
                                                     importance_type='split',
                                                     learning_rate=0.001,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0,
                                                     n_estimators=110,
                                                     n_jobs=-1, num_leaves=60,
                                                     objective=None,
                                                     random_state=1641,
                                                     reg_alpha=0.4,
                                                     reg_lambda=0.05,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:46:35,148:INFO:create_model() successfully completed......................................
2024-01-03 18:46:35,422:INFO:SubProcess create_model() end ==================================
2024-01-03 18:46:35,434:INFO:_master_model_container: 4
2024-01-03 18:46:35,434:INFO:_display_container: 4
2024-01-03 18:46:35,435:INFO:CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.5,
                                                     importance_type='split',
                                                     learning_rate=0.001,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0,
                                                     n_estimators=110,
                                                     n_jobs=-1, num_leaves=60,
                                                     objective=None,
                                                     random_state=1641,
                                                     reg_alpha=0.4,
                                                     reg_lambda=0.05,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:46:35,435:INFO:calibrate_model() successfully completed......................................
2024-01-03 18:46:35,693:INFO:Initializing finalize_model()
2024-01-03 18:46:35,693:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.5,
                                                     importance_type='split',
                                                     learning_rate=0.001,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0,
                                                     n_estimators=110,
                                                     n_jobs=-1, num_leaves=60,
                                                     objective=None,
                                                     random_state=1641,
                                                     reg_alpha=0.4,
                                                     reg_lambda=0.05,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-03 18:46:35,694:INFO:Finalizing CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.5,
                                                     importance_type='split',
                                                     learning_rate=0.001,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0,
                                                     n_estimators=110,
                                                     n_jobs=-1, num_leaves=60,
                                                     objective=None,
                                                     random_state=1641,
                                                     reg_alpha=0.4,
                                                     reg_lambda=0.05,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:46:35,697:INFO:Initializing create_model()
2024-01-03 18:46:35,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.5,
                                                     importance_type='split',
                                                     learning_rate=0.001,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0,
                                                     n_estimators=110,
                                                     n_jobs=-1, num_leaves=60,
                                                     objective=None,
                                                     random_state=1641,
                                                     reg_alpha=0.4,
                                                     reg_lambda=0.05,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:46:35,698:INFO:Checking exceptions
2024-01-03 18:46:35,699:INFO:Importing libraries
2024-01-03 18:46:35,699:INFO:Copying training dataset
2024-01-03 18:46:35,699:INFO:Defining folds
2024-01-03 18:46:35,699:INFO:Declaring metric variables
2024-01-03 18:46:35,700:INFO:Importing untrained model
2024-01-03 18:46:35,700:INFO:Declaring custom model
2024-01-03 18:46:35,700:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:46:35,701:INFO:Cross validation set to False
2024-01-03 18:46:35,701:INFO:Fitting Model
2024-01-03 18:46:35,738:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:46:35,742:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,742:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,742:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,743:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,743:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,744:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,744:INFO:[LightGBM] [Info] Number of positive: 4981, number of negative: 9630
2024-01-03 18:46:35,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000056 seconds.
2024-01-03 18:46:35,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:35,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:35,744:INFO:[LightGBM] [Info] Total Bins 6
2024-01-03 18:46:35,744:INFO:[LightGBM] [Info] Number of data points in the train set: 14611, number of used features: 1
2024-01-03 18:46:35,744:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340908 -> initscore=-0.659253
2024-01-03 18:46:35,744:INFO:[LightGBM] [Info] Start training from score -0.659253
2024-01-03 18:46:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,773:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,773:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,773:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,799:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,799:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,799:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,801:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,801:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,802:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,802:INFO:[LightGBM] [Info] Number of positive: 4981, number of negative: 9630
2024-01-03 18:46:35,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.
2024-01-03 18:46:35,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:35,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:35,802:INFO:[LightGBM] [Info] Total Bins 6
2024-01-03 18:46:35,802:INFO:[LightGBM] [Info] Number of data points in the train set: 14611, number of used features: 1
2024-01-03 18:46:35,802:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340908 -> initscore=-0.659253
2024-01-03 18:46:35,802:INFO:[LightGBM] [Info] Start training from score -0.659253
2024-01-03 18:46:35,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,828:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,829:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,829:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,854:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,854:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,854:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,856:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,857:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,857:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,857:INFO:[LightGBM] [Info] Number of positive: 4981, number of negative: 9630
2024-01-03 18:46:35,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.
2024-01-03 18:46:35,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:35,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:35,857:INFO:[LightGBM] [Info] Total Bins 6
2024-01-03 18:46:35,857:INFO:[LightGBM] [Info] Number of data points in the train set: 14611, number of used features: 1
2024-01-03 18:46:35,857:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340908 -> initscore=-0.659253
2024-01-03 18:46:35,857:INFO:[LightGBM] [Info] Start training from score -0.659253
2024-01-03 18:46:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,886:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,886:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,887:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,914:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,914:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,914:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,917:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,917:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,917:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,917:INFO:[LightGBM] [Info] Number of positive: 4980, number of negative: 9631
2024-01-03 18:46:35,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.
2024-01-03 18:46:35,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:35,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:35,917:INFO:[LightGBM] [Info] Total Bins 6
2024-01-03 18:46:35,918:INFO:[LightGBM] [Info] Number of data points in the train set: 14611, number of used features: 1
2024-01-03 18:46:35,918:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340839 -> initscore=-0.659557
2024-01-03 18:46:35,918:INFO:[LightGBM] [Info] Start training from score -0.659557
2024-01-03 18:46:35,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,950:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,950:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,950:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,978:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,978:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,978:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,981:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:35,981:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:35,981:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:35,981:INFO:[LightGBM] [Info] Number of positive: 4981, number of negative: 9631
2024-01-03 18:46:35,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.
2024-01-03 18:46:35,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:46:35,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:46:35,981:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:46:35,982:INFO:[LightGBM] [Info] Number of data points in the train set: 14612, number of used features: 1
2024-01-03 18:46:35,982:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340884 -> initscore=-0.659356
2024-01-03 18:46:35,982:INFO:[LightGBM] [Info] Start training from score -0.659356
2024-01-03 18:46:35,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:35,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:46:36,011:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,011:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,011:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,043:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.001,
                                                                      max_depth=-1,
                                                                      min_child_samples=16,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0,
                                                                      n_estimators=110,
                                                                      n_jobs=-1,
                                                                      num_leaves=60,
                                                                      objective=None,
                                                                      random_state=1641,
                                                                      reg_alpha=0.4,
                                                                      reg_lambda=0.05,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-01-03 18:46:36,043:INFO:create_model() successfully completed......................................
2024-01-03 18:46:36,315:INFO:_master_model_container: 4
2024-01-03 18:46:36,315:INFO:_display_container: 4
2024-01-03 18:46:36,321:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.001,
                                                                      max_depth=-1,
                                                                      min_child_samples=16,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0,
                                                                      n_estimators=110,
                                                                      n_jobs=-1,
                                                                      num_leaves=60,
                                                                      objective=None,
                                                                      random_state=1641,
                                                                      reg_alpha=0.4,
                                                                      reg_lambda=0.05,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-01-03 18:46:36,322:INFO:finalize_model() successfully completed......................................
2024-01-03 18:46:36,577:INFO:Initializing plot_model()
2024-01-03 18:46:36,577:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0821BE990>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.001,
                                                                      max_depth=-1,
                                                                      min_child_samples=16,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0,
                                                                      n_estimators=110,
                                                                      n_jobs=-1,
                                                                      num_leaves=60,
                                                                      objective=None,
                                                                      random_state=1641,
                                                                      reg_alpha=0.4,
                                                                      reg_lambda=0.05,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-01-03 18:46:36,577:INFO:Checking exceptions
2024-01-03 18:46:36,581:INFO:Preloading libraries
2024-01-03 18:46:36,598:INFO:Copying training dataset
2024-01-03 18:46:36,598:INFO:Plot type: confusion_matrix
2024-01-03 18:46:36,882:INFO:Fitting Model
2024-01-03 18:46:36,883:INFO:Scoring test/hold-out set
2024-01-03 18:46:36,883:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,883:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,883:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,889:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,889:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,889:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,895:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,895:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,895:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,900:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,900:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,900:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,906:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,906:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,906:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,913:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,913:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,913:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,919:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,919:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,919:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,925:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,925:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,925:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,930:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,930:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,930:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:36,936:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-03 18:46:36,936:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:46:36,936:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:46:37,041:INFO:Visual Rendered Successfully
2024-01-03 18:46:37,314:INFO:plot_model() successfully completed......................................
2024-01-03 18:47:23,983:INFO:PyCaret ClassificationExperiment
2024-01-03 18:47:23,983:INFO:Logging name: clf-default-name
2024-01-03 18:47:23,984:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:47:23,984:INFO:version 3.2.0
2024-01-03 18:47:23,984:INFO:Initializing setup()
2024-01-03 18:47:23,984:INFO:self.USI: 9408
2024-01-03 18:47:23,984:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:47:23,984:INFO:Checking environment
2024-01-03 18:47:23,984:INFO:python_version: 3.11.5
2024-01-03 18:47:23,984:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:47:23,984:INFO:machine: AMD64
2024-01-03 18:47:23,984:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:47:23,984:INFO:Memory: svmem(total=16893386752, available=3517415424, percent=79.2, used=13375971328, free=3517415424)
2024-01-03 18:47:23,984:INFO:Physical Core: 4
2024-01-03 18:47:23,984:INFO:Logical Core: 8
2024-01-03 18:47:23,984:INFO:Checking libraries
2024-01-03 18:47:23,984:INFO:System:
2024-01-03 18:47:23,984:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:47:23,984:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:47:23,984:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:47:23,984:INFO:PyCaret required dependencies:
2024-01-03 18:47:23,984:INFO:                 pip: 23.3.1
2024-01-03 18:47:23,984:INFO:          setuptools: 68.2.2
2024-01-03 18:47:23,984:INFO:             pycaret: 3.2.0
2024-01-03 18:47:23,985:INFO:             IPython: 8.15.0
2024-01-03 18:47:23,985:INFO:          ipywidgets: 8.0.4
2024-01-03 18:47:23,985:INFO:                tqdm: 4.66.1
2024-01-03 18:47:23,985:INFO:               numpy: 1.25.2
2024-01-03 18:47:23,985:INFO:              pandas: 1.5.3
2024-01-03 18:47:23,985:INFO:              jinja2: 3.1.2
2024-01-03 18:47:23,985:INFO:               scipy: 1.10.1
2024-01-03 18:47:23,985:INFO:              joblib: 1.2.0
2024-01-03 18:47:23,985:INFO:             sklearn: 1.2.2
2024-01-03 18:47:23,985:INFO:                pyod: 1.1.2
2024-01-03 18:47:23,985:INFO:            imblearn: 0.11.0
2024-01-03 18:47:23,985:INFO:   category_encoders: 2.6.3
2024-01-03 18:47:23,985:INFO:            lightgbm: 4.2.0
2024-01-03 18:47:23,985:INFO:               numba: 0.58.1
2024-01-03 18:47:23,985:INFO:            requests: 2.31.0
2024-01-03 18:47:23,985:INFO:          matplotlib: 3.6.0
2024-01-03 18:47:23,985:INFO:          scikitplot: 0.3.7
2024-01-03 18:47:23,985:INFO:         yellowbrick: 1.5
2024-01-03 18:47:23,985:INFO:              plotly: 5.18.0
2024-01-03 18:47:23,985:INFO:    plotly-resampler: Not installed
2024-01-03 18:47:23,985:INFO:             kaleido: 0.2.1
2024-01-03 18:47:23,985:INFO:           schemdraw: 0.15
2024-01-03 18:47:23,985:INFO:         statsmodels: 0.14.1
2024-01-03 18:47:23,985:INFO:              sktime: 0.21.1
2024-01-03 18:47:23,985:INFO:               tbats: 1.1.3
2024-01-03 18:47:23,985:INFO:            pmdarima: 2.0.4
2024-01-03 18:47:23,985:INFO:              psutil: 5.9.0
2024-01-03 18:47:23,985:INFO:          markupsafe: 2.1.1
2024-01-03 18:47:23,985:INFO:             pickle5: Not installed
2024-01-03 18:47:23,985:INFO:         cloudpickle: 3.0.0
2024-01-03 18:47:23,985:INFO:         deprecation: 2.1.0
2024-01-03 18:47:23,985:INFO:              xxhash: 3.4.1
2024-01-03 18:47:23,985:INFO:           wurlitzer: Not installed
2024-01-03 18:47:23,986:INFO:PyCaret optional dependencies:
2024-01-03 18:47:23,986:INFO:                shap: Not installed
2024-01-03 18:47:23,986:INFO:           interpret: Not installed
2024-01-03 18:47:23,986:INFO:                umap: Not installed
2024-01-03 18:47:23,986:INFO:     ydata_profiling: Not installed
2024-01-03 18:47:23,986:INFO:  explainerdashboard: Not installed
2024-01-03 18:47:23,986:INFO:             autoviz: Not installed
2024-01-03 18:47:23,986:INFO:           fairlearn: Not installed
2024-01-03 18:47:23,986:INFO:          deepchecks: Not installed
2024-01-03 18:47:23,986:INFO:             xgboost: Not installed
2024-01-03 18:47:23,986:INFO:            catboost: Not installed
2024-01-03 18:47:23,986:INFO:              kmodes: Not installed
2024-01-03 18:47:23,986:INFO:             mlxtend: 0.23.0
2024-01-03 18:47:23,986:INFO:       statsforecast: Not installed
2024-01-03 18:47:23,986:INFO:        tune_sklearn: Not installed
2024-01-03 18:47:23,986:INFO:                 ray: Not installed
2024-01-03 18:47:23,986:INFO:            hyperopt: Not installed
2024-01-03 18:47:23,986:INFO:              optuna: Not installed
2024-01-03 18:47:23,986:INFO:               skopt: Not installed
2024-01-03 18:47:23,986:INFO:              mlflow: Not installed
2024-01-03 18:47:23,986:INFO:              gradio: Not installed
2024-01-03 18:47:23,986:INFO:             fastapi: Not installed
2024-01-03 18:47:23,986:INFO:             uvicorn: Not installed
2024-01-03 18:47:23,986:INFO:              m2cgen: Not installed
2024-01-03 18:47:23,986:INFO:           evidently: Not installed
2024-01-03 18:47:23,986:INFO:               fugue: Not installed
2024-01-03 18:47:23,986:INFO:           streamlit: Not installed
2024-01-03 18:47:23,986:INFO:             prophet: Not installed
2024-01-03 18:47:23,986:INFO:None
2024-01-03 18:47:23,986:INFO:Set up data.
2024-01-03 18:47:24,006:INFO:Set up folding strategy.
2024-01-03 18:47:24,006:INFO:Set up train/test split.
2024-01-03 18:47:24,006:INFO:Set up data.
2024-01-03 18:47:24,029:INFO:Set up index.
2024-01-03 18:47:24,029:INFO:Assigning column types.
2024-01-03 18:47:24,034:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:47:24,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:47:24,087:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:47:24,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:47:24,142:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:47:24,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,162:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:47:24,195:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:47:24,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,250:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:47:24,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,271:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:47:24,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,379:INFO:Preparing preprocessing pipeline...
2024-01-03 18:47:24,380:INFO:Set up label encoding.
2024-01-03 18:47:24,380:INFO:Set up simple imputation.
2024-01-03 18:47:24,385:INFO:Set up encoding of categorical features.
2024-01-03 18:47:24,469:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:47:24,473:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:47:24,473:INFO:Creating final display dataframe.
2024-01-03 18:47:24,712:INFO:Setup _display_container:                     Description             Value
0                    Session id              2882
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (18264, 2)
5        Transformed data shape        (18264, 2)
6   Transformed train set shape        (14483, 2)
7    Transformed test set shape         (3781, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              9408
2024-01-03 18:47:24,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:47:24,822:INFO:setup() successfully completed in 0.84s...............
2024-01-03 18:47:24,823:INFO:Initializing compare_models()
2024-01-03 18:47:24,823:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-03 18:47:24,823:INFO:Checking exceptions
2024-01-03 18:47:24,827:INFO:Preparing display monitor
2024-01-03 18:47:24,848:INFO:Initializing Logistic Regression
2024-01-03 18:47:24,848:INFO:Total runtime is 0.0 minutes
2024-01-03 18:47:24,851:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:24,852:INFO:Initializing create_model()
2024-01-03 18:47:24,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:24,852:INFO:Checking exceptions
2024-01-03 18:47:24,852:INFO:Importing libraries
2024-01-03 18:47:24,852:INFO:Copying training dataset
2024-01-03 18:47:24,858:INFO:Defining folds
2024-01-03 18:47:24,858:INFO:Declaring metric variables
2024-01-03 18:47:24,861:INFO:Importing untrained model
2024-01-03 18:47:24,864:INFO:Logistic Regression Imported successfully
2024-01-03 18:47:24,868:INFO:Starting cross validation
2024-01-03 18:47:24,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:25,012:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,029:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,029:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,029:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,037:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,045:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,045:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,047:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,048:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,050:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,051:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,053:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,059:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,063:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,063:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,064:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,065:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,067:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,068:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,074:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,079:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,081:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,082:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,083:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,086:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,087:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,089:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,093:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,094:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,099:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,100:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,155:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,156:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,161:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,165:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,165:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,169:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:25,172:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:25,183:INFO:Calculating mean and std
2024-01-03 18:47:25,183:INFO:Creating metrics dataframe
2024-01-03 18:47:25,186:INFO:Uploading results into container
2024-01-03 18:47:25,186:INFO:Uploading model into container now
2024-01-03 18:47:25,186:INFO:_master_model_container: 1
2024-01-03 18:47:25,186:INFO:_display_container: 2
2024-01-03 18:47:25,187:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2882, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 18:47:25,187:INFO:create_model() successfully completed......................................
2024-01-03 18:47:25,458:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:25,458:INFO:Creating metrics dataframe
2024-01-03 18:47:25,463:INFO:Initializing K Neighbors Classifier
2024-01-03 18:47:25,464:INFO:Total runtime is 0.010265680154164632 minutes
2024-01-03 18:47:25,466:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:25,466:INFO:Initializing create_model()
2024-01-03 18:47:25,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:25,466:INFO:Checking exceptions
2024-01-03 18:47:25,466:INFO:Importing libraries
2024-01-03 18:47:25,466:INFO:Copying training dataset
2024-01-03 18:47:25,471:INFO:Defining folds
2024-01-03 18:47:25,471:INFO:Declaring metric variables
2024-01-03 18:47:25,473:INFO:Importing untrained model
2024-01-03 18:47:25,476:INFO:K Neighbors Classifier Imported successfully
2024-01-03 18:47:25,483:INFO:Starting cross validation
2024-01-03 18:47:25,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:26,362:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,374:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,380:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:26,385:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,397:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,408:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,415:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:26,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,490:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,494:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,538:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,545:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,547:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,551:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,558:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,560:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:26,566:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:26,601:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,601:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,607:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,620:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,628:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:26,638:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,759:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,770:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,777:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:26,821:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,873:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,886:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:26,941:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:26,946:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,075:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,087:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,095:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,123:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,185:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,196:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,202:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,207:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,218:INFO:Calculating mean and std
2024-01-03 18:47:27,219:INFO:Creating metrics dataframe
2024-01-03 18:47:27,222:INFO:Uploading results into container
2024-01-03 18:47:27,223:INFO:Uploading model into container now
2024-01-03 18:47:27,224:INFO:_master_model_container: 2
2024-01-03 18:47:27,224:INFO:_display_container: 2
2024-01-03 18:47:27,224:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 18:47:27,224:INFO:create_model() successfully completed......................................
2024-01-03 18:47:27,484:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:27,484:INFO:Creating metrics dataframe
2024-01-03 18:47:27,492:INFO:Initializing Naive Bayes
2024-01-03 18:47:27,492:INFO:Total runtime is 0.04406989812850952 minutes
2024-01-03 18:47:27,494:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:27,494:INFO:Initializing create_model()
2024-01-03 18:47:27,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:27,495:INFO:Checking exceptions
2024-01-03 18:47:27,495:INFO:Importing libraries
2024-01-03 18:47:27,495:INFO:Copying training dataset
2024-01-03 18:47:27,502:INFO:Defining folds
2024-01-03 18:47:27,502:INFO:Declaring metric variables
2024-01-03 18:47:27,507:INFO:Importing untrained model
2024-01-03 18:47:27,512:INFO:Naive Bayes Imported successfully
2024-01-03 18:47:27,520:INFO:Starting cross validation
2024-01-03 18:47:27,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:27,634:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,644:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,648:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,652:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,657:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,659:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,660:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,663:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,667:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,667:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,670:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,674:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,677:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,678:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,681:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,683:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,685:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,687:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,690:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,694:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,695:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,700:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,705:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,707:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,710:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,715:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,715:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,721:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,721:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,733:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,739:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,762:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,765:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,769:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,773:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,777:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:27,777:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,780:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:27,790:INFO:Calculating mean and std
2024-01-03 18:47:27,791:INFO:Creating metrics dataframe
2024-01-03 18:47:27,793:INFO:Uploading results into container
2024-01-03 18:47:27,794:INFO:Uploading model into container now
2024-01-03 18:47:27,794:INFO:_master_model_container: 3
2024-01-03 18:47:27,794:INFO:_display_container: 2
2024-01-03 18:47:27,794:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 18:47:27,794:INFO:create_model() successfully completed......................................
2024-01-03 18:47:28,059:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:28,059:INFO:Creating metrics dataframe
2024-01-03 18:47:28,069:INFO:Initializing Decision Tree Classifier
2024-01-03 18:47:28,069:INFO:Total runtime is 0.05368512074152628 minutes
2024-01-03 18:47:28,071:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:28,071:INFO:Initializing create_model()
2024-01-03 18:47:28,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:28,071:INFO:Checking exceptions
2024-01-03 18:47:28,072:INFO:Importing libraries
2024-01-03 18:47:28,072:INFO:Copying training dataset
2024-01-03 18:47:28,078:INFO:Defining folds
2024-01-03 18:47:28,078:INFO:Declaring metric variables
2024-01-03 18:47:28,081:INFO:Importing untrained model
2024-01-03 18:47:28,085:INFO:Decision Tree Classifier Imported successfully
2024-01-03 18:47:28,091:INFO:Starting cross validation
2024-01-03 18:47:28,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:28,198:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,202:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,212:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,216:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,217:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,220:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,226:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,227:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,231:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,232:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,238:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,246:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,254:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,260:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,263:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,263:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,265:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,270:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,271:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,276:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,281:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,282:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,283:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,285:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,290:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,290:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,291:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,293:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,295:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,296:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,300:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,332:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,334:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,342:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,343:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,347:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,348:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,350:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,351:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,361:INFO:Calculating mean and std
2024-01-03 18:47:28,362:INFO:Creating metrics dataframe
2024-01-03 18:47:28,364:INFO:Uploading results into container
2024-01-03 18:47:28,365:INFO:Uploading model into container now
2024-01-03 18:47:28,365:INFO:_master_model_container: 4
2024-01-03 18:47:28,365:INFO:_display_container: 2
2024-01-03 18:47:28,366:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2882, splitter='best')
2024-01-03 18:47:28,366:INFO:create_model() successfully completed......................................
2024-01-03 18:47:28,618:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:28,618:INFO:Creating metrics dataframe
2024-01-03 18:47:28,627:INFO:Initializing SVM - Linear Kernel
2024-01-03 18:47:28,627:INFO:Total runtime is 0.06298431555430094 minutes
2024-01-03 18:47:28,630:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:28,631:INFO:Initializing create_model()
2024-01-03 18:47:28,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:28,631:INFO:Checking exceptions
2024-01-03 18:47:28,631:INFO:Importing libraries
2024-01-03 18:47:28,631:INFO:Copying training dataset
2024-01-03 18:47:28,637:INFO:Defining folds
2024-01-03 18:47:28,637:INFO:Declaring metric variables
2024-01-03 18:47:28,640:INFO:Importing untrained model
2024-01-03 18:47:28,644:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 18:47:28,650:INFO:Starting cross validation
2024-01-03 18:47:28,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:28,758:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,759:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,764:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,765:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,779:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,780:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,781:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,786:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,787:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,789:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,790:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,793:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,795:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,795:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,795:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,796:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,800:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,801:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,801:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,802:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,807:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,809:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,810:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,815:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,816:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,815:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,818:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,820:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,823:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,825:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,827:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,827:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,831:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

er, msg_start, len(result))

2024-01-03 18:47:28,833:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,833:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,837:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,841:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,847:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,879:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,882:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,884:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 18:47:28,887:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,889:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,894:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,894:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,897:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,898:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:28,903:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:28,916:INFO:Calculating mean and std
2024-01-03 18:47:28,917:INFO:Creating metrics dataframe
2024-01-03 18:47:28,919:INFO:Uploading results into container
2024-01-03 18:47:28,919:INFO:Uploading model into container now
2024-01-03 18:47:28,920:INFO:_master_model_container: 5
2024-01-03 18:47:28,920:INFO:_display_container: 2
2024-01-03 18:47:28,920:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2882, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 18:47:28,920:INFO:create_model() successfully completed......................................
2024-01-03 18:47:29,168:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:29,168:INFO:Creating metrics dataframe
2024-01-03 18:47:29,177:INFO:Initializing Ridge Classifier
2024-01-03 18:47:29,177:INFO:Total runtime is 0.07215363581975301 minutes
2024-01-03 18:47:29,179:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:29,179:INFO:Initializing create_model()
2024-01-03 18:47:29,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:29,180:INFO:Checking exceptions
2024-01-03 18:47:29,180:INFO:Importing libraries
2024-01-03 18:47:29,180:INFO:Copying training dataset
2024-01-03 18:47:29,186:INFO:Defining folds
2024-01-03 18:47:29,186:INFO:Declaring metric variables
2024-01-03 18:47:29,189:INFO:Importing untrained model
2024-01-03 18:47:29,192:INFO:Ridge Classifier Imported successfully
2024-01-03 18:47:29,197:INFO:Starting cross validation
2024-01-03 18:47:29,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:29,330:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,336:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,350:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,357:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,358:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,360:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,363:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,364:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,366:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,377:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,382:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,382:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,385:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,388:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,391:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,392:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,397:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,398:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,398:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,403:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,404:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,405:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,410:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,411:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,411:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,413:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,417:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,418:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,420:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,422:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,425:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,426:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,428:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,431:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,432:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,432:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,436:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,440:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,446:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,461:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,464:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,472:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,476:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 18:47:29,477:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,479:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,480:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,486:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,490:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:29,492:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:29,503:INFO:Calculating mean and std
2024-01-03 18:47:29,503:INFO:Creating metrics dataframe
2024-01-03 18:47:29,506:INFO:Uploading results into container
2024-01-03 18:47:29,507:INFO:Uploading model into container now
2024-01-03 18:47:29,507:INFO:_master_model_container: 6
2024-01-03 18:47:29,507:INFO:_display_container: 2
2024-01-03 18:47:29,507:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2882, solver='auto',
                tol=0.0001)
2024-01-03 18:47:29,507:INFO:create_model() successfully completed......................................
2024-01-03 18:47:29,776:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:29,776:INFO:Creating metrics dataframe
2024-01-03 18:47:29,784:INFO:Initializing Random Forest Classifier
2024-01-03 18:47:29,784:INFO:Total runtime is 0.08226979970932007 minutes
2024-01-03 18:47:29,787:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:29,787:INFO:Initializing create_model()
2024-01-03 18:47:29,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:29,788:INFO:Checking exceptions
2024-01-03 18:47:29,788:INFO:Importing libraries
2024-01-03 18:47:29,788:INFO:Copying training dataset
2024-01-03 18:47:29,794:INFO:Defining folds
2024-01-03 18:47:29,794:INFO:Declaring metric variables
2024-01-03 18:47:29,798:INFO:Importing untrained model
2024-01-03 18:47:29,802:INFO:Random Forest Classifier Imported successfully
2024-01-03 18:47:29,809:INFO:Starting cross validation
2024-01-03 18:47:29,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:30,265:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,280:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,282:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,296:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,311:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,317:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,318:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,327:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,336:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,342:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,343:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,345:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,354:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,357:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,361:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,363:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,366:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,368:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,375:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,386:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,386:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,397:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,404:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,449:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,459:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,461:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,465:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,467:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,469:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,473:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,477:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,640:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,647:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,652:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,655:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,657:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,661:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:30,663:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,664:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:30,678:INFO:Calculating mean and std
2024-01-03 18:47:30,679:INFO:Creating metrics dataframe
2024-01-03 18:47:30,681:INFO:Uploading results into container
2024-01-03 18:47:30,682:INFO:Uploading model into container now
2024-01-03 18:47:30,682:INFO:_master_model_container: 7
2024-01-03 18:47:30,682:INFO:_display_container: 2
2024-01-03 18:47:30,682:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2882, verbose=0, warm_start=False)
2024-01-03 18:47:30,683:INFO:create_model() successfully completed......................................
2024-01-03 18:47:30,944:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:30,944:INFO:Creating metrics dataframe
2024-01-03 18:47:30,952:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 18:47:30,952:INFO:Total runtime is 0.10173877477645873 minutes
2024-01-03 18:47:30,954:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:30,955:INFO:Initializing create_model()
2024-01-03 18:47:30,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:30,955:INFO:Checking exceptions
2024-01-03 18:47:30,955:INFO:Importing libraries
2024-01-03 18:47:30,955:INFO:Copying training dataset
2024-01-03 18:47:30,961:INFO:Defining folds
2024-01-03 18:47:30,962:INFO:Declaring metric variables
2024-01-03 18:47:30,965:INFO:Importing untrained model
2024-01-03 18:47:30,968:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 18:47:30,974:INFO:Starting cross validation
2024-01-03 18:47:30,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:31,085:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,087:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,099:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,102:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,107:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,108:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,112:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,114:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,118:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,119:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,120:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,124:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,129:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,129:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,135:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,136:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,143:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,144:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,146:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,152:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,154:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,154:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,160:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,160:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,160:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,162:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,171:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,175:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,176:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,183:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,189:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,220:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,225:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,229:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,232:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,236:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,236:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,240:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,250:INFO:Calculating mean and std
2024-01-03 18:47:31,251:INFO:Creating metrics dataframe
2024-01-03 18:47:31,254:INFO:Uploading results into container
2024-01-03 18:47:31,254:INFO:Uploading model into container now
2024-01-03 18:47:31,254:INFO:_master_model_container: 8
2024-01-03 18:47:31,254:INFO:_display_container: 2
2024-01-03 18:47:31,255:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 18:47:31,255:INFO:create_model() successfully completed......................................
2024-01-03 18:47:31,504:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:31,505:INFO:Creating metrics dataframe
2024-01-03 18:47:31,512:INFO:Initializing Ada Boost Classifier
2024-01-03 18:47:31,512:INFO:Total runtime is 0.11107488473256429 minutes
2024-01-03 18:47:31,515:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:31,515:INFO:Initializing create_model()
2024-01-03 18:47:31,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:31,515:INFO:Checking exceptions
2024-01-03 18:47:31,515:INFO:Importing libraries
2024-01-03 18:47:31,516:INFO:Copying training dataset
2024-01-03 18:47:31,520:INFO:Defining folds
2024-01-03 18:47:31,521:INFO:Declaring metric variables
2024-01-03 18:47:31,523:INFO:Importing untrained model
2024-01-03 18:47:31,526:INFO:Ada Boost Classifier Imported successfully
2024-01-03 18:47:31,532:INFO:Starting cross validation
2024-01-03 18:47:31,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:31,685:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,700:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,715:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,838:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,852:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,861:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,867:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,972:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,974:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,986:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,987:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,989:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,995:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:31,997:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,997:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:31,999:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,001:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,003:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,007:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,008:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,009:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,010:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,013:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,015:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,018:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,021:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,022:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,025:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,025:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,027:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,031:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,037:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,039:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,044:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,048:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,191:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,199:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,203:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,206:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,218:INFO:Calculating mean and std
2024-01-03 18:47:32,219:INFO:Creating metrics dataframe
2024-01-03 18:47:32,221:INFO:Uploading results into container
2024-01-03 18:47:32,221:INFO:Uploading model into container now
2024-01-03 18:47:32,221:INFO:_master_model_container: 9
2024-01-03 18:47:32,222:INFO:_display_container: 2
2024-01-03 18:47:32,222:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2882)
2024-01-03 18:47:32,222:INFO:create_model() successfully completed......................................
2024-01-03 18:47:32,469:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:32,469:INFO:Creating metrics dataframe
2024-01-03 18:47:32,477:INFO:Initializing Gradient Boosting Classifier
2024-01-03 18:47:32,477:INFO:Total runtime is 0.12715617815653482 minutes
2024-01-03 18:47:32,479:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:32,479:INFO:Initializing create_model()
2024-01-03 18:47:32,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:32,480:INFO:Checking exceptions
2024-01-03 18:47:32,480:INFO:Importing libraries
2024-01-03 18:47:32,480:INFO:Copying training dataset
2024-01-03 18:47:32,485:INFO:Defining folds
2024-01-03 18:47:32,485:INFO:Declaring metric variables
2024-01-03 18:47:32,489:INFO:Importing untrained model
2024-01-03 18:47:32,492:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 18:47:32,498:INFO:Starting cross validation
2024-01-03 18:47:32,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:32,908:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,908:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,911:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,923:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,924:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,926:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,932:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,933:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,942:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,946:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,956:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,956:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,960:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,961:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,961:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,969:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,972:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,972:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,975:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,975:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,976:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,981:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,984:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,984:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:32,987:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,987:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,990:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:32,991:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,192:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,199:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,201:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,203:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,206:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,209:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,213:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,216:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,226:INFO:Calculating mean and std
2024-01-03 18:47:33,227:INFO:Creating metrics dataframe
2024-01-03 18:47:33,229:INFO:Uploading results into container
2024-01-03 18:47:33,229:INFO:Uploading model into container now
2024-01-03 18:47:33,230:INFO:_master_model_container: 10
2024-01-03 18:47:33,230:INFO:_display_container: 2
2024-01-03 18:47:33,230:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2882, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 18:47:33,230:INFO:create_model() successfully completed......................................
2024-01-03 18:47:33,476:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:33,476:INFO:Creating metrics dataframe
2024-01-03 18:47:33,484:INFO:Initializing Linear Discriminant Analysis
2024-01-03 18:47:33,484:INFO:Total runtime is 0.14393374919891355 minutes
2024-01-03 18:47:33,487:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:33,487:INFO:Initializing create_model()
2024-01-03 18:47:33,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:33,487:INFO:Checking exceptions
2024-01-03 18:47:33,487:INFO:Importing libraries
2024-01-03 18:47:33,487:INFO:Copying training dataset
2024-01-03 18:47:33,494:INFO:Defining folds
2024-01-03 18:47:33,494:INFO:Declaring metric variables
2024-01-03 18:47:33,496:INFO:Importing untrained model
2024-01-03 18:47:33,499:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 18:47:33,504:INFO:Starting cross validation
2024-01-03 18:47:33,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:33,620:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,621:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,625:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,635:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,637:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,639:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,646:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,646:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,648:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,649:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,652:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,652:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,653:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,654:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,662:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,665:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,667:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,667:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,666:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,672:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,676:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,676:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,679:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,680:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,682:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,682:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,687:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,688:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,694:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,696:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,703:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,740:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,743:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,747:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,750:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,751:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,755:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,755:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:33,758:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:33,769:INFO:Calculating mean and std
2024-01-03 18:47:33,770:INFO:Creating metrics dataframe
2024-01-03 18:47:33,773:INFO:Uploading results into container
2024-01-03 18:47:33,773:INFO:Uploading model into container now
2024-01-03 18:47:33,773:INFO:_master_model_container: 11
2024-01-03 18:47:33,773:INFO:_display_container: 2
2024-01-03 18:47:33,774:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 18:47:33,774:INFO:create_model() successfully completed......................................
2024-01-03 18:47:34,020:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:34,020:INFO:Creating metrics dataframe
2024-01-03 18:47:34,031:INFO:Initializing Extra Trees Classifier
2024-01-03 18:47:34,031:INFO:Total runtime is 0.1530528903007507 minutes
2024-01-03 18:47:34,033:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:34,033:INFO:Initializing create_model()
2024-01-03 18:47:34,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:34,034:INFO:Checking exceptions
2024-01-03 18:47:34,034:INFO:Importing libraries
2024-01-03 18:47:34,034:INFO:Copying training dataset
2024-01-03 18:47:34,039:INFO:Defining folds
2024-01-03 18:47:34,039:INFO:Declaring metric variables
2024-01-03 18:47:34,043:INFO:Importing untrained model
2024-01-03 18:47:34,045:INFO:Extra Trees Classifier Imported successfully
2024-01-03 18:47:34,052:INFO:Starting cross validation
2024-01-03 18:47:34,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:34,481:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,486:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,492:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,495:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,496:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,501:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,510:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,511:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,520:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,520:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,522:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,524:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,529:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,536:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,543:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,604:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,608:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,615:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,622:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,627:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,631:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,631:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,633:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,638:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,640:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,647:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,714:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,725:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,736:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,807:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,813:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,814:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,818:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,820:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,821:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,824:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:34,828:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:34,838:INFO:Calculating mean and std
2024-01-03 18:47:34,839:INFO:Creating metrics dataframe
2024-01-03 18:47:34,841:INFO:Uploading results into container
2024-01-03 18:47:34,841:INFO:Uploading model into container now
2024-01-03 18:47:34,841:INFO:_master_model_container: 12
2024-01-03 18:47:34,841:INFO:_display_container: 2
2024-01-03 18:47:34,842:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2882, verbose=0, warm_start=False)
2024-01-03 18:47:34,842:INFO:create_model() successfully completed......................................
2024-01-03 18:47:35,090:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:35,090:INFO:Creating metrics dataframe
2024-01-03 18:47:35,101:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 18:47:35,101:INFO:Total runtime is 0.1708945751190185 minutes
2024-01-03 18:47:35,103:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:35,103:INFO:Initializing create_model()
2024-01-03 18:47:35,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:35,104:INFO:Checking exceptions
2024-01-03 18:47:35,104:INFO:Importing libraries
2024-01-03 18:47:35,104:INFO:Copying training dataset
2024-01-03 18:47:35,111:INFO:Defining folds
2024-01-03 18:47:35,111:INFO:Declaring metric variables
2024-01-03 18:47:35,113:INFO:Importing untrained model
2024-01-03 18:47:35,116:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:47:35,121:INFO:Starting cross validation
2024-01-03 18:47:35,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:35,401:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,408:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,412:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,416:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,416:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,423:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,425:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,427:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,427:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,432:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,433:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,434:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,440:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,450:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,456:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,475:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,489:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,504:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,515:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,530:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,540:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,546:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,565:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,568:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,580:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,582:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,588:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,590:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,594:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,595:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,646:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,646:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,659:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,660:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,668:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,668:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:35,673:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,673:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:35,691:INFO:Calculating mean and std
2024-01-03 18:47:35,692:INFO:Creating metrics dataframe
2024-01-03 18:47:35,696:INFO:Uploading results into container
2024-01-03 18:47:35,696:INFO:Uploading model into container now
2024-01-03 18:47:35,697:INFO:_master_model_container: 13
2024-01-03 18:47:35,697:INFO:_display_container: 2
2024-01-03 18:47:35,698:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2882, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:47:35,698:INFO:create_model() successfully completed......................................
2024-01-03 18:47:35,954:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:35,954:INFO:Creating metrics dataframe
2024-01-03 18:47:35,963:INFO:Initializing Dummy Classifier
2024-01-03 18:47:35,963:INFO:Total runtime is 0.1852464874585469 minutes
2024-01-03 18:47:35,965:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:35,965:INFO:Initializing create_model()
2024-01-03 18:47:35,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08DC10D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:35,965:INFO:Checking exceptions
2024-01-03 18:47:35,966:INFO:Importing libraries
2024-01-03 18:47:35,966:INFO:Copying training dataset
2024-01-03 18:47:35,971:INFO:Defining folds
2024-01-03 18:47:35,971:INFO:Declaring metric variables
2024-01-03 18:47:35,974:INFO:Importing untrained model
2024-01-03 18:47:35,977:INFO:Dummy Classifier Imported successfully
2024-01-03 18:47:35,982:INFO:Starting cross validation
2024-01-03 18:47:35,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:36,075:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,090:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,094:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,099:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,102:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,105:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,109:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,117:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,117:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,119:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,123:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,125:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,125:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,127:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,132:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,138:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,142:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,144:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,149:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,151:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,153:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,153:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,155:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,156:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,157:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,160:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,162:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,168:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,170:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,179:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,185:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,200:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,209:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,210:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,214:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,217:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,218:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,223:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:36,226:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:36,237:INFO:Calculating mean and std
2024-01-03 18:47:36,238:INFO:Creating metrics dataframe
2024-01-03 18:47:36,241:INFO:Uploading results into container
2024-01-03 18:47:36,241:INFO:Uploading model into container now
2024-01-03 18:47:36,242:INFO:_master_model_container: 14
2024-01-03 18:47:36,242:INFO:_display_container: 2
2024-01-03 18:47:36,242:INFO:DummyClassifier(constant=None, random_state=2882, strategy='prior')
2024-01-03 18:47:36,242:INFO:create_model() successfully completed......................................
2024-01-03 18:47:36,490:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:36,490:INFO:Creating metrics dataframe
2024-01-03 18:47:36,504:INFO:Initializing create_model()
2024-01-03 18:47:36,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2882, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:36,504:INFO:Checking exceptions
2024-01-03 18:47:36,505:INFO:Importing libraries
2024-01-03 18:47:36,505:INFO:Copying training dataset
2024-01-03 18:47:36,510:INFO:Defining folds
2024-01-03 18:47:36,511:INFO:Declaring metric variables
2024-01-03 18:47:36,511:INFO:Importing untrained model
2024-01-03 18:47:36,511:INFO:Declaring custom model
2024-01-03 18:47:36,511:INFO:Logistic Regression Imported successfully
2024-01-03 18:47:36,512:INFO:Cross validation set to False
2024-01-03 18:47:36,512:INFO:Fitting Model
2024-01-03 18:47:36,562:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2882, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 18:47:36,562:INFO:create_model() successfully completed......................................
2024-01-03 18:47:36,815:INFO:Initializing create_model()
2024-01-03 18:47:36,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:36,815:INFO:Checking exceptions
2024-01-03 18:47:36,817:INFO:Importing libraries
2024-01-03 18:47:36,817:INFO:Copying training dataset
2024-01-03 18:47:36,824:INFO:Defining folds
2024-01-03 18:47:36,824:INFO:Declaring metric variables
2024-01-03 18:47:36,824:INFO:Importing untrained model
2024-01-03 18:47:36,824:INFO:Declaring custom model
2024-01-03 18:47:36,825:INFO:K Neighbors Classifier Imported successfully
2024-01-03 18:47:36,826:INFO:Cross validation set to False
2024-01-03 18:47:36,826:INFO:Fitting Model
2024-01-03 18:47:36,864:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 18:47:36,864:INFO:create_model() successfully completed......................................
2024-01-03 18:47:37,130:INFO:Initializing create_model()
2024-01-03 18:47:37,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2882, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:37,130:INFO:Checking exceptions
2024-01-03 18:47:37,132:INFO:Importing libraries
2024-01-03 18:47:37,132:INFO:Copying training dataset
2024-01-03 18:47:37,138:INFO:Defining folds
2024-01-03 18:47:37,138:INFO:Declaring metric variables
2024-01-03 18:47:37,138:INFO:Importing untrained model
2024-01-03 18:47:37,138:INFO:Declaring custom model
2024-01-03 18:47:37,139:INFO:Decision Tree Classifier Imported successfully
2024-01-03 18:47:37,139:INFO:Cross validation set to False
2024-01-03 18:47:37,140:INFO:Fitting Model
2024-01-03 18:47:37,182:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2882, splitter='best')
2024-01-03 18:47:37,182:INFO:create_model() successfully completed......................................
2024-01-03 18:47:37,455:INFO:Initializing create_model()
2024-01-03 18:47:37,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2882, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:37,455:INFO:Checking exceptions
2024-01-03 18:47:37,457:INFO:Importing libraries
2024-01-03 18:47:37,457:INFO:Copying training dataset
2024-01-03 18:47:37,463:INFO:Defining folds
2024-01-03 18:47:37,463:INFO:Declaring metric variables
2024-01-03 18:47:37,463:INFO:Importing untrained model
2024-01-03 18:47:37,463:INFO:Declaring custom model
2024-01-03 18:47:37,464:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 18:47:37,465:INFO:Cross validation set to False
2024-01-03 18:47:37,465:INFO:Fitting Model
2024-01-03 18:47:37,503:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2882, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 18:47:37,503:INFO:create_model() successfully completed......................................
2024-01-03 18:47:37,779:INFO:Initializing create_model()
2024-01-03 18:47:37,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2882, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:37,779:INFO:Checking exceptions
2024-01-03 18:47:37,781:INFO:Importing libraries
2024-01-03 18:47:37,781:INFO:Copying training dataset
2024-01-03 18:47:37,786:INFO:Defining folds
2024-01-03 18:47:37,786:INFO:Declaring metric variables
2024-01-03 18:47:37,787:INFO:Importing untrained model
2024-01-03 18:47:37,787:INFO:Declaring custom model
2024-01-03 18:47:37,787:INFO:Ridge Classifier Imported successfully
2024-01-03 18:47:37,788:INFO:Cross validation set to False
2024-01-03 18:47:37,788:INFO:Fitting Model
2024-01-03 18:47:37,824:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2882, solver='auto',
                tol=0.0001)
2024-01-03 18:47:37,824:INFO:create_model() successfully completed......................................
2024-01-03 18:47:38,115:INFO:_master_model_container: 14
2024-01-03 18:47:38,115:INFO:_display_container: 2
2024-01-03 18:47:38,116:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2882, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2882, splitter='best'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2882, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2882, solver='auto',
                tol=0.0001)]
2024-01-03 18:47:38,116:INFO:compare_models() successfully completed......................................
2024-01-03 18:47:38,117:INFO:Initializing create_model()
2024-01-03 18:47:38,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:38,117:INFO:Checking exceptions
2024-01-03 18:47:38,118:INFO:Importing libraries
2024-01-03 18:47:38,118:INFO:Copying training dataset
2024-01-03 18:47:38,123:INFO:Defining folds
2024-01-03 18:47:38,124:INFO:Declaring metric variables
2024-01-03 18:47:38,124:INFO:Importing untrained model
2024-01-03 18:47:38,124:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:47:38,124:INFO:Starting cross validation
2024-01-03 18:47:38,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:38,456:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,465:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,466:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,469:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,479:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,483:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,486:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,486:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,493:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,499:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,500:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,501:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,510:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,516:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,516:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,526:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,527:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,533:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,533:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,594:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,598:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,610:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,615:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,620:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,624:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,626:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,629:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,644:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,658:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,665:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,671:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,738:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,746:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,746:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:38,752:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,752:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:38,771:INFO:Calculating mean and std
2024-01-03 18:47:38,772:INFO:Creating metrics dataframe
2024-01-03 18:47:38,774:INFO:Finalizing model
2024-01-03 18:47:38,831:INFO:[LightGBM] [Info] Number of positive: 5009, number of negative: 9474
2024-01-03 18:47:38,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.
2024-01-03 18:47:38,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:38,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:38,831:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:47:38,831:INFO:[LightGBM] [Info] Number of data points in the train set: 14483, number of used features: 1
2024-01-03 18:47:38,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345854 -> initscore=-0.637315
2024-01-03 18:47:38,832:INFO:[LightGBM] [Info] Start training from score -0.637315
2024-01-03 18:47:38,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:38,870:INFO:Uploading results into container
2024-01-03 18:47:38,870:INFO:Uploading model into container now
2024-01-03 18:47:38,871:INFO:_master_model_container: 15
2024-01-03 18:47:38,871:INFO:_display_container: 3
2024-01-03 18:47:38,871:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2882, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:47:38,872:INFO:create_model() successfully completed......................................
2024-01-03 18:47:39,158:INFO:Initializing tune_model()
2024-01-03 18:47:39,159:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2882, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=True, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-01-03 18:47:39,159:INFO:Checking exceptions
2024-01-03 18:47:39,178:INFO:Copying training dataset
2024-01-03 18:47:39,187:INFO:Checking base model
2024-01-03 18:47:39,187:INFO:Base model : Light Gradient Boosting Machine
2024-01-03 18:47:39,191:INFO:Declaring metric variables
2024-01-03 18:47:39,194:INFO:Defining Hyperparameters
2024-01-03 18:47:39,462:INFO:Tuning with n_jobs=-1
2024-01-03 18:47:39,462:INFO:Initializing RandomizedSearchCV
2024-01-03 18:47:44,982:INFO:best_params: {'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1e-07, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 16, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-01-03 18:47:44,982:INFO:Hyperparameter search completed
2024-01-03 18:47:44,983:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:44,983:INFO:Initializing create_model()
2024-01-03 18:47:44,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2882, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C08BBF4190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.5, 'reg_alpha': 1e-07, 'num_leaves': 150, 'n_estimators': 280, 'min_split_gain': 0.2, 'min_child_samples': 16, 'learning_rate': 0.0005, 'feature_fraction': 0.8, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-01-03 18:47:44,984:INFO:Checking exceptions
2024-01-03 18:47:44,984:INFO:Importing libraries
2024-01-03 18:47:44,984:INFO:Copying training dataset
2024-01-03 18:47:44,992:INFO:Defining folds
2024-01-03 18:47:44,992:INFO:Declaring metric variables
2024-01-03 18:47:44,996:INFO:Importing untrained model
2024-01-03 18:47:44,996:INFO:Declaring custom model
2024-01-03 18:47:45,000:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:47:45,007:INFO:Starting cross validation
2024-01-03 18:47:45,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:45,584:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,588:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,598:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,600:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,603:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,610:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:45,613:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:45,616:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,618:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,627:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:45,634:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,644:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,659:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,668:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:45,676:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,709:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,725:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,734:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:45,740:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,762:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,778:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,782:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,787:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:45,791:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,794:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,798:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,805:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,807:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:45,814:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,814:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:45,820:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,984:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,993:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:45,999:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,006:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:46,007:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,013:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,016:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:46,022:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,042:INFO:Calculating mean and std
2024-01-03 18:47:46,043:INFO:Creating metrics dataframe
2024-01-03 18:47:46,048:INFO:Finalizing model
2024-01-03 18:47:46,109:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:46,109:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:46,109:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:46,114:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:46,114:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:46,114:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:46,114:INFO:[LightGBM] [Info] Number of positive: 5009, number of negative: 9474
2024-01-03 18:47:46,114:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.
2024-01-03 18:47:46,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:46,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:46,115:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:47:46,115:INFO:[LightGBM] [Info] Number of data points in the train set: 14483, number of used features: 1
2024-01-03 18:47:46,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345854 -> initscore=-0.637315
2024-01-03 18:47:46,115:INFO:[LightGBM] [Info] Start training from score -0.637315
2024-01-03 18:47:46,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:46,222:INFO:Uploading results into container
2024-01-03 18:47:46,223:INFO:Uploading model into container now
2024-01-03 18:47:46,223:INFO:_master_model_container: 16
2024-01-03 18:47:46,223:INFO:_display_container: 4
2024-01-03 18:47:46,224:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=280, n_jobs=-1, num_leaves=150, objective=None,
               random_state=2882, reg_alpha=1e-07, reg_lambda=0.5,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:47:46,224:INFO:create_model() successfully completed......................................
2024-01-03 18:47:46,516:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:46,517:INFO:choose_better activated
2024-01-03 18:47:46,519:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:46,519:INFO:Initializing create_model()
2024-01-03 18:47:46,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2882, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:46,519:INFO:Checking exceptions
2024-01-03 18:47:46,520:INFO:Importing libraries
2024-01-03 18:47:46,520:INFO:Copying training dataset
2024-01-03 18:47:46,526:INFO:Defining folds
2024-01-03 18:47:46,526:INFO:Declaring metric variables
2024-01-03 18:47:46,526:INFO:Importing untrained model
2024-01-03 18:47:46,526:INFO:Declaring custom model
2024-01-03 18:47:46,527:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:47:46,527:INFO:Starting cross validation
2024-01-03 18:47:46,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:46,848:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,848:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,860:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,861:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,863:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,865:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,876:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,880:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,884:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,885:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:46,889:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:46,893:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,894:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,895:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,910:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,912:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:46,919:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,923:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:46,930:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,988:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:46,996:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,003:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,014:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,014:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:47,020:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,023:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:47,030:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,044:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,057:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,065:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:47,071:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,116:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,117:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,130:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,132:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,139:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:47,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:47,145:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,147:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:47,167:INFO:Calculating mean and std
2024-01-03 18:47:47,168:INFO:Creating metrics dataframe
2024-01-03 18:47:47,170:INFO:Finalizing model
2024-01-03 18:47:47,227:INFO:[LightGBM] [Info] Number of positive: 5009, number of negative: 9474
2024-01-03 18:47:47,228:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000059 seconds.
2024-01-03 18:47:47,228:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:47,228:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:47,228:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:47:47,228:INFO:[LightGBM] [Info] Number of data points in the train set: 14483, number of used features: 1
2024-01-03 18:47:47,228:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345854 -> initscore=-0.637315
2024-01-03 18:47:47,228:INFO:[LightGBM] [Info] Start training from score -0.637315
2024-01-03 18:47:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:47,258:INFO:Uploading results into container
2024-01-03 18:47:47,259:INFO:Uploading model into container now
2024-01-03 18:47:47,259:INFO:_master_model_container: 17
2024-01-03 18:47:47,259:INFO:_display_container: 5
2024-01-03 18:47:47,260:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2882, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:47:47,260:INFO:create_model() successfully completed......................................
2024-01-03 18:47:47,538:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:47,538:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2882, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.4074
2024-01-03 18:47:47,539:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=280, n_jobs=-1, num_leaves=150, objective=None,
               random_state=2882, reg_alpha=1e-07, reg_lambda=0.5,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6541
2024-01-03 18:47:47,539:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=280, n_jobs=-1, num_leaves=150, objective=None,
               random_state=2882, reg_alpha=1e-07, reg_lambda=0.5,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-03 18:47:47,539:INFO:choose_better completed
2024-01-03 18:47:47,546:INFO:_master_model_container: 17
2024-01-03 18:47:47,546:INFO:_display_container: 4
2024-01-03 18:47:47,547:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=280, n_jobs=-1, num_leaves=150, objective=None,
               random_state=2882, reg_alpha=1e-07, reg_lambda=0.5,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-03 18:47:47,547:INFO:tune_model() successfully completed......................................
2024-01-03 18:47:47,804:INFO:Initializing calibrate_model()
2024-01-03 18:47:47,804:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=280, n_jobs=-1, num_leaves=150, objective=None,
               random_state=2882, reg_alpha=1e-07, reg_lambda=0.5,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), method=sigmoid, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2024-01-03 18:47:47,804:INFO:Checking exceptions
2024-01-03 18:47:47,807:INFO:Preloading libraries
2024-01-03 18:47:47,808:INFO:Preparing display monitor
2024-01-03 18:47:47,818:INFO:Getting model name
2024-01-03 18:47:47,821:INFO:Base model : Light Gradient Boosting Machine
2024-01-03 18:47:47,827:INFO:Importing untrained CalibratedClassifierCV
2024-01-03 18:47:47,827:INFO:SubProcess create_model() called ==================================
2024-01-03 18:47:47,828:INFO:Initializing create_model()
2024-01-03 18:47:47,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.8,
                                                     importance_type='split',
                                                     learning_rate=0.0005,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.2,
                                                     n_estimators=280,
                                                     n_jobs=-1, num_leaves=150,
                                                     objective=None,
                                                     random_state=2882,
                                                     reg_alpha=1e-07,
                                                     reg_lambda=0.5,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C088E58B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:47,828:INFO:Checking exceptions
2024-01-03 18:47:47,829:INFO:Importing libraries
2024-01-03 18:47:47,829:INFO:Copying training dataset
2024-01-03 18:47:47,835:INFO:Defining folds
2024-01-03 18:47:47,835:INFO:Declaring metric variables
2024-01-03 18:47:47,837:INFO:Importing untrained model
2024-01-03 18:47:47,838:INFO:Declaring custom model
2024-01-03 18:47:47,841:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:47:47,848:INFO:Starting cross validation
2024-01-03 18:47:47,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:47:47,937:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:47,945:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:47,947:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:47,974:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:47,976:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:47,981:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:47,988:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:48,002:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:50,517:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,519:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,533:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,538:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,549:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:50,555:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,557:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,583:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,601:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,615:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:50,624:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,655:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:50,669:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:50,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,736:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,751:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,753:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,761:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:50,763:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:50,768:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,770:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,823:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,838:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,849:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,849:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:50,856:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,865:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,874:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:50,881:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,960:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,973:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:50,981:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:50,987:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:51,850:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:51,864:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:51,873:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:51,878:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:51,880:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:51,895:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:51,902:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 18:47:51,907:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:47:51,924:INFO:Calculating mean and std
2024-01-03 18:47:51,925:INFO:Creating metrics dataframe
2024-01-03 18:47:51,930:INFO:Finalizing model
2024-01-03 18:47:51,980:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:51,984:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:51,984:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:51,984:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:51,986:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:51,986:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:51,986:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:51,986:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:47:51,987:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2024-01-03 18:47:51,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:51,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:51,987:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:47:51,987:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:47:51,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:47:51,987:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:47:51,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,059:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,060:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,060:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,084:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,084:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,084:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,086:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,087:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,087:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,087:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:47:52,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.
2024-01-03 18:47:52,087:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:52,087:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:52,087:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:47:52,087:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:47:52,087:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:47:52,087:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:47:52,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,186:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,186:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,187:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,212:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,212:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,212:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,215:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,215:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,215:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,215:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7579
2024-01-03 18:47:52,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.
2024-01-03 18:47:52,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:52,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:52,215:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:47:52,215:INFO:[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1
2024-01-03 18:47:52,216:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345848 -> initscore=-0.637338
2024-01-03 18:47:52,216:INFO:[LightGBM] [Info] Start training from score -0.637338
2024-01-03 18:47:52,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,291:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,291:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,291:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,316:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,316:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,316:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,318:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,318:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,318:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,318:INFO:[LightGBM] [Info] Number of positive: 4008, number of negative: 7579
2024-01-03 18:47:52,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.
2024-01-03 18:47:52,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:52,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:52,319:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:47:52,319:INFO:[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1
2024-01-03 18:47:52,319:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345905 -> initscore=-0.637089
2024-01-03 18:47:52,319:INFO:[LightGBM] [Info] Start training from score -0.637089
2024-01-03 18:47:52,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,396:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,396:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,396:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,421:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,421:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,421:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,424:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,424:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,424:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,424:INFO:[LightGBM] [Info] Number of positive: 4007, number of negative: 7580
2024-01-03 18:47:52,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000055 seconds.
2024-01-03 18:47:52,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:52,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:52,425:INFO:[LightGBM] [Info] Total Bins 4
2024-01-03 18:47:52,425:INFO:[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1
2024-01-03 18:47:52,425:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345819 -> initscore=-0.637470
2024-01-03 18:47:52,425:INFO:[LightGBM] [Info] Start training from score -0.637470
2024-01-03 18:47:52,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:52,502:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:52,502:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:52,502:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:52,526:INFO:Uploading results into container
2024-01-03 18:47:52,527:INFO:Uploading model into container now
2024-01-03 18:47:52,528:INFO:_master_model_container: 18
2024-01-03 18:47:52,528:INFO:_display_container: 5
2024-01-03 18:47:52,529:INFO:CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.8,
                                                     importance_type='split',
                                                     learning_rate=0.0005,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.2,
                                                     n_estimators=280,
                                                     n_jobs=-1, num_leaves=150,
                                                     objective=None,
                                                     random_state=2882,
                                                     reg_alpha=1e-07,
                                                     reg_lambda=0.5,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:47:52,529:INFO:create_model() successfully completed......................................
2024-01-03 18:47:52,805:INFO:SubProcess create_model() end ==================================
2024-01-03 18:47:52,818:INFO:_master_model_container: 18
2024-01-03 18:47:52,818:INFO:_display_container: 5
2024-01-03 18:47:52,819:INFO:CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.8,
                                                     importance_type='split',
                                                     learning_rate=0.0005,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.2,
                                                     n_estimators=280,
                                                     n_jobs=-1, num_leaves=150,
                                                     objective=None,
                                                     random_state=2882,
                                                     reg_alpha=1e-07,
                                                     reg_lambda=0.5,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:47:52,820:INFO:calibrate_model() successfully completed......................................
2024-01-03 18:47:53,067:INFO:Initializing finalize_model()
2024-01-03 18:47:53,067:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.8,
                                                     importance_type='split',
                                                     learning_rate=0.0005,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.2,
                                                     n_estimators=280,
                                                     n_jobs=-1, num_leaves=150,
                                                     objective=None,
                                                     random_state=2882,
                                                     reg_alpha=1e-07,
                                                     reg_lambda=0.5,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-03 18:47:53,068:INFO:Finalizing CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.8,
                                                     importance_type='split',
                                                     learning_rate=0.0005,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.2,
                                                     n_estimators=280,
                                                     n_jobs=-1, num_leaves=150,
                                                     objective=None,
                                                     random_state=2882,
                                                     reg_alpha=1e-07,
                                                     reg_lambda=0.5,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None)
2024-01-03 18:47:53,071:INFO:Initializing create_model()
2024-01-03 18:47:53,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=CalibratedClassifierCV(base_estimator=LGBMClassifier(bagging_fraction=0.7,
                                                     bagging_freq=6,
                                                     boosting_type='gbdt',
                                                     class_weight=None,
                                                     colsample_bytree=1.0,
                                                     feature_fraction=0.8,
                                                     importance_type='split',
                                                     learning_rate=0.0005,
                                                     max_depth=-1,
                                                     min_child_samples=16,
                                                     min_child_weight=0.001,
                                                     min_split_gain=0.2,
                                                     n_estimators=280,
                                                     n_jobs=-1, num_leaves=150,
                                                     objective=None,
                                                     random_state=2882,
                                                     reg_alpha=1e-07,
                                                     reg_lambda=0.5,
                                                     subsample=1.0,
                                                     subsample_for_bin=200000,
                                                     subsample_freq=0),
                       cv=5, ensemble=True, estimator=None, method='sigmoid',
                       n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:47:53,072:INFO:Checking exceptions
2024-01-03 18:47:53,073:INFO:Importing libraries
2024-01-03 18:47:53,073:INFO:Copying training dataset
2024-01-03 18:47:53,073:INFO:Defining folds
2024-01-03 18:47:53,073:INFO:Declaring metric variables
2024-01-03 18:47:53,073:INFO:Importing untrained model
2024-01-03 18:47:53,073:INFO:Declaring custom model
2024-01-03 18:47:53,074:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 18:47:53,074:INFO:Cross validation set to False
2024-01-03 18:47:53,074:INFO:Fitting Model
2024-01-03 18:47:53,112:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
  warnings.warn(

2024-01-03 18:47:53,116:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,116:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,116:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,118:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,119:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,119:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,119:INFO:[LightGBM] [Info] Number of positive: 4981, number of negative: 9630
2024-01-03 18:47:53,119:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.
2024-01-03 18:47:53,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:53,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:53,119:INFO:[LightGBM] [Info] Total Bins 6
2024-01-03 18:47:53,119:INFO:[LightGBM] [Info] Number of data points in the train set: 14611, number of used features: 1
2024-01-03 18:47:53,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340908 -> initscore=-0.659253
2024-01-03 18:47:53,119:INFO:[LightGBM] [Info] Start training from score -0.659253
2024-01-03 18:47:53,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,184:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,184:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,184:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,213:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,213:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,213:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,216:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,216:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,216:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,216:INFO:[LightGBM] [Info] Number of positive: 4981, number of negative: 9630
2024-01-03 18:47:53,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.
2024-01-03 18:47:53,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:53,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:53,216:INFO:[LightGBM] [Info] Total Bins 6
2024-01-03 18:47:53,216:INFO:[LightGBM] [Info] Number of data points in the train set: 14611, number of used features: 1
2024-01-03 18:47:53,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340908 -> initscore=-0.659253
2024-01-03 18:47:53,217:INFO:[LightGBM] [Info] Start training from score -0.659253
2024-01-03 18:47:53,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,290:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,290:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,291:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,318:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,318:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,318:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,321:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,321:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,321:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,321:INFO:[LightGBM] [Info] Number of positive: 4981, number of negative: 9630
2024-01-03 18:47:53,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000065 seconds.
2024-01-03 18:47:53,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:53,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:53,322:INFO:[LightGBM] [Info] Total Bins 6
2024-01-03 18:47:53,322:INFO:[LightGBM] [Info] Number of data points in the train set: 14611, number of used features: 1
2024-01-03 18:47:53,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340908 -> initscore=-0.659253
2024-01-03 18:47:53,322:INFO:[LightGBM] [Info] Start training from score -0.659253
2024-01-03 18:47:53,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,403:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,403:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,432:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,432:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,432:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,435:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,435:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,435:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,435:INFO:[LightGBM] [Info] Number of positive: 4980, number of negative: 9631
2024-01-03 18:47:53,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000053 seconds.
2024-01-03 18:47:53,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:53,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:53,436:INFO:[LightGBM] [Info] Total Bins 6
2024-01-03 18:47:53,436:INFO:[LightGBM] [Info] Number of data points in the train set: 14611, number of used features: 1
2024-01-03 18:47:53,436:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340839 -> initscore=-0.659557
2024-01-03 18:47:53,436:INFO:[LightGBM] [Info] Start training from score -0.659557
2024-01-03 18:47:53,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,511:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,511:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,539:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,539:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,539:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,542:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,542:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,542:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,542:INFO:[LightGBM] [Info] Number of positive: 4981, number of negative: 9631
2024-01-03 18:47:53,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.
2024-01-03 18:47:53,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 18:47:53,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 18:47:53,542:INFO:[LightGBM] [Info] Total Bins 5
2024-01-03 18:47:53,543:INFO:[LightGBM] [Info] Number of data points in the train set: 14612, number of used features: 1
2024-01-03 18:47:53,543:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.340884 -> initscore=-0.659356
2024-01-03 18:47:53,543:INFO:[LightGBM] [Info] Start training from score -0.659356
2024-01-03 18:47:53,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 18:47:53,615:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:53,615:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:53,615:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:53,652:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.0005,
                                                                      max_depth=-1,
                                                                      min_child_samples=16,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0.2,
                                                                      n_estimators=280,
                                                                      n_jobs=-1,
                                                                      num_leaves=150,
                                                                      objective=None,
                                                                      random_state=2882,
                                                                      reg_alpha=1e-07,
                                                                      reg_lambda=0.5,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-01-03 18:47:53,652:INFO:create_model() successfully completed......................................
2024-01-03 18:47:53,959:INFO:_master_model_container: 18
2024-01-03 18:47:53,959:INFO:_display_container: 5
2024-01-03 18:47:53,966:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.0005,
                                                                      max_depth=-1,
                                                                      min_child_samples=16,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0.2,
                                                                      n_estimators=280,
                                                                      n_jobs=-1,
                                                                      num_leaves=150,
                                                                      objective=None,
                                                                      random_state=2882,
                                                                      reg_alpha=1e-07,
                                                                      reg_lambda=0.5,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-01-03 18:47:53,966:INFO:finalize_model() successfully completed......................................
2024-01-03 18:47:54,241:INFO:Initializing plot_model()
2024-01-03 18:47:54,241:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F12DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                      importance_type='split',
                                                                      learning_rate=0.0005,
                                                                      max_depth=-1,
                                                                      min_child_samples=16,
                                                                      min_child_weight=0.001,
                                                                      min_split_gain=0.2,
                                                                      n_estimators=280,
                                                                      n_jobs=-1,
                                                                      num_leaves=150,
                                                                      objective=None,
                                                                      random_state=2882,
                                                                      reg_alpha=1e-07,
                                                                      reg_lambda=0.5,
                                                                      subsample=1.0,
                                                                      subsample_for_bin=200000,
                                                                      subsample_freq=0),
                                        cv=5, ensemble=True, estimator=None,
                                        method='sigmoid', n_jobs=None))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-01-03 18:47:54,241:INFO:Checking exceptions
2024-01-03 18:47:54,245:INFO:Preloading libraries
2024-01-03 18:47:54,281:INFO:Copying training dataset
2024-01-03 18:47:54,281:INFO:Plot type: confusion_matrix
2024-01-03 18:47:54,582:INFO:Fitting Model
2024-01-03 18:47:54,582:INFO:Scoring test/hold-out set
2024-01-03 18:47:54,583:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,583:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,583:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,587:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,587:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,587:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,592:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,592:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,592:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,596:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,596:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,599:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,599:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,599:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,603:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,603:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,603:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,609:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,609:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,609:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,613:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,616:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,616:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,616:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,619:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-01-03 18:47:54,619:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-03 18:47:54,619:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-03 18:47:54,731:INFO:Visual Rendered Successfully
2024-01-03 18:47:54,994:INFO:plot_model() successfully completed......................................
2024-01-03 18:56:44,974:INFO:PyCaret ClassificationExperiment
2024-01-03 18:56:44,974:INFO:Logging name: clf-default-name
2024-01-03 18:56:44,974:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:56:44,974:INFO:version 3.2.0
2024-01-03 18:56:44,974:INFO:Initializing setup()
2024-01-03 18:56:44,974:INFO:self.USI: f9b7
2024-01-03 18:56:44,975:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:56:44,975:INFO:Checking environment
2024-01-03 18:56:44,975:INFO:python_version: 3.11.5
2024-01-03 18:56:44,975:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:56:44,975:INFO:machine: AMD64
2024-01-03 18:56:44,975:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:56:44,975:INFO:Memory: svmem(total=16893386752, available=4642902016, percent=72.5, used=12250484736, free=4642902016)
2024-01-03 18:56:44,975:INFO:Physical Core: 4
2024-01-03 18:56:44,975:INFO:Logical Core: 8
2024-01-03 18:56:44,975:INFO:Checking libraries
2024-01-03 18:56:44,975:INFO:System:
2024-01-03 18:56:44,975:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:56:44,975:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:56:44,975:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:56:44,975:INFO:PyCaret required dependencies:
2024-01-03 18:56:44,975:INFO:                 pip: 23.3.1
2024-01-03 18:56:44,976:INFO:          setuptools: 68.2.2
2024-01-03 18:56:44,976:INFO:             pycaret: 3.2.0
2024-01-03 18:56:44,976:INFO:             IPython: 8.15.0
2024-01-03 18:56:44,976:INFO:          ipywidgets: 8.0.4
2024-01-03 18:56:44,976:INFO:                tqdm: 4.66.1
2024-01-03 18:56:44,976:INFO:               numpy: 1.25.2
2024-01-03 18:56:44,976:INFO:              pandas: 1.5.3
2024-01-03 18:56:44,976:INFO:              jinja2: 3.1.2
2024-01-03 18:56:44,976:INFO:               scipy: 1.10.1
2024-01-03 18:56:44,976:INFO:              joblib: 1.2.0
2024-01-03 18:56:44,976:INFO:             sklearn: 1.2.2
2024-01-03 18:56:44,976:INFO:                pyod: 1.1.2
2024-01-03 18:56:44,976:INFO:            imblearn: 0.11.0
2024-01-03 18:56:44,976:INFO:   category_encoders: 2.6.3
2024-01-03 18:56:44,976:INFO:            lightgbm: 4.2.0
2024-01-03 18:56:44,976:INFO:               numba: 0.58.1
2024-01-03 18:56:44,976:INFO:            requests: 2.31.0
2024-01-03 18:56:44,977:INFO:          matplotlib: 3.6.0
2024-01-03 18:56:44,977:INFO:          scikitplot: 0.3.7
2024-01-03 18:56:44,977:INFO:         yellowbrick: 1.5
2024-01-03 18:56:44,977:INFO:              plotly: 5.18.0
2024-01-03 18:56:44,977:INFO:    plotly-resampler: Not installed
2024-01-03 18:56:44,977:INFO:             kaleido: 0.2.1
2024-01-03 18:56:44,977:INFO:           schemdraw: 0.15
2024-01-03 18:56:44,977:INFO:         statsmodels: 0.14.1
2024-01-03 18:56:44,977:INFO:              sktime: 0.21.1
2024-01-03 18:56:44,977:INFO:               tbats: 1.1.3
2024-01-03 18:56:44,977:INFO:            pmdarima: 2.0.4
2024-01-03 18:56:44,977:INFO:              psutil: 5.9.0
2024-01-03 18:56:44,977:INFO:          markupsafe: 2.1.1
2024-01-03 18:56:44,977:INFO:             pickle5: Not installed
2024-01-03 18:56:44,977:INFO:         cloudpickle: 3.0.0
2024-01-03 18:56:44,977:INFO:         deprecation: 2.1.0
2024-01-03 18:56:44,977:INFO:              xxhash: 3.4.1
2024-01-03 18:56:44,978:INFO:           wurlitzer: Not installed
2024-01-03 18:56:44,978:INFO:PyCaret optional dependencies:
2024-01-03 18:56:44,978:INFO:                shap: Not installed
2024-01-03 18:56:44,978:INFO:           interpret: Not installed
2024-01-03 18:56:44,978:INFO:                umap: Not installed
2024-01-03 18:56:44,978:INFO:     ydata_profiling: Not installed
2024-01-03 18:56:44,978:INFO:  explainerdashboard: Not installed
2024-01-03 18:56:44,978:INFO:             autoviz: Not installed
2024-01-03 18:56:44,978:INFO:           fairlearn: Not installed
2024-01-03 18:56:44,978:INFO:          deepchecks: Not installed
2024-01-03 18:56:44,978:INFO:             xgboost: Not installed
2024-01-03 18:56:44,978:INFO:            catboost: Not installed
2024-01-03 18:56:44,978:INFO:              kmodes: Not installed
2024-01-03 18:56:44,979:INFO:             mlxtend: 0.23.0
2024-01-03 18:56:44,979:INFO:       statsforecast: Not installed
2024-01-03 18:56:44,979:INFO:        tune_sklearn: Not installed
2024-01-03 18:56:44,979:INFO:                 ray: Not installed
2024-01-03 18:56:44,979:INFO:            hyperopt: Not installed
2024-01-03 18:56:44,979:INFO:              optuna: Not installed
2024-01-03 18:56:44,979:INFO:               skopt: Not installed
2024-01-03 18:56:44,979:INFO:              mlflow: Not installed
2024-01-03 18:56:44,979:INFO:              gradio: Not installed
2024-01-03 18:56:44,979:INFO:             fastapi: Not installed
2024-01-03 18:56:44,979:INFO:             uvicorn: Not installed
2024-01-03 18:56:44,979:INFO:              m2cgen: Not installed
2024-01-03 18:56:44,979:INFO:           evidently: Not installed
2024-01-03 18:56:44,979:INFO:               fugue: Not installed
2024-01-03 18:56:44,979:INFO:           streamlit: Not installed
2024-01-03 18:56:44,979:INFO:             prophet: Not installed
2024-01-03 18:56:44,980:INFO:None
2024-01-03 18:56:44,980:INFO:Set up data.
2024-01-03 18:56:45,038:INFO:Set up folding strategy.
2024-01-03 18:56:45,038:INFO:Set up train/test split.
2024-01-03 18:56:45,080:INFO:Set up index.
2024-01-03 18:57:10,776:INFO:PyCaret ClassificationExperiment
2024-01-03 18:57:10,776:INFO:Logging name: clf-default-name
2024-01-03 18:57:10,777:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:57:10,777:INFO:version 3.2.0
2024-01-03 18:57:10,777:INFO:Initializing setup()
2024-01-03 18:57:10,777:INFO:self.USI: f20f
2024-01-03 18:57:10,777:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:57:10,777:INFO:Checking environment
2024-01-03 18:57:10,777:INFO:python_version: 3.11.5
2024-01-03 18:57:10,777:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:57:10,777:INFO:machine: AMD64
2024-01-03 18:57:10,777:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:57:10,777:INFO:Memory: svmem(total=16893386752, available=4802048000, percent=71.6, used=12091338752, free=4802048000)
2024-01-03 18:57:10,777:INFO:Physical Core: 4
2024-01-03 18:57:10,777:INFO:Logical Core: 8
2024-01-03 18:57:10,777:INFO:Checking libraries
2024-01-03 18:57:10,777:INFO:System:
2024-01-03 18:57:10,777:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:57:10,777:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:57:10,777:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:57:10,778:INFO:PyCaret required dependencies:
2024-01-03 18:57:10,778:INFO:                 pip: 23.3.1
2024-01-03 18:57:10,778:INFO:          setuptools: 68.2.2
2024-01-03 18:57:10,778:INFO:             pycaret: 3.2.0
2024-01-03 18:57:10,778:INFO:             IPython: 8.15.0
2024-01-03 18:57:10,778:INFO:          ipywidgets: 8.0.4
2024-01-03 18:57:10,778:INFO:                tqdm: 4.66.1
2024-01-03 18:57:10,778:INFO:               numpy: 1.25.2
2024-01-03 18:57:10,778:INFO:              pandas: 1.5.3
2024-01-03 18:57:10,778:INFO:              jinja2: 3.1.2
2024-01-03 18:57:10,778:INFO:               scipy: 1.10.1
2024-01-03 18:57:10,778:INFO:              joblib: 1.2.0
2024-01-03 18:57:10,778:INFO:             sklearn: 1.2.2
2024-01-03 18:57:10,779:INFO:                pyod: 1.1.2
2024-01-03 18:57:10,779:INFO:            imblearn: 0.11.0
2024-01-03 18:57:10,779:INFO:   category_encoders: 2.6.3
2024-01-03 18:57:10,779:INFO:            lightgbm: 4.2.0
2024-01-03 18:57:10,779:INFO:               numba: 0.58.1
2024-01-03 18:57:10,779:INFO:            requests: 2.31.0
2024-01-03 18:57:10,779:INFO:          matplotlib: 3.6.0
2024-01-03 18:57:10,779:INFO:          scikitplot: 0.3.7
2024-01-03 18:57:10,779:INFO:         yellowbrick: 1.5
2024-01-03 18:57:10,779:INFO:              plotly: 5.18.0
2024-01-03 18:57:10,779:INFO:    plotly-resampler: Not installed
2024-01-03 18:57:10,779:INFO:             kaleido: 0.2.1
2024-01-03 18:57:10,779:INFO:           schemdraw: 0.15
2024-01-03 18:57:10,779:INFO:         statsmodels: 0.14.1
2024-01-03 18:57:10,779:INFO:              sktime: 0.21.1
2024-01-03 18:57:10,779:INFO:               tbats: 1.1.3
2024-01-03 18:57:10,779:INFO:            pmdarima: 2.0.4
2024-01-03 18:57:10,779:INFO:              psutil: 5.9.0
2024-01-03 18:57:10,780:INFO:          markupsafe: 2.1.1
2024-01-03 18:57:10,780:INFO:             pickle5: Not installed
2024-01-03 18:57:10,780:INFO:         cloudpickle: 3.0.0
2024-01-03 18:57:10,780:INFO:         deprecation: 2.1.0
2024-01-03 18:57:10,780:INFO:              xxhash: 3.4.1
2024-01-03 18:57:10,780:INFO:           wurlitzer: Not installed
2024-01-03 18:57:10,780:INFO:PyCaret optional dependencies:
2024-01-03 18:57:10,780:INFO:                shap: Not installed
2024-01-03 18:57:10,780:INFO:           interpret: Not installed
2024-01-03 18:57:10,780:INFO:                umap: Not installed
2024-01-03 18:57:10,780:INFO:     ydata_profiling: Not installed
2024-01-03 18:57:10,780:INFO:  explainerdashboard: Not installed
2024-01-03 18:57:10,780:INFO:             autoviz: Not installed
2024-01-03 18:57:10,780:INFO:           fairlearn: Not installed
2024-01-03 18:57:10,780:INFO:          deepchecks: Not installed
2024-01-03 18:57:10,780:INFO:             xgboost: Not installed
2024-01-03 18:57:10,780:INFO:            catboost: Not installed
2024-01-03 18:57:10,780:INFO:              kmodes: Not installed
2024-01-03 18:57:10,780:INFO:             mlxtend: 0.23.0
2024-01-03 18:57:10,780:INFO:       statsforecast: Not installed
2024-01-03 18:57:10,781:INFO:        tune_sklearn: Not installed
2024-01-03 18:57:10,781:INFO:                 ray: Not installed
2024-01-03 18:57:10,781:INFO:            hyperopt: Not installed
2024-01-03 18:57:10,781:INFO:              optuna: Not installed
2024-01-03 18:57:10,781:INFO:               skopt: Not installed
2024-01-03 18:57:10,781:INFO:              mlflow: Not installed
2024-01-03 18:57:10,781:INFO:              gradio: Not installed
2024-01-03 18:57:10,781:INFO:             fastapi: Not installed
2024-01-03 18:57:10,781:INFO:             uvicorn: Not installed
2024-01-03 18:57:10,781:INFO:              m2cgen: Not installed
2024-01-03 18:57:10,781:INFO:           evidently: Not installed
2024-01-03 18:57:10,781:INFO:               fugue: Not installed
2024-01-03 18:57:10,781:INFO:           streamlit: Not installed
2024-01-03 18:57:10,781:INFO:             prophet: Not installed
2024-01-03 18:57:10,781:INFO:None
2024-01-03 18:57:10,781:INFO:Set up data.
2024-01-03 18:57:10,808:INFO:Set up folding strategy.
2024-01-03 18:57:10,808:INFO:Set up train/test split.
2024-01-03 18:57:10,829:INFO:Set up index.
2024-01-03 18:57:34,794:INFO:PyCaret ClassificationExperiment
2024-01-03 18:57:34,795:INFO:Logging name: clf-default-name
2024-01-03 18:57:34,795:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:57:34,795:INFO:version 3.2.0
2024-01-03 18:57:34,795:INFO:Initializing setup()
2024-01-03 18:57:34,795:INFO:self.USI: d66e
2024-01-03 18:57:34,795:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:57:34,795:INFO:Checking environment
2024-01-03 18:57:34,795:INFO:python_version: 3.11.5
2024-01-03 18:57:34,795:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:57:34,795:INFO:machine: AMD64
2024-01-03 18:57:34,795:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:57:34,795:INFO:Memory: svmem(total=16893386752, available=4755095552, percent=71.9, used=12138291200, free=4755095552)
2024-01-03 18:57:34,795:INFO:Physical Core: 4
2024-01-03 18:57:34,795:INFO:Logical Core: 8
2024-01-03 18:57:34,796:INFO:Checking libraries
2024-01-03 18:57:34,796:INFO:System:
2024-01-03 18:57:34,796:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:57:34,796:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:57:34,796:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:57:34,796:INFO:PyCaret required dependencies:
2024-01-03 18:57:34,796:INFO:                 pip: 23.3.1
2024-01-03 18:57:34,796:INFO:          setuptools: 68.2.2
2024-01-03 18:57:34,796:INFO:             pycaret: 3.2.0
2024-01-03 18:57:34,796:INFO:             IPython: 8.15.0
2024-01-03 18:57:34,796:INFO:          ipywidgets: 8.0.4
2024-01-03 18:57:34,796:INFO:                tqdm: 4.66.1
2024-01-03 18:57:34,796:INFO:               numpy: 1.25.2
2024-01-03 18:57:34,796:INFO:              pandas: 1.5.3
2024-01-03 18:57:34,796:INFO:              jinja2: 3.1.2
2024-01-03 18:57:34,797:INFO:               scipy: 1.10.1
2024-01-03 18:57:34,797:INFO:              joblib: 1.2.0
2024-01-03 18:57:34,797:INFO:             sklearn: 1.2.2
2024-01-03 18:57:34,797:INFO:                pyod: 1.1.2
2024-01-03 18:57:34,797:INFO:            imblearn: 0.11.0
2024-01-03 18:57:34,797:INFO:   category_encoders: 2.6.3
2024-01-03 18:57:34,797:INFO:            lightgbm: 4.2.0
2024-01-03 18:57:34,797:INFO:               numba: 0.58.1
2024-01-03 18:57:34,797:INFO:            requests: 2.31.0
2024-01-03 18:57:34,797:INFO:          matplotlib: 3.6.0
2024-01-03 18:57:34,797:INFO:          scikitplot: 0.3.7
2024-01-03 18:57:34,797:INFO:         yellowbrick: 1.5
2024-01-03 18:57:34,797:INFO:              plotly: 5.18.0
2024-01-03 18:57:34,797:INFO:    plotly-resampler: Not installed
2024-01-03 18:57:34,797:INFO:             kaleido: 0.2.1
2024-01-03 18:57:34,798:INFO:           schemdraw: 0.15
2024-01-03 18:57:34,798:INFO:         statsmodels: 0.14.1
2024-01-03 18:57:34,798:INFO:              sktime: 0.21.1
2024-01-03 18:57:34,798:INFO:               tbats: 1.1.3
2024-01-03 18:57:34,798:INFO:            pmdarima: 2.0.4
2024-01-03 18:57:34,798:INFO:              psutil: 5.9.0
2024-01-03 18:57:34,798:INFO:          markupsafe: 2.1.1
2024-01-03 18:57:34,798:INFO:             pickle5: Not installed
2024-01-03 18:57:34,798:INFO:         cloudpickle: 3.0.0
2024-01-03 18:57:34,798:INFO:         deprecation: 2.1.0
2024-01-03 18:57:34,798:INFO:              xxhash: 3.4.1
2024-01-03 18:57:34,798:INFO:           wurlitzer: Not installed
2024-01-03 18:57:34,798:INFO:PyCaret optional dependencies:
2024-01-03 18:57:34,798:INFO:                shap: Not installed
2024-01-03 18:57:34,798:INFO:           interpret: Not installed
2024-01-03 18:57:34,798:INFO:                umap: Not installed
2024-01-03 18:57:34,798:INFO:     ydata_profiling: Not installed
2024-01-03 18:57:34,798:INFO:  explainerdashboard: Not installed
2024-01-03 18:57:34,798:INFO:             autoviz: Not installed
2024-01-03 18:57:34,798:INFO:           fairlearn: Not installed
2024-01-03 18:57:34,798:INFO:          deepchecks: Not installed
2024-01-03 18:57:34,798:INFO:             xgboost: Not installed
2024-01-03 18:57:34,798:INFO:            catboost: Not installed
2024-01-03 18:57:34,799:INFO:              kmodes: Not installed
2024-01-03 18:57:34,799:INFO:             mlxtend: 0.23.0
2024-01-03 18:57:34,799:INFO:       statsforecast: Not installed
2024-01-03 18:57:34,799:INFO:        tune_sklearn: Not installed
2024-01-03 18:57:34,799:INFO:                 ray: Not installed
2024-01-03 18:57:34,799:INFO:            hyperopt: Not installed
2024-01-03 18:57:34,799:INFO:              optuna: Not installed
2024-01-03 18:57:34,799:INFO:               skopt: Not installed
2024-01-03 18:57:34,799:INFO:              mlflow: Not installed
2024-01-03 18:57:34,799:INFO:              gradio: Not installed
2024-01-03 18:57:34,799:INFO:             fastapi: Not installed
2024-01-03 18:57:34,799:INFO:             uvicorn: Not installed
2024-01-03 18:57:34,799:INFO:              m2cgen: Not installed
2024-01-03 18:57:34,799:INFO:           evidently: Not installed
2024-01-03 18:57:34,799:INFO:               fugue: Not installed
2024-01-03 18:57:34,799:INFO:           streamlit: Not installed
2024-01-03 18:57:34,799:INFO:             prophet: Not installed
2024-01-03 18:57:34,799:INFO:None
2024-01-03 18:57:34,799:INFO:Set up data.
2024-01-03 18:57:34,827:INFO:Set up folding strategy.
2024-01-03 18:57:34,827:INFO:Set up train/test split.
2024-01-03 18:57:34,846:INFO:Set up index.
2024-01-03 18:57:34,846:INFO:Assigning column types.
2024-01-03 18:57:34,848:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:57:34,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:57:34,880:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:57:34,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:34,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:34,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:57:34,932:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:57:34,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:34,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:34,952:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:57:34,984:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:57:35,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,038:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:57:35,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,059:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:57:35,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,174:INFO:Preparing preprocessing pipeline...
2024-01-03 18:57:35,175:INFO:Set up label encoding.
2024-01-03 18:57:35,175:INFO:Set up simple imputation.
2024-01-03 18:57:35,177:INFO:Set up encoding of categorical features.
2024-01-03 18:57:35,278:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:57:35,282:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:57:35,282:INFO:Creating final display dataframe.
2024-01-03 18:57:35,622:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (25826, 2)
5        Transformed data shape        (25826, 2)
6   Transformed train set shape        (18078, 2)
7    Transformed test set shape         (7748, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              d66e
2024-01-03 18:57:35,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:57:35,748:INFO:setup() successfully completed in 0.95s...............
2024-01-03 18:57:35,749:INFO:Initializing create_model()
2024-01-03 18:57:35,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C089053910>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'multi_core': True})
2024-01-03 18:57:35,749:INFO:Checking exceptions
2024-01-03 18:57:35,760:INFO:Importing libraries
2024-01-03 18:57:35,760:INFO:Copying training dataset
2024-01-03 18:57:35,766:INFO:Defining folds
2024-01-03 18:57:35,766:INFO:Declaring metric variables
2024-01-03 18:57:35,770:INFO:Importing untrained model
2024-01-03 18:58:01,773:INFO:PyCaret ClassificationExperiment
2024-01-03 18:58:01,773:INFO:Logging name: clf-default-name
2024-01-03 18:58:01,773:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 18:58:01,773:INFO:version 3.2.0
2024-01-03 18:58:01,773:INFO:Initializing setup()
2024-01-03 18:58:01,774:INFO:self.USI: f9ec
2024-01-03 18:58:01,774:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 18:58:01,774:INFO:Checking environment
2024-01-03 18:58:01,774:INFO:python_version: 3.11.5
2024-01-03 18:58:01,774:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 18:58:01,774:INFO:machine: AMD64
2024-01-03 18:58:01,774:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 18:58:01,774:INFO:Memory: svmem(total=16893386752, available=4761755648, percent=71.8, used=12131631104, free=4761755648)
2024-01-03 18:58:01,774:INFO:Physical Core: 4
2024-01-03 18:58:01,774:INFO:Logical Core: 8
2024-01-03 18:58:01,774:INFO:Checking libraries
2024-01-03 18:58:01,774:INFO:System:
2024-01-03 18:58:01,774:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 18:58:01,774:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 18:58:01,774:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 18:58:01,774:INFO:PyCaret required dependencies:
2024-01-03 18:58:01,774:INFO:                 pip: 23.3.1
2024-01-03 18:58:01,774:INFO:          setuptools: 68.2.2
2024-01-03 18:58:01,774:INFO:             pycaret: 3.2.0
2024-01-03 18:58:01,774:INFO:             IPython: 8.15.0
2024-01-03 18:58:01,774:INFO:          ipywidgets: 8.0.4
2024-01-03 18:58:01,774:INFO:                tqdm: 4.66.1
2024-01-03 18:58:01,775:INFO:               numpy: 1.25.2
2024-01-03 18:58:01,775:INFO:              pandas: 1.5.3
2024-01-03 18:58:01,775:INFO:              jinja2: 3.1.2
2024-01-03 18:58:01,775:INFO:               scipy: 1.10.1
2024-01-03 18:58:01,775:INFO:              joblib: 1.2.0
2024-01-03 18:58:01,775:INFO:             sklearn: 1.2.2
2024-01-03 18:58:01,775:INFO:                pyod: 1.1.2
2024-01-03 18:58:01,775:INFO:            imblearn: 0.11.0
2024-01-03 18:58:01,775:INFO:   category_encoders: 2.6.3
2024-01-03 18:58:01,775:INFO:            lightgbm: 4.2.0
2024-01-03 18:58:01,775:INFO:               numba: 0.58.1
2024-01-03 18:58:01,775:INFO:            requests: 2.31.0
2024-01-03 18:58:01,775:INFO:          matplotlib: 3.6.0
2024-01-03 18:58:01,775:INFO:          scikitplot: 0.3.7
2024-01-03 18:58:01,775:INFO:         yellowbrick: 1.5
2024-01-03 18:58:01,775:INFO:              plotly: 5.18.0
2024-01-03 18:58:01,775:INFO:    plotly-resampler: Not installed
2024-01-03 18:58:01,775:INFO:             kaleido: 0.2.1
2024-01-03 18:58:01,775:INFO:           schemdraw: 0.15
2024-01-03 18:58:01,775:INFO:         statsmodels: 0.14.1
2024-01-03 18:58:01,775:INFO:              sktime: 0.21.1
2024-01-03 18:58:01,775:INFO:               tbats: 1.1.3
2024-01-03 18:58:01,776:INFO:            pmdarima: 2.0.4
2024-01-03 18:58:01,776:INFO:              psutil: 5.9.0
2024-01-03 18:58:01,776:INFO:          markupsafe: 2.1.1
2024-01-03 18:58:01,776:INFO:             pickle5: Not installed
2024-01-03 18:58:01,776:INFO:         cloudpickle: 3.0.0
2024-01-03 18:58:01,776:INFO:         deprecation: 2.1.0
2024-01-03 18:58:01,776:INFO:              xxhash: 3.4.1
2024-01-03 18:58:01,776:INFO:           wurlitzer: Not installed
2024-01-03 18:58:01,776:INFO:PyCaret optional dependencies:
2024-01-03 18:58:01,776:INFO:                shap: Not installed
2024-01-03 18:58:01,776:INFO:           interpret: Not installed
2024-01-03 18:58:01,776:INFO:                umap: Not installed
2024-01-03 18:58:01,776:INFO:     ydata_profiling: Not installed
2024-01-03 18:58:01,777:INFO:  explainerdashboard: Not installed
2024-01-03 18:58:01,777:INFO:             autoviz: Not installed
2024-01-03 18:58:01,777:INFO:           fairlearn: Not installed
2024-01-03 18:58:01,777:INFO:          deepchecks: Not installed
2024-01-03 18:58:01,777:INFO:             xgboost: Not installed
2024-01-03 18:58:01,777:INFO:            catboost: Not installed
2024-01-03 18:58:01,777:INFO:              kmodes: Not installed
2024-01-03 18:58:01,777:INFO:             mlxtend: 0.23.0
2024-01-03 18:58:01,777:INFO:       statsforecast: Not installed
2024-01-03 18:58:01,777:INFO:        tune_sklearn: Not installed
2024-01-03 18:58:01,777:INFO:                 ray: Not installed
2024-01-03 18:58:01,778:INFO:            hyperopt: Not installed
2024-01-03 18:58:01,778:INFO:              optuna: Not installed
2024-01-03 18:58:01,778:INFO:               skopt: Not installed
2024-01-03 18:58:01,778:INFO:              mlflow: Not installed
2024-01-03 18:58:01,778:INFO:              gradio: Not installed
2024-01-03 18:58:01,778:INFO:             fastapi: Not installed
2024-01-03 18:58:01,778:INFO:             uvicorn: Not installed
2024-01-03 18:58:01,778:INFO:              m2cgen: Not installed
2024-01-03 18:58:01,778:INFO:           evidently: Not installed
2024-01-03 18:58:01,778:INFO:               fugue: Not installed
2024-01-03 18:58:01,778:INFO:           streamlit: Not installed
2024-01-03 18:58:01,778:INFO:             prophet: Not installed
2024-01-03 18:58:01,778:INFO:None
2024-01-03 18:58:01,778:INFO:Set up data.
2024-01-03 18:58:01,805:INFO:Set up folding strategy.
2024-01-03 18:58:01,805:INFO:Set up train/test split.
2024-01-03 18:58:01,824:INFO:Set up index.
2024-01-03 18:58:01,825:INFO:Assigning column types.
2024-01-03 18:58:01,827:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 18:58:01,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:58:01,859:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:58:01,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:01,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:01,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 18:58:01,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:58:01,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:01,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:01,936:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 18:58:01,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:58:01,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:01,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,021:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 18:58:02,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,042:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 18:58:02,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,150:INFO:Preparing preprocessing pipeline...
2024-01-03 18:58:02,151:INFO:Set up label encoding.
2024-01-03 18:58:02,151:INFO:Set up simple imputation.
2024-01-03 18:58:02,153:INFO:Set up encoding of categorical features.
2024-01-03 18:58:02,260:INFO:Finished creating preprocessing pipeline.
2024-01-03 18:58:02,264:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 18:58:02,264:INFO:Creating final display dataframe.
2024-01-03 18:58:02,599:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (25826, 2)
5        Transformed data shape        (25826, 2)
6   Transformed train set shape        (18078, 2)
7    Transformed test set shape         (7748, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              f9ec
2024-01-03 18:58:02,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 18:58:02,719:INFO:setup() successfully completed in 0.95s...............
2024-01-03 18:58:02,720:INFO:Initializing create_model()
2024-01-03 18:58:02,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C08DBA1A50>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 18:58:02,720:INFO:Checking exceptions
2024-01-03 18:58:02,732:INFO:Importing libraries
2024-01-03 18:58:02,733:INFO:Copying training dataset
2024-01-03 18:58:02,738:INFO:Defining folds
2024-01-03 18:58:02,738:INFO:Declaring metric variables
2024-01-03 18:58:02,741:INFO:Importing untrained model
2024-01-03 18:58:02,744:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 18:58:02,749:INFO:Starting cross validation
2024-01-03 18:58:02,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 18:58:06,625:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,628:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,631:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,635:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,637:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,643:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,645:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,647:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,647:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,652:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,654:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,655:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,656:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,664:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,665:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,665:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,666:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,671:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,673:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,674:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,676:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,684:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,685:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,694:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,850:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,854:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,863:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,865:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,874:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,874:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 18:58:06,893:INFO:Calculating mean and std
2024-01-03 18:58:06,893:INFO:Creating metrics dataframe
2024-01-03 18:58:06,897:INFO:Finalizing model
2024-01-03 18:58:06,941:INFO:Uploading results into container
2024-01-03 18:58:06,943:INFO:Uploading model into container now
2024-01-03 18:58:06,950:INFO:_master_model_container: 1
2024-01-03 18:58:06,951:INFO:_display_container: 2
2024-01-03 18:58:06,951:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 18:58:06,951:INFO:create_model() successfully completed......................................
2024-01-03 19:00:51,602:INFO:PyCaret ClassificationExperiment
2024-01-03 19:00:51,602:INFO:Logging name: clf-default-name
2024-01-03 19:00:51,602:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 19:00:51,602:INFO:version 3.2.0
2024-01-03 19:00:51,602:INFO:Initializing setup()
2024-01-03 19:00:51,603:INFO:self.USI: 12bf
2024-01-03 19:00:51,603:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 19:00:51,603:INFO:Checking environment
2024-01-03 19:00:51,603:INFO:python_version: 3.11.5
2024-01-03 19:00:51,603:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 19:00:51,603:INFO:machine: AMD64
2024-01-03 19:00:51,603:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 19:00:51,603:INFO:Memory: svmem(total=16893386752, available=3728490496, percent=77.9, used=13164896256, free=3728490496)
2024-01-03 19:00:51,603:INFO:Physical Core: 4
2024-01-03 19:00:51,603:INFO:Logical Core: 8
2024-01-03 19:00:51,603:INFO:Checking libraries
2024-01-03 19:00:51,603:INFO:System:
2024-01-03 19:00:51,603:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 19:00:51,603:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 19:00:51,603:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 19:00:51,603:INFO:PyCaret required dependencies:
2024-01-03 19:00:51,603:INFO:                 pip: 23.3.1
2024-01-03 19:00:51,603:INFO:          setuptools: 68.2.2
2024-01-03 19:00:51,603:INFO:             pycaret: 3.2.0
2024-01-03 19:00:51,603:INFO:             IPython: 8.15.0
2024-01-03 19:00:51,603:INFO:          ipywidgets: 8.0.4
2024-01-03 19:00:51,603:INFO:                tqdm: 4.66.1
2024-01-03 19:00:51,603:INFO:               numpy: 1.25.2
2024-01-03 19:00:51,603:INFO:              pandas: 1.5.3
2024-01-03 19:00:51,603:INFO:              jinja2: 3.1.2
2024-01-03 19:00:51,603:INFO:               scipy: 1.10.1
2024-01-03 19:00:51,603:INFO:              joblib: 1.2.0
2024-01-03 19:00:51,603:INFO:             sklearn: 1.2.2
2024-01-03 19:00:51,603:INFO:                pyod: 1.1.2
2024-01-03 19:00:51,603:INFO:            imblearn: 0.11.0
2024-01-03 19:00:51,603:INFO:   category_encoders: 2.6.3
2024-01-03 19:00:51,603:INFO:            lightgbm: 4.2.0
2024-01-03 19:00:51,603:INFO:               numba: 0.58.1
2024-01-03 19:00:51,603:INFO:            requests: 2.31.0
2024-01-03 19:00:51,604:INFO:          matplotlib: 3.6.0
2024-01-03 19:00:51,604:INFO:          scikitplot: 0.3.7
2024-01-03 19:00:51,604:INFO:         yellowbrick: 1.5
2024-01-03 19:00:51,604:INFO:              plotly: 5.18.0
2024-01-03 19:00:51,604:INFO:    plotly-resampler: Not installed
2024-01-03 19:00:51,604:INFO:             kaleido: 0.2.1
2024-01-03 19:00:51,604:INFO:           schemdraw: 0.15
2024-01-03 19:00:51,604:INFO:         statsmodels: 0.14.1
2024-01-03 19:00:51,604:INFO:              sktime: 0.21.1
2024-01-03 19:00:51,604:INFO:               tbats: 1.1.3
2024-01-03 19:00:51,604:INFO:            pmdarima: 2.0.4
2024-01-03 19:00:51,604:INFO:              psutil: 5.9.0
2024-01-03 19:00:51,604:INFO:          markupsafe: 2.1.1
2024-01-03 19:00:51,604:INFO:             pickle5: Not installed
2024-01-03 19:00:51,604:INFO:         cloudpickle: 3.0.0
2024-01-03 19:00:51,604:INFO:         deprecation: 2.1.0
2024-01-03 19:00:51,604:INFO:              xxhash: 3.4.1
2024-01-03 19:00:51,604:INFO:           wurlitzer: Not installed
2024-01-03 19:00:51,604:INFO:PyCaret optional dependencies:
2024-01-03 19:00:51,604:INFO:                shap: Not installed
2024-01-03 19:00:51,605:INFO:           interpret: Not installed
2024-01-03 19:00:51,605:INFO:                umap: Not installed
2024-01-03 19:00:51,605:INFO:     ydata_profiling: Not installed
2024-01-03 19:00:51,605:INFO:  explainerdashboard: Not installed
2024-01-03 19:00:51,605:INFO:             autoviz: Not installed
2024-01-03 19:00:51,605:INFO:           fairlearn: Not installed
2024-01-03 19:00:51,605:INFO:          deepchecks: Not installed
2024-01-03 19:00:51,605:INFO:             xgboost: Not installed
2024-01-03 19:00:51,605:INFO:            catboost: Not installed
2024-01-03 19:00:51,605:INFO:              kmodes: Not installed
2024-01-03 19:00:51,605:INFO:             mlxtend: 0.23.0
2024-01-03 19:00:51,605:INFO:       statsforecast: Not installed
2024-01-03 19:00:51,605:INFO:        tune_sklearn: Not installed
2024-01-03 19:00:51,605:INFO:                 ray: Not installed
2024-01-03 19:00:51,605:INFO:            hyperopt: Not installed
2024-01-03 19:00:51,605:INFO:              optuna: Not installed
2024-01-03 19:00:51,605:INFO:               skopt: Not installed
2024-01-03 19:00:51,605:INFO:              mlflow: Not installed
2024-01-03 19:00:51,605:INFO:              gradio: Not installed
2024-01-03 19:00:51,605:INFO:             fastapi: Not installed
2024-01-03 19:00:51,606:INFO:             uvicorn: Not installed
2024-01-03 19:00:51,606:INFO:              m2cgen: Not installed
2024-01-03 19:00:51,606:INFO:           evidently: Not installed
2024-01-03 19:00:51,606:INFO:               fugue: Not installed
2024-01-03 19:00:51,606:INFO:           streamlit: Not installed
2024-01-03 19:00:51,606:INFO:             prophet: Not installed
2024-01-03 19:00:51,606:INFO:None
2024-01-03 19:00:51,606:INFO:Set up data.
2024-01-03 19:00:51,640:INFO:Set up folding strategy.
2024-01-03 19:00:51,640:INFO:Set up train/test split.
2024-01-03 19:00:51,662:INFO:Set up index.
2024-01-03 19:00:51,662:INFO:Assigning column types.
2024-01-03 19:00:51,665:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 19:00:51,697:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 19:00:51,698:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:00:51,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,750:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 19:00:51,751:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:00:51,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,771:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 19:00:51,803:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:00:51,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,855:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:00:51,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,876:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 19:00:51,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:51,980:INFO:Preparing preprocessing pipeline...
2024-01-03 19:00:51,980:INFO:Set up label encoding.
2024-01-03 19:00:51,981:INFO:Set up simple imputation.
2024-01-03 19:00:51,982:INFO:Set up encoding of categorical features.
2024-01-03 19:00:52,084:INFO:Finished creating preprocessing pipeline.
2024-01-03 19:00:52,089:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 19:00:52,089:INFO:Creating final display dataframe.
2024-01-03 19:00:52,415:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (25826, 2)
5        Transformed data shape        (25826, 2)
6   Transformed train set shape        (18078, 2)
7    Transformed test set shape         (7748, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              12bf
2024-01-03 19:00:52,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:52,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:52,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:52,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:00:52,527:INFO:setup() successfully completed in 0.93s...............
2024-01-03 19:00:52,528:INFO:Initializing create_model()
2024-01-03 19:00:52,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C089031F90>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 19:00:52,529:INFO:Checking exceptions
2024-01-03 19:00:52,540:INFO:Importing libraries
2024-01-03 19:00:52,540:INFO:Copying training dataset
2024-01-03 19:00:52,547:INFO:Defining folds
2024-01-03 19:00:52,547:INFO:Declaring metric variables
2024-01-03 19:00:52,551:INFO:Importing untrained model
2024-01-03 19:00:52,553:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 19:00:52,559:INFO:Starting cross validation
2024-01-03 19:00:52,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 19:00:52,689:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,706:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,708:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,709:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,723:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,724:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,728:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,736:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,741:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,742:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,743:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,748:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,750:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,753:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,755:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,760:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,768:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,772:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,772:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,776:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,778:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,788:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,831:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,846:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,848:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,856:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,858:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,867:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:00:52,879:INFO:Calculating mean and std
2024-01-03 19:00:52,880:INFO:Creating metrics dataframe
2024-01-03 19:00:52,884:INFO:Finalizing model
2024-01-03 19:00:52,928:INFO:Uploading results into container
2024-01-03 19:00:52,929:INFO:Uploading model into container now
2024-01-03 19:00:52,937:INFO:_master_model_container: 1
2024-01-03 19:00:52,937:INFO:_display_container: 2
2024-01-03 19:00:52,938:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 19:00:52,938:INFO:create_model() successfully completed......................................
2024-01-03 19:02:59,192:INFO:PyCaret ClassificationExperiment
2024-01-03 19:02:59,192:INFO:Logging name: clf-default-name
2024-01-03 19:02:59,192:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 19:02:59,192:INFO:version 3.2.0
2024-01-03 19:02:59,192:INFO:Initializing setup()
2024-01-03 19:02:59,192:INFO:self.USI: c8ec
2024-01-03 19:02:59,192:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 19:02:59,192:INFO:Checking environment
2024-01-03 19:02:59,192:INFO:python_version: 3.11.5
2024-01-03 19:02:59,192:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 19:02:59,192:INFO:machine: AMD64
2024-01-03 19:02:59,192:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 19:02:59,193:INFO:Memory: svmem(total=16893386752, available=3741265920, percent=77.9, used=13152120832, free=3741265920)
2024-01-03 19:02:59,193:INFO:Physical Core: 4
2024-01-03 19:02:59,193:INFO:Logical Core: 8
2024-01-03 19:02:59,193:INFO:Checking libraries
2024-01-03 19:02:59,193:INFO:System:
2024-01-03 19:02:59,193:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 19:02:59,193:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 19:02:59,193:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 19:02:59,193:INFO:PyCaret required dependencies:
2024-01-03 19:02:59,193:INFO:                 pip: 23.3.1
2024-01-03 19:02:59,193:INFO:          setuptools: 68.2.2
2024-01-03 19:02:59,193:INFO:             pycaret: 3.2.0
2024-01-03 19:02:59,193:INFO:             IPython: 8.15.0
2024-01-03 19:02:59,193:INFO:          ipywidgets: 8.0.4
2024-01-03 19:02:59,193:INFO:                tqdm: 4.66.1
2024-01-03 19:02:59,193:INFO:               numpy: 1.25.2
2024-01-03 19:02:59,193:INFO:              pandas: 1.5.3
2024-01-03 19:02:59,193:INFO:              jinja2: 3.1.2
2024-01-03 19:02:59,193:INFO:               scipy: 1.10.1
2024-01-03 19:02:59,193:INFO:              joblib: 1.2.0
2024-01-03 19:02:59,193:INFO:             sklearn: 1.2.2
2024-01-03 19:02:59,193:INFO:                pyod: 1.1.2
2024-01-03 19:02:59,193:INFO:            imblearn: 0.11.0
2024-01-03 19:02:59,193:INFO:   category_encoders: 2.6.3
2024-01-03 19:02:59,193:INFO:            lightgbm: 4.2.0
2024-01-03 19:02:59,193:INFO:               numba: 0.58.1
2024-01-03 19:02:59,193:INFO:            requests: 2.31.0
2024-01-03 19:02:59,193:INFO:          matplotlib: 3.6.0
2024-01-03 19:02:59,194:INFO:          scikitplot: 0.3.7
2024-01-03 19:02:59,194:INFO:         yellowbrick: 1.5
2024-01-03 19:02:59,194:INFO:              plotly: 5.18.0
2024-01-03 19:02:59,194:INFO:    plotly-resampler: Not installed
2024-01-03 19:02:59,194:INFO:             kaleido: 0.2.1
2024-01-03 19:02:59,194:INFO:           schemdraw: 0.15
2024-01-03 19:02:59,194:INFO:         statsmodels: 0.14.1
2024-01-03 19:02:59,194:INFO:              sktime: 0.21.1
2024-01-03 19:02:59,194:INFO:               tbats: 1.1.3
2024-01-03 19:02:59,194:INFO:            pmdarima: 2.0.4
2024-01-03 19:02:59,194:INFO:              psutil: 5.9.0
2024-01-03 19:02:59,194:INFO:          markupsafe: 2.1.1
2024-01-03 19:02:59,194:INFO:             pickle5: Not installed
2024-01-03 19:02:59,194:INFO:         cloudpickle: 3.0.0
2024-01-03 19:02:59,194:INFO:         deprecation: 2.1.0
2024-01-03 19:02:59,194:INFO:              xxhash: 3.4.1
2024-01-03 19:02:59,194:INFO:           wurlitzer: Not installed
2024-01-03 19:02:59,194:INFO:PyCaret optional dependencies:
2024-01-03 19:02:59,194:INFO:                shap: Not installed
2024-01-03 19:02:59,194:INFO:           interpret: Not installed
2024-01-03 19:02:59,194:INFO:                umap: Not installed
2024-01-03 19:02:59,194:INFO:     ydata_profiling: Not installed
2024-01-03 19:02:59,194:INFO:  explainerdashboard: Not installed
2024-01-03 19:02:59,194:INFO:             autoviz: Not installed
2024-01-03 19:02:59,194:INFO:           fairlearn: Not installed
2024-01-03 19:02:59,194:INFO:          deepchecks: Not installed
2024-01-03 19:02:59,194:INFO:             xgboost: Not installed
2024-01-03 19:02:59,195:INFO:            catboost: Not installed
2024-01-03 19:02:59,195:INFO:              kmodes: Not installed
2024-01-03 19:02:59,195:INFO:             mlxtend: 0.23.0
2024-01-03 19:02:59,195:INFO:       statsforecast: Not installed
2024-01-03 19:02:59,195:INFO:        tune_sklearn: Not installed
2024-01-03 19:02:59,195:INFO:                 ray: Not installed
2024-01-03 19:02:59,195:INFO:            hyperopt: Not installed
2024-01-03 19:02:59,195:INFO:              optuna: Not installed
2024-01-03 19:02:59,195:INFO:               skopt: Not installed
2024-01-03 19:02:59,195:INFO:              mlflow: Not installed
2024-01-03 19:02:59,195:INFO:              gradio: Not installed
2024-01-03 19:02:59,195:INFO:             fastapi: Not installed
2024-01-03 19:02:59,195:INFO:             uvicorn: Not installed
2024-01-03 19:02:59,195:INFO:              m2cgen: Not installed
2024-01-03 19:02:59,195:INFO:           evidently: Not installed
2024-01-03 19:02:59,195:INFO:               fugue: Not installed
2024-01-03 19:02:59,195:INFO:           streamlit: Not installed
2024-01-03 19:02:59,195:INFO:             prophet: Not installed
2024-01-03 19:02:59,195:INFO:None
2024-01-03 19:02:59,195:INFO:Set up data.
2024-01-03 19:02:59,231:INFO:Set up folding strategy.
2024-01-03 19:02:59,231:INFO:Set up train/test split.
2024-01-03 19:02:59,252:INFO:Set up index.
2024-01-03 19:02:59,252:INFO:Assigning column types.
2024-01-03 19:02:59,255:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 19:02:59,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 19:02:59,288:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:02:59,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,341:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 19:02:59,341:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:02:59,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,363:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 19:02:59,394:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:02:59,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:02:59,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,470:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 19:02:59,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:02:59,575:INFO:Preparing preprocessing pipeline...
2024-01-03 19:02:59,576:INFO:Set up label encoding.
2024-01-03 19:02:59,576:INFO:Set up simple imputation.
2024-01-03 19:02:59,578:INFO:Set up encoding of categorical features.
2024-01-03 19:02:59,679:INFO:Finished creating preprocessing pipeline.
2024-01-03 19:02:59,684:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 19:02:59,685:INFO:Creating final display dataframe.
2024-01-03 19:03:00,011:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (25826, 2)
5        Transformed data shape        (25826, 2)
6   Transformed train set shape        (18078, 2)
7    Transformed test set shape         (7748, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              c8ec
2024-01-03 19:03:00,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:00,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:00,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:00,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:00,132:INFO:setup() successfully completed in 0.94s...............
2024-01-03 19:03:15,560:INFO:PyCaret ClassificationExperiment
2024-01-03 19:03:15,560:INFO:Logging name: clf-default-name
2024-01-03 19:03:15,560:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 19:03:15,560:INFO:version 3.2.0
2024-01-03 19:03:15,560:INFO:Initializing setup()
2024-01-03 19:03:15,560:INFO:self.USI: 450a
2024-01-03 19:03:15,560:INFO:self._variable_keys: {'fold_shuffle_param', 'idx', 'y', 'X_test', 'X_train', 'gpu_n_jobs_param', 'X', 'data', 'exp_id', 'n_jobs_param', 'logging_param', 'pipeline', 'fold_generator', 'memory', 'fold_groups_param', 'html_param', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'target_param', 'y_test', 'fix_imbalance', 'USI', 'gpu_param', '_ml_usecase', 'seed', '_available_plots'}
2024-01-03 19:03:15,560:INFO:Checking environment
2024-01-03 19:03:15,560:INFO:python_version: 3.11.5
2024-01-03 19:03:15,560:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-03 19:03:15,560:INFO:machine: AMD64
2024-01-03 19:03:15,560:INFO:platform: Windows-10-10.0.19045-SP0
2024-01-03 19:03:15,560:INFO:Memory: svmem(total=16893386752, available=3759792128, percent=77.7, used=13133594624, free=3759792128)
2024-01-03 19:03:15,560:INFO:Physical Core: 4
2024-01-03 19:03:15,560:INFO:Logical Core: 8
2024-01-03 19:03:15,561:INFO:Checking libraries
2024-01-03 19:03:15,561:INFO:System:
2024-01-03 19:03:15,561:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-03 19:03:15,561:INFO:executable: C:\Users\Windows\.conda\envs\COMP3222Labs\python.exe
2024-01-03 19:03:15,561:INFO:   machine: Windows-10-10.0.19045-SP0
2024-01-03 19:03:15,561:INFO:PyCaret required dependencies:
2024-01-03 19:03:15,561:INFO:                 pip: 23.3.1
2024-01-03 19:03:15,561:INFO:          setuptools: 68.2.2
2024-01-03 19:03:15,561:INFO:             pycaret: 3.2.0
2024-01-03 19:03:15,561:INFO:             IPython: 8.15.0
2024-01-03 19:03:15,561:INFO:          ipywidgets: 8.0.4
2024-01-03 19:03:15,561:INFO:                tqdm: 4.66.1
2024-01-03 19:03:15,561:INFO:               numpy: 1.25.2
2024-01-03 19:03:15,561:INFO:              pandas: 1.5.3
2024-01-03 19:03:15,561:INFO:              jinja2: 3.1.2
2024-01-03 19:03:15,561:INFO:               scipy: 1.10.1
2024-01-03 19:03:15,561:INFO:              joblib: 1.2.0
2024-01-03 19:03:15,561:INFO:             sklearn: 1.2.2
2024-01-03 19:03:15,561:INFO:                pyod: 1.1.2
2024-01-03 19:03:15,562:INFO:            imblearn: 0.11.0
2024-01-03 19:03:15,562:INFO:   category_encoders: 2.6.3
2024-01-03 19:03:15,562:INFO:            lightgbm: 4.2.0
2024-01-03 19:03:15,562:INFO:               numba: 0.58.1
2024-01-03 19:03:15,562:INFO:            requests: 2.31.0
2024-01-03 19:03:15,562:INFO:          matplotlib: 3.6.0
2024-01-03 19:03:15,562:INFO:          scikitplot: 0.3.7
2024-01-03 19:03:15,562:INFO:         yellowbrick: 1.5
2024-01-03 19:03:15,562:INFO:              plotly: 5.18.0
2024-01-03 19:03:15,562:INFO:    plotly-resampler: Not installed
2024-01-03 19:03:15,562:INFO:             kaleido: 0.2.1
2024-01-03 19:03:15,562:INFO:           schemdraw: 0.15
2024-01-03 19:03:15,562:INFO:         statsmodels: 0.14.1
2024-01-03 19:03:15,562:INFO:              sktime: 0.21.1
2024-01-03 19:03:15,562:INFO:               tbats: 1.1.3
2024-01-03 19:03:15,562:INFO:            pmdarima: 2.0.4
2024-01-03 19:03:15,562:INFO:              psutil: 5.9.0
2024-01-03 19:03:15,562:INFO:          markupsafe: 2.1.1
2024-01-03 19:03:15,562:INFO:             pickle5: Not installed
2024-01-03 19:03:15,562:INFO:         cloudpickle: 3.0.0
2024-01-03 19:03:15,562:INFO:         deprecation: 2.1.0
2024-01-03 19:03:15,562:INFO:              xxhash: 3.4.1
2024-01-03 19:03:15,562:INFO:           wurlitzer: Not installed
2024-01-03 19:03:15,562:INFO:PyCaret optional dependencies:
2024-01-03 19:03:15,563:INFO:                shap: Not installed
2024-01-03 19:03:15,563:INFO:           interpret: Not installed
2024-01-03 19:03:15,563:INFO:                umap: Not installed
2024-01-03 19:03:15,563:INFO:     ydata_profiling: Not installed
2024-01-03 19:03:15,563:INFO:  explainerdashboard: Not installed
2024-01-03 19:03:15,563:INFO:             autoviz: Not installed
2024-01-03 19:03:15,563:INFO:           fairlearn: Not installed
2024-01-03 19:03:15,563:INFO:          deepchecks: Not installed
2024-01-03 19:03:15,563:INFO:             xgboost: Not installed
2024-01-03 19:03:15,563:INFO:            catboost: Not installed
2024-01-03 19:03:15,563:INFO:              kmodes: Not installed
2024-01-03 19:03:15,563:INFO:             mlxtend: 0.23.0
2024-01-03 19:03:15,563:INFO:       statsforecast: Not installed
2024-01-03 19:03:15,563:INFO:        tune_sklearn: Not installed
2024-01-03 19:03:15,563:INFO:                 ray: Not installed
2024-01-03 19:03:15,563:INFO:            hyperopt: Not installed
2024-01-03 19:03:15,563:INFO:              optuna: Not installed
2024-01-03 19:03:15,563:INFO:               skopt: Not installed
2024-01-03 19:03:15,563:INFO:              mlflow: Not installed
2024-01-03 19:03:15,563:INFO:              gradio: Not installed
2024-01-03 19:03:15,564:INFO:             fastapi: Not installed
2024-01-03 19:03:15,564:INFO:             uvicorn: Not installed
2024-01-03 19:03:15,564:INFO:              m2cgen: Not installed
2024-01-03 19:03:15,564:INFO:           evidently: Not installed
2024-01-03 19:03:15,564:INFO:               fugue: Not installed
2024-01-03 19:03:15,564:INFO:           streamlit: Not installed
2024-01-03 19:03:15,564:INFO:             prophet: Not installed
2024-01-03 19:03:15,564:INFO:None
2024-01-03 19:03:15,564:INFO:Set up data.
2024-01-03 19:03:15,592:INFO:Set up folding strategy.
2024-01-03 19:03:15,592:INFO:Set up train/test split.
2024-01-03 19:03:15,612:INFO:Set up index.
2024-01-03 19:03:15,612:INFO:Assigning column types.
2024-01-03 19:03:15,614:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 19:03:15,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 19:03:15,712:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:03:15,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:15,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:15,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 19:03:15,871:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:03:15,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:15,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:15,938:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 19:03:16,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:03:16,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:16,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:16,184:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 19:03:16,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:16,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:16,246:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 19:03:16,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:16,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:16,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:16,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:16,631:INFO:Preparing preprocessing pipeline...
2024-01-03 19:03:16,632:INFO:Set up label encoding.
2024-01-03 19:03:16,632:INFO:Set up simple imputation.
2024-01-03 19:03:16,634:INFO:Set up encoding of categorical features.
2024-01-03 19:03:16,753:INFO:Finished creating preprocessing pipeline.
2024-01-03 19:03:16,757:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Windows\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['processedText'],
                                    transformer=TargetEncoder(cols=['processedText'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-03 19:03:16,757:INFO:Creating final display dataframe.
2024-01-03 19:03:17,120:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, real: 1
4           Original data shape        (25826, 2)
5        Transformed data shape        (25826, 2)
6   Transformed train set shape        (18078, 2)
7    Transformed test set shape         (7748, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              450a
2024-01-03 19:03:17,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:17,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:17,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:17,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 19:03:17,476:INFO:setup() successfully completed in 1.92s...............
2024-01-03 19:03:17,478:INFO:Initializing create_model()
2024-01-03 19:03:17,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C088F97810>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-03 19:03:17,478:INFO:Checking exceptions
2024-01-03 19:03:17,490:INFO:Importing libraries
2024-01-03 19:03:17,490:INFO:Copying training dataset
2024-01-03 19:03:17,494:INFO:Defining folds
2024-01-03 19:03:17,494:INFO:Declaring metric variables
2024-01-03 19:03:17,497:INFO:Importing untrained model
2024-01-03 19:03:17,500:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 19:03:17,504:INFO:Starting cross validation
2024-01-03 19:03:17,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 19:03:17,639:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,649:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,655:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,658:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,665:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,669:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,672:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,673:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,678:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,682:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,685:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,691:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,691:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,691:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,700:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,702:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,705:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,709:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,710:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,722:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,726:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,727:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,740:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,744:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,792:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,793:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,802:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,802:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,814:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,814:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'real') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-03 19:03:17,827:INFO:Calculating mean and std
2024-01-03 19:03:17,828:INFO:Creating metrics dataframe
2024-01-03 19:03:17,831:INFO:Finalizing model
2024-01-03 19:03:17,876:INFO:Uploading results into container
2024-01-03 19:03:17,877:INFO:Uploading model into container now
2024-01-03 19:03:17,884:INFO:_master_model_container: 1
2024-01-03 19:03:17,884:INFO:_display_container: 2
2024-01-03 19:03:17,885:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 19:03:17,885:INFO:create_model() successfully completed......................................
2024-01-04 09:34:28,377:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:34:46,502:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:34:58,669:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:36:37,279:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:36:57,525:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:36:57,525:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:37:00,148:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:37:29,868:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:37:29,868:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:37:31,948:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:38:35,971:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-01-04 09:39:06,512:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-01-04 09:40:06,141:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-01-04 09:40:29,340:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:40:36,512:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:41:46,052:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 09:52:35,442:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:52:35,445:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:52:43,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:52:43,939:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:52:58,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:52:58,732:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:54:08,114:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:54:08,115:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:55:02,255:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:55:02,256:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:55:02,503:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-01-04 09:55:30,280:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:55:30,280:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:55:30,533:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-01-04 09:55:37,464:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:55:37,465:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:55:37,713:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-01-04 09:55:47,363:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:55:47,363:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:56:57,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:56:57,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 09:59:25,108:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 09:59:25,108:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 10:01:07,017:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 10:01:07,017:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 10:01:51,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 10:01:51,620:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 10:31:02,519:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 10:31:02,519:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 10:33:13,010:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 10:33:13,011:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 10:50:15,108:WARNING:C:\Users\Windows\AppData\Local\Temp\ipykernel_26300\1440119742.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.
  soup = BeautifulSoup(unescape(text), 'lxml')

2024-01-04 10:50:16,909:WARNING:C:\Users\Windows\AppData\Local\Temp\ipykernel_26300\1440119742.py:6: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.
  soup = BeautifulSoup(unescape(text), 'lxml')

2024-01-04 10:55:02,906:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 10:55:02,906:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 10:55:57,191:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 10:55:57,191:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 10:56:07,072:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 10:56:07,072:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 10:56:39,780:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 10:56:39,780:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:05:38,640:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:05:38,640:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:06:01,602:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:06:01,602:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:34:13,082:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:34:13,083:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:37:29,075:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:37:29,075:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:38:45,726:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:38:45,726:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:45:09,649:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:45:09,649:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:45:32,170:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:45:32,170:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:46:04,890:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:46:04,890:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:55:17,927:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:55:17,927:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:57:35,790:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:57:35,790:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:57:54,983:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:57:54,983:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 11:59:37,572:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 11:59:37,572:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 12:01:34,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 12:01:34,619:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 12:05:29,233:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 12:05:29,233:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 13:48:53,280:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 13:48:53,280:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 13:52:44,317:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 13:52:53,761:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 13:53:10,347:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:00:51,429:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:01:10,824:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:01:15,706:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:01:19,286:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:01:23,286:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:01:27,680:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:01:38,310:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:05:01,356:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:05:01,357:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:07:07,131:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:07:07,131:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:07:15,618:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:08:10,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:08:10,180:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:09:11,133:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:09:11,133:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:10:17,323:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:10:17,323:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:10:25,811:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:13:03,159:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:13:03,159:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:15:59,115:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:15:59,115:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:18:03,921:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:18:03,921:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:20:55,701:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:20:55,701:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

2024-01-04 14:22:26,979:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:23:56,733:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:44:04,645:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.
  warnings.warn(

2024-01-04 14:44:04,645:WARNING:C:\Users\Windows\.conda\envs\COMP3222Labs\Lib\site-packages\sklearn\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.
  warnings.warn(

